```py
import tensorflow as tf
import numpy as np

def image_crop_3(datapoint, target_shape=300):
    image, label = datapoint["image"], datapoint["label"]
    height, width = image.shape[:2]
    if height == width:
        resize_shape = (target_shape, target_shape)
        crops = [tf.image.resize(image, resize_shape)] * 3
    elif height < width:
        resize_shape = (target_shape, target_shape * width // height)
        image = tf.image.resize(image, resize_shape)
        crops = [
            image[:, :target_shape],
            image[:, (image.shape[1] - target_shape) // 2 : (image.shape[1] + target_shape) // 2],
            image[:, -target_shape:],
        ]
    else:
        resize_shape = (target_shape * height // width, target_shape)
        image = tf.image.resize(image, resize_shape)
        crops = [
            image[:target_shape, :],
            image[(image.shape[0] - target_shape) // 2 : (image.shape[0] + target_shape) // 2, :],
            image[-target_shape:, :],
        ]
    return np.array(crops), label


def model_pred_3(model, image_batch):
    preds = model((np.array(image_batch) - 127.5) / 127)
    pred_values, pred_classes = np.max(preds, -1), np.argmax(preds, -1)
    pred_values, pred_classes = pred_values.reshape(-1, 3), pred_classes.reshape(-1, 3)

    voted_classes, voted_values = [], []
    for pred_value, pred_class in zip(pred_values, pred_classes):
        if pred_class[0] == pred_class[1]:
            voted_class = pred_class[0]
            voted_value = max(pred_value[0], pred_value[1])
        elif pred_class[0] == pred_class[2]:
            voted_class = pred_class[0]
            voted_value = max(pred_value[0], pred_value[2])
        elif pred_class[1] == pred_class[2]:
            voted_class = pred_class[1]
            voted_value = max(pred_value[1], pred_value[2])
        else:
            voted_class = pred_class[np.argmax(pred_value)]
            voted_value = np.max(pred_value)
        voted_classes.append(voted_class)
        voted_values.append(voted_value)
    return voted_classes, voted_values, preds


def model_validation_3(model, batch_size=64):
    from tqdm import tqdm

    dataset, info = tfds.load("food101", with_info=True)
    batch_size = 64
    test_gen = dataset["validation"].as_numpy_iterator()
    total_test = info.splits["validation"].num_examples

    voted_classes, voted_values, labels, image_batch = [], [], [], []
    batch_size *= 3
    for id, datapoint in tqdm(enumerate(test_gen), total=total_test):
        crops, label = image_crop_3(datapoint)
        image_batch.extend(crops)
        labels.append(label)
        if id + 1 == total_test or len(image_batch) == batch_size:
            batch_voted_classes, batch_voted_values, batch_preds = model_pred_3(model, image_batch)
            voted_classes.extend(batch_voted_classes)
            voted_values.extend(batch_voted_values)
            image_batch = []

    voted_classes, voted_values, labels = np.array(voted_classes), np.array(voted_values), np.array(labels)
    print("crop_3_predict accuray:", (voted_classes == labels).sum() / labels.shape[0])
    return voted_classes, voted_values, labels

if __name__ == "__main__":
    import json
    import efficientnet_v2

    train_dataset, test_dataset, total_images, num_classes = food101.init_dataset()
    print("total_images: %s, num_classes: %s" % (total_images, num_classes))

    total_epochs = 36
    lr_scheduler = LearningRateScheduler(
        lambda epoch: exp_scheduler(epoch, lr_base=0.256, decay_step=1, decay_rate=0.88, warmup=2)
    )

    print(">>>> Basic input_shape=(128, 128, 3), dropout=0")
    eb2 = efficientnet_v2.EfficientNetV2(input_shape=(None, None, 3), include_top=True, classes=num_classes)
    inited_weights = eb2.get_weights()
    # optmizer = keras.optimizers.RMSprop(learning_rate=0.256, momentum=0.9, decay=0.9)
    optmizer = keras.optimizers.SGD(momentum=0.9)
    eb2.compile(loss="sparse_categorical_crossentropy", optimizer=optmizer, metrics=["accuracy"])
    history = eb2.fit(train_dataset, epochs=total_epochs, validation_data=test_dataset, callbacks=[lr_scheduler])
    with open("basic_dropout_0.json", "w") as ff:
        json.dump(history.history, ff)

    print(">>>> Basic input_shape=(128, 128, 3), dropout=0.4")
    eb2 = efficientnet_v2.EfficientNetV2(input_shape=(None, None, 3), include_top=True, classes=num_classes, dropout=0.4)
    eb2.set_weights(inited_weights)
    optmizer = keras.optimizers.SGD(momentum=0.9)
    eb2.compile(loss="sparse_categorical_crossentropy", optimizer=optmizer, metrics=["accuracy"])
    history = eb2.fit(train_dataset, epochs=total_epochs, validation_data=test_dataset, callbacks=[lr_scheduler])
    with open("basic_dropout_0.4.json", "w") as ff:
        json.dump(history.history, ff)

    print(">>>> Progressive input_shape=[56, 80, 104, 128], dropout=[0.1, 0.2, 0.3, 0.4]")
    eb2 = efficientnet_v2.EfficientNetV2(input_shape=(None, None, 3), include_top=True, classes=num_classes, dropout=0.1)
    eb2.set_weights(inited_weights)
    optmizer = keras.optimizers.SGD(momentum=0.9)
    eb2.compile(loss="sparse_categorical_crossentropy", optimizer=optmizer, metrics=["accuracy"])
    hhs = progressive_with_dropout_randaug(
        eb2, 36, stages=4, target_shapes=[56, 80, 104, 128], dropouts=[0.1, 0.2, 0.3, 0.4], magnitudes=[5, 5, 5, 5]
    )
    with open("progressive.json", "w") as ff:
        json.dump(hhs, ff)
elif __name__ == "__train_test__":
    import json

    keras.mixed_precision.set_global_policy("mixed_float16")

    train_dataset, test_dataset, total_images, num_classes = food101.init_dataset(
        target_shape=(300, 300), magnitude=15, keep_shape=True
    )
    # model = keras.applications.MobileNet(input_shape=(None, None, 3), include_top=False, weights='imagenet')
    model = keras.applications.InceptionV3(input_shape=(None, None, 3), weights="imagenet", include_top=False)
    # model = keras.applications.ResNet50(input_shape=(None, None, 3), weights='imagenet', include_top=False)
    inputs = model.inputs[0]
    nn = model.outputs[0]
    nn = keras.layers.GlobalAveragePooling2D()(nn)
    nn = keras.layers.Dropout(0.4)(nn)
    nn = keras.layers.Activation("linear", dtype="float32")(nn)
    nn = keras.layers.Dense(
        num_classes, kernel_regularizer=keras.regularizers.l2(0.0005), activation="softmax", name="predictions", dtype="float32"
    )(nn)
    model = keras.models.Model(inputs, nn)

    total_epochs = 52
    lr_scheduler = LearningRateScheduler(
        lambda epoch: exp_scheduler(epoch, lr_base=0.01, decay_step=1, decay_rate=0.9, warmup=4)
    )
    optimizer = keras.optimizers.SGD(momentum=0.9)
    loss = "categorical_crossentropy"
    # loss = keras.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=0.1)
    model.compile(loss=loss, optimizer=optimizer, metrics=["accuracy"])

    history = model.fit(train_dataset, epochs=total_epochs, validation_data=test_dataset, callbacks=[lr_scheduler])

    hhs = {kk: np.array(vv, "float").tolist() for kk, vv in history.history.items()}
    with open("inceptionV3_magnitude_10.json", "w") as ff:
        json.dump(hhs, ff)
    _ = food101.model_validation_3(model)
    food101.plot_hist(["inceptionV3_magnitude_15_keep_shape_true_ls_01.json"], names=["aa"])

    hhs = progressive_with_dropout_randaug(
        model,
        lr_scheduler,
        52,
        target_shapes=[128, 185, 242, 300],
        dropouts=[0.1, 0.2, 0.3, 0.4],
        magnitudes=[5, 8, 12, 15],
    )

```
```py
def face_align_landmark(img, landmark, image_size=(112, 112), method="similar"):
    tform = transform.AffineTransform() if method == "affine" else transform.SimilarityTransform()
    src = np.array(
        [[38.2946, 51.6963], [73.5318, 51.5014], [56.0252, 71.7366], [41.5493, 92.3655], [70.729904, 92.2041]], dtype=np.float32
    )
    tform.estimate(landmark, src)
    # ndimage = transform.warp(img, tform.inverse, output_shape=image_size)
    # ndimage = (ndimage * 255).astype(np.uint8)
    M = tform.params[0:2, :]
    ndimage = cv2.warpAffine(img, M, image_size, borderValue=0.0)
    if len(ndimage.shape) == 2:
        ndimage = np.stack([ndimage, ndimage, ndimage], -1)
    else:
        ndimage = cv2.cvtColor(ndimage, cv2.COLOR_BGR2RGB)
    return ndimage
```
