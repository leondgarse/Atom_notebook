# ___NMC5363___
***

# Lecture
## Week 1
  Part 1/2

  * [12:03–12:06] **Welcome, agenda, and introductions**
    **English** Today is Week 1: “Introduction — AI as Media.” I’ll start with brief admin items (course objectives, format, syllabus/readings, assignments), then we’ll discuss “What is AI?”, take a short break, and come back to “AI as media” and a course overview.

    **Chinese** 今天是第一周：“导论——把 AI 当作一种媒介”。先把课程的基本信息讲清楚（目标、上课形式、教学大纲/阅读、作业），再讨论“什么是 AI？”，中间休息一下，回来讲“AI 作为媒介”以及整学期主题安排。

  * [12:03–12:05] **Instructor background and contact**
    **English** I’m **Dr. Jun Yu** (course coordinator), Assistant Professor in Communications & New Media, and a Principal Investigator at the **NUS AI Institute**. I did my PhD at **LSE (2020)** and previously worked as a policy analyst at the **OECD (~2023)**, and still consult externally. My research interests include **datafication, platform economy, AI ethics & governance, internet infrastructure, privacy/dataveillance, social theory, and moral philosophy**. You can email me at **[jun.yu@nus.edu.sg](mailto:jun.yu@nus.edu.sg)**; consultations are available (email to arrange).

    **Chinese** 我是 **余骏博士（Dr. Jun Yu）**，传播与新媒体系助理教授，也是 **NUS AI Institute** 的 PI。**LSE 2020 博士**，曾在 **OECD（约到 2023）** 做政策分析，也有外部顾问工作。研究方向包括：**数据化、平台经济、AI 伦理与治理、互联网基础设施、隐私/数据监控、社会理论与道德哲学**。联系方式：**[jun.yu@nus.edu.sg](mailto:jun.yu@nus.edu.sg)**，想面谈或线上聊都可以，发邮件约时间。

  * [12:05–12:06] **Student introductions (quick round)**
    **English** Since many of you come from different majors (and some are part-time students working full-time), let’s do a quick round: your name, where you’re from, your educational background (e.g., CS/psych/econ), and what you hope to learn about AI in this course.

    **Chinese** 因为大家背景很多元（也有在职同学），我们快速自我介绍：姓名、来自哪里、本科/专业背景（比如计算机、心理、经济等），以及你希望这门课带你理解 AI 的什么问题。

  * [12:30–12:33] **Syllabus and readings on Canvas**
    **English** The syllabus and compulsory readings are on Canvas (Files → Readings folder). Up to around **Week 6** is already available; later weeks may be uploaded once finalized. Typically there are **2–3 compulsory readings per week**. Supplementary readings may be many; they’re optional and meant as extra resources, not an expectation to finish everything.

    **Chinese** 教学大纲和必读都在 Canvas（Files → Readings folder）。目前大概到 **第 6 周** 已经放上去，后面会在确定后更新。每周一般 **2–3 篇必读**。补充阅读可能很多，但属于“可选拓展”，不是要求全部读完。

  * [12:33–12:34] **Flexibility of syllabus**
    **English** The syllabus/readings may adjust based on class needs and feedback, but changes will be announced in advance (so you won’t be surprised mid-semester).

    **Chinese** 大纲/阅读可能会根据课堂节奏和反馈微调，但会提前通知，不会突然改到让大家措手不及。

  * [12:34–12:40] **Assignments overview (weights and what they mean)**
    **English** There are ongoing components plus a dated group project:

    1. **Class participation (20%)** — attendance and contributions to discussion.
    2. **Reading presentation (20%)** — begins around **Week 5**, usually in groups; readings are generally assigned (with some chance to indicate topic preferences).
    3. **AI reflective essay (25%)** — keep a short “AI diary” about your own encounters with AI (social media feeds, translation tools like Google Translate, photo apps, assistants, etc.), then write an essay using a course concept/theory to critically analyse your experience.
    4. **Group project (Week 13, 35%)** — a critical explanatory report plus a creative output.

    **Chinese** 作业分“贯穿全学期”的部分 + “有固定周次截止”的小组项目：
    1）**课堂参与 20%**：到课 + 参与讨论。
    2）**阅读展示 20%**：大概 **第 5 周**开始，多数是小组形式；阅读通常会分配，但会尽量考虑大家的兴趣偏好。
    3）**AI 反思论文 25%**：先做一个简短的“AI 日记”，记录你生活里遇到的 AI（社媒推荐、翻译工具、拍照修图、语音助手等），再用课程里的概念/理论去做批判性分析。
    4）**第 13 周小组项目 35%**：写一篇面向大众的“解释型文章”+ 一个创意呈现作品。

  * [12:38–12:40] **Group project format (explanatory + creative)**
    **English** Choose a specific AI application area (e.g., inequality, ethics/bias, journalism, finance, education, etc.). The report should be written like a public-facing explanatory piece (similar to outlets like *The Conversation*), grounded in evidence and argument. Then produce a creative component (visualisation / podcast / infographic / etc.) that communicates your key message.

    **Chinese** 小组会选一个 AI 应用领域（比如不平等、伦理与偏见、新闻、金融、教育等）。报告写成面向公众的“解释型文章”（类似 *The Conversation* 这种风格）：讲清楚问题、给出论据和观点。然后再做一个创意作品（可视化/播客/信息图等）把核心论点表达出来。

  * [12:40–12:49] **Mentimeter: “What is AI?” (how people define it)**
    **English** We did a quick Mentimeter exercise asking “What is AI?”. Many responses cluster around: **human intelligence**, **machines that mimic/extend human thinking**, **learning**, and **communication**. This already shows that people use the same label “AI” to mean quite different things, which can create confusion in debates.

    **Chinese** 我们用 Mentimeter 做了一个小练习：“你觉得 AI 是什么？”大家的回答常见关键词集中在：**人类智能**、**模仿/增强人类思考的机器**、**学习**、**沟通**。这说明“AI”这个词本身就很容易被大家用来指不同东西，所以讨论时经常会产生“各说各话”。

  * [12:50–13:02] **AI “snake oil”: AI is an umbrella term + key types**
    **English** A key point: **AI is an umbrella term** for different applications, not one single thing. One framing (from Narayanan & Kapoor) distinguishes:

    * **Generative AI**: creates new content (e.g., ChatGPT, DeepSeek, Gemini, Midjourney).
    * **Predictive AI**: forecasts human behaviour or social outcomes (employment, education outcomes, welfare eligibility, recidivism, insurance risk, etc.).
    * **Content moderation AI**: tools used to police social media at scale (often pattern-matching plus workflow + human labour).

    **Chinese** 一个核心观点：**AI 是“总称”，不是单一技术**。一种常用分类是：

    * **生成式 AI**：生成新内容（如 ChatGPT、DeepSeek、Gemini、Midjourney）。
    * **预测式 AI**：预测人的行为或社会结果（就业、教育成绩、福利资格、再犯风险、保险风险等）。
    * **内容审核 AI**：用于大规模管理/过滤社交媒体内容（很多时候是“模式匹配 + 流程 + 人工介入”组合）。

  * [12:53–13:02] **Examples of the “gap” between claims and reality**
    **English** We looked at examples where systems were marketed as objective/efficient but created harm or failed in practice, such as:

    * **A-level grading algorithm controversy** (predicting grades from historical patterns).
    * **Dutch childcare benefits scandal** (large-scale wrongful accusations and severe downstream harm).
    * **Bias in hiring tools** (e.g., systems trained on past data reproducing past imbalances).
    * **Proxy measurement problems**: e.g., using **eye-tracking** as a proxy for attention/reading comprehension; even if it measures eye movement, it may not truly measure understanding.
    * **Emotion recognition in interviews**: assuming facial expressions map cleanly to confidence, stress tolerance, honesty, etc., which is often not a stable assumption.

    **Chinese** 我们看了一些“宣传很大、落地很难”的例子：

    * **英国 A-level 成绩算法争议**（用历史数据推算成绩）。
    * **荷兰育儿补贴丑闻**（大规模错误指控，造成严重连锁伤害）。
    * **招聘系统偏见**（训练数据来自过去，就容易把过去的不平等继续放大）。
    * **“代理指标”问题**：比如用**眼动**来代表注意力/阅读理解——它能测眼睛动，但不一定真能测“理解”。
    * **面试情绪识别**：把表情直接等同于自信、抗压、诚实等，现实里往往不成立。

  * [13:02–13:29] **Discussion: why the gap persists (multi-factor, sociotechnical)**
    **English** We discussed why “big claims vs reality” keeps happening. Key reasons include:

    1. **Incentives reward overclaiming**: funding, adoption, marketing, and media attention push inflated narratives.
    2. **Capability is easy to demo, hard to validate in context**: real deployments involve messy workflows, edge cases, humans-in-the-loop, accountability, and organisational constraints; AI is a **sociotechnical system**, not just a model.
    3. **Ambiguous problem definitions → goalpost shifting**: goals like “improve hiring” or “predict risk” are contested and multidimensional.
    4. **Reality changes; data lags**: distribution shift over time reduces reliability.
    5. **Hidden labour/infrastructure**: labelling, moderation, exception handling, escalation work makes systems look more capable than they are.
    6. **Weak accountability**: responsibility is diffuse across vendors, deployers, and frontline users.
       Closing idea before break: don’t treat AI as simply “good vs bad.” Be **specific and contextual** about what system, what task, what evidence, and what consequences.

    **Chinese** 我们讨论了为什么“宣传很猛、现实很骨感”会反复出现，通常不是单一原因：
    1）**激励机制鼓励夸大**：融资、市场、媒体传播都偏好“更大更快更通用”的叙事。
    2）**演示容易、真实验证难**：真实场景有流程摩擦、边界案例、人机协作、责任归属、组织限制；AI 是**社会—技术系统**，不是一个模型分数。
    3）**问题定义含糊→标准可移动**：比如“提升招聘”“预测风险”本身就有多维目标和争议，评价标准很容易被改。
    4）**世界在变、数据滞后**：环境变化导致模型可靠性下降。
    5）**隐形劳动与基础设施**：标注、审核、兜底、升级处理让系统“看起来”更强。
    6）**问责链条弱**：供应商、部署方、一线使用者之间责任分散。
    休息前的落点：不要把 AI 简化成“好/坏二选一”，要更**具体、情境化**：是哪种系统、做什么任务、证据是什么、带来什么后果。

  * [13:29–13:40] **Break**
    **English** 10-minute break; return at around 1:40.

    **Chinese** 休息 10 分钟，约 1:40 回来继续。

  Part 2/2  

  * [13:43–13:49] **AI as “media”: why communication matters**
    **English** We shift from “What is AI?” to “AI as media.” Drawing on **Guzman & Lewis (2020)**, AI can be seen as automating communication and placing machines into roles historically reserved for humans-as-communicators. This raises three layers of questions:

    * **Functional**: How do people perceive AI as a communicator?
    * **Relational**: How is AI positioned in social roles (assistant, writer, etc.), and how does that reshape interaction?
    * **Metaphysical**: If machines can communicate, what does that imply for what we mean by “human” and “communication”?

    **Chinese** 我们从“AI 是什么”转向“AI 作为媒介”。根据 **Guzman & Lewis (2020)**，可以把 AI 看成是在**自动化沟通**，并让机器进入过去只有人才能承担的“沟通者角色”。因此会产生三层问题：

    * **功能层**：人们如何把 AI 当成一个“沟通者”？
    * **关系层**：AI 被放在什么社会角色里（助手、写作者等），这会怎样改变人与人的互动？
    * **本体层**：如果机器也能沟通，那“人是什么”“沟通是什么”会不会被重新定义？

  * [13:44–13:49] **Why “Social Transformations”: from interpersonal to institutional**
    **English** Communication is not only about person-to-person interaction; it is also how societies coordinate: institutions make decisions, rules are enforced, value is assigned, uncertainty is managed, and legitimacy is produced. If AI automates or reshapes communication, the stakes are not just individual but also **institutional and societal**. A supporting historical lens is Beniger’s **The Control Revolution (1986)**: information/communication technologies help societies maintain coordination and control as complexity scales.

    **Chinese** “社会变革”强调：沟通不只是人与人的聊天，它还是社会如何运转的机制——机构如何决策、规则如何执行、价值如何被分配、不确定性如何被管理、合法性如何被建构。AI 一旦开始自动化/重塑沟通，影响就不只是个人层面，而是**制度与社会层面**。一个历史视角是 Beniger 的 **《控制革命》(1986)**：信息与传播技术往往是在社会变复杂时，用来维持协调与治理能力的工具。

  * [13:49–14:00] **Course overview (Weeks 2–13)**
    **English** The rest of the semester maps key themes of AI-as-media and its societal implications:

    * **Week 2**: Technical foundations (classification, algorithmic curation, machine learning) — not for engineering depth, but to support social analysis.
    * **Week 3**: Political economy of AI (data, infrastructure, concentration of resources in big tech; why AI development is structured the way it is).
    * **Week 4**: Work, labour, and automation (beyond “job loss vs job gain”; distribution of benefits/harms, and ethical issues in transitions).
    * **Week 5**: Creativity, authorship, and AI-generated content (cultural production + journalism).
    * **Week 6**: AI, relationships, and intimacy (avoid simple “good/bad”; analyse how relationships are reconfigured).
    * **Week 7**: AI and surveillance (privacy, data security, cybersecurity).
    * **Week 8**: AI, biases, inequalities (not only “remove bias,” but why bias is structurally hard and perspective-dependent).
    * **Week 9**: Deepfakes, synthetic media, disinformation (what changes qualitatively/quantitatively).
    * **Week 10**: Materiality and sustainability (energy/water claims need evidence; investigate what is known vs assumed).
    * **Week 11**: Well-being Day (no seminar).
    * **Week 12**: AI ethics, regulation, governance (regulation not simply “blocking innovation”; how to enable better outcomes).
    * **Week 13**: Wrap-up — futures of AI (what kind of AI/human future is desired).

    **Chinese** 后面 12 周会围绕“AI 作为媒介”带来的社会影响展开：

    * **第 2 周**：技术基础（分类、算法推荐/策展、机器学习）——重点不是工程细节，而是为社会分析打底。
    * **第 3 周**：AI 的政治经济（数据与基础设施、资源向大公司集中，AI 为什么以这种方式发展）。
    * **第 4 周**：工作、劳动与自动化（不陷入“失业/增岗”二分；看利益与风险如何分配、转型中的伦理问题）。
    * **第 5 周**：创造力、作者身份与生成内容（文化生产与新闻实践）。
    * **第 6 周**：AI、关系与亲密（避免“好/坏”简单结论，看关系结构如何被改写）。
    * **第 7 周**：AI 与监控（隐私、数据安全、网络安全）。
    * **第 8 周**：偏见与不平等（不仅是“消除偏见”，还要理解偏见为何结构性顽固、且与立场相关）。
    * **第 9 周**：深度伪造、合成媒体与虚假信息（与过去相比有哪些质与量的变化）。
    * **第 10 周**：AI 的物质性与可持续（能耗/用水的说法需要证据，区分“知道什么”和“以为知道什么”）。
    * **第 11 周**：Well-being Day（无课）。
    * **第 12 周**：伦理、监管与治理（监管不等于“扼杀创新”，而是如何导向更好的结果）。
    * **第 13 周**：总结：AI 的未来（我们想要怎样的 AI 与人类未来）。
***

## Course syllabus
  Jump to today
  Please note: This page is automatically updated using information from the Class Data Management System (CDMS), ensuring consistent course information across various systems.

  Course Description
  This interdisciplinary master’s course interrogates artificial intelligence not merely as technology but as an institutionalised medium that channels data, resources, and power, reshaping everyday life. Drawing on media and communications studies, sociology, political economy, critical AI studies, and Science and Technology Studies, it explores: (1) the historical and geographical trajectories of AI development; (2) AI’s integration into work, labour, creativity and social norms; and (3) legal-ethical debates on intellectual property, privacy, sustainability, disinformation and algorithmic bias across race, gender and class. Through critical readings, case studies and a research project, students analyse AI’s local and global impacts and debate future directions. The course is non-technical (no coding required), aimed at students seeking nuanced insight into AI’s role in reorganising economy, culture and governance.

  Units: 4

  Grading Basis: GRD (Graded)

  Pre-requisites / Co-requisites / Preclusions
  Type	Description	Additional Information
  Pre-requisite(s)
  Co-requisite(s)

  Learning outcomes
  Students will develop a contextual understanding of AI, its history, and evolution, to have an informed opinion for its future use and trajectory.
  Students will understand the basics of the technologies behind AI, such as machine learning, deep learning, natural language processing, neural networks, and algorithms.
  Students will be able to critically analyse AI as a form of media that structures and mediates data, information, social interactions, and work practices, and understand its broader societal implications.
  Students will be able to examine the impact of AI on media and cultural industries, such as journalism, advertising, entertainment, and cultural production, considering AI-driven automation and personalisation.
  Students will be able to evaluate the ethical, social, and regulatory challenges surrounding AI, such as algorithmic bias, disinformation, surveillance, intellectual property rights, and data governance.
## Week 1 Introduction: AI as Media
  Compulsory readings

  Guzman, A. L., & Lewis, S. C. (2019). Artificial intelligence and communication: A Human–Machine Communication research agenda. New Media & Society, 21(8), 1673–1686.
  Narayanan, A., & Kapoor, S. (2024). Introduction. In AI snake oil: What artificial intelligence can do, what it can’t, and how to tell the difference (pp. 1–35). Princeton University Press. https://press.princeton.edu/books/hardcover/9780691249131/ai-snake-oilLinks to an external site.
  Recommended readings

  Couldry, N., & Mejias, U. A. (2019). The costs of connection: How data are colonizing human life and appropriating it for capitalism. Stanford University Press.
  Crawford, K. (2021). Atlas of AI: Power, politics, and the planetary costs of artificial intelligence. Yale University Press.
  Esposito, E. (2022). Artificial communication: Algorithms as interaction partners. In Artificial communication: How algorithms produce social intelligence (pp. 1–32). MIT Press.
  Suchman, L. (2023). The uncontroversial ‘thingness’ of AI. Big Data & Society, 10(2), 1–5.
## Week 2 Technical Foundations of AI: Classification, Algorithmic Curation, Machine Learning
  Compulsory readings

  Bowker, G. C., & Star, S. L. (1999). Introduction: To classify is human. In Sorting things out: Classification and its consequences (pp. 1–32). MIT Press.
  Crawford, K., & Paglen, T. (2019, September 19). Excavating AI: The politics of training sets for machine learning. https://excavating.aiLinks to an external site.
  Gillespie, T. (2014). The relevance of algorithms. In T. Gillespie, P. J. Boczkowski, & K. A. Foot (Eds.), Media technologies: Essays on communication, materiality, and society (pp. 167–194). MIT Press.
  Recommended readings

  Broussard, M. (2018). Machine learning: The DL on ML. In Artificial unintelligence: How computers misunderstand the world (pp. 87–119). MIT Press.
  Burrell, J. (2016). How the machine ‘thinks’: Understanding opacity in machine learning algorithms. Big Data & Society, 3(1), 1–12.
  Campolo, A., & Crawford, K. (2020). Enchanted determinism: Power without responsibility in artificial intelligence. Engaging Science, Technology, and Society, 6, 1–19.
  Domingos, P. (2012). A few useful things to know about machine learning. Communications of the ACM, 55(10), 78–87.
  Dreyfus, H. L. (1972). What computers can’t do: A critique of artificial reason. Harper & Row.
  Gebru, T., Morgenstern, J., Vecchione, B., Vaughan, J. W., Wallach, H., Iii, H. D., & Crawford, K. (2021). Datasheets for datasets. Communications of the ACM, 64(12), 86–92.
  Gillespie, T. (2020). Content moderation, AI, and the question of scale. Big Data & Society, 7(2), 1–5.
  LeCun, Y., Bengio, Y., & Hinton, G. (2015). Deep learning. Nature, 521(7553), 436–444.
  Searle, J. R. (1980). Minds, brains, and programs. Behavioral and Brain Sciences, 3(3), 417–424.
  On the Media (2018) – Podcast Segment On the Media. (2018, September 21). How neural networks revolutionized AI [Audio podcast segment: a conversation with Geoffrey Hinton]. WNYC Studios. https://www.wnycstudios.org/podcasts/otm/segments/how-neural-networks-revolutionized-ai-on-the-mediaLinks to an external site.
## Week 3 Political Economy of AI
  Compulsory readings

  Srnicek, N. (2017). Platform capitalism. In Platform capitalism (pp. 36–73). Polity.
  Van der Vlist, F. N., Helmond, A., & Ferrari, F. (2024). Big AI: Cloud infrastructure dependence and the industrialisation of artificial intelligence. Big Data & Society, 11(1).
  Recommended readings

  Cohen, J. E. (2018). The biopolitical public domain: The legal construction of the surveillance economy. Philosophy & Technology, 31(2), 213–233.
  Cohen, J. E. (2019). Between truth and power: The legal constructions of informational capitalism. Oxford University Press.
  Couldry, N., & Mejias, U. A. (2019). Data colonialism: Rethinking big data’s relation to the contemporary subject. Television & New Media, 20(4), 336–349.
  Crawford, K. (2021). Introduction. In Atlas of AI: Power, politics, and the planetary costs of artificial intelligence (pp. 1–20). Yale University Press.
  Dyer-Witheford, N., Kjøsen, A. M., & Steinhoff, J. (2019). Inhuman power: Artificial intelligence and the future of capitalism. Pluto Press.
  Farronato, C. (2025). Data as the new oil. In A. Agrawal, J. Gans, A. Goldfarb, & C. Tucker (Eds.), The political economy of artificial intelligence. University of Chicago Press.
  Fourcade, Marion and Healy, Kieran (2016). Seeing Like a Market. Socio-Economic Review, 15(1), 9–29.
  Hao, K. (2025). Empire of AI: Dreams and nightmares in Sam Altman’s OpenAI. Penguin.
  Mosco, V. (2014). To the cloud: Big data in a turbulent world. Routledge.
  Pasquale, F. (2015). The Black Box Society: The Secret Algorithms That Control Money and Information. Harvard University Press.
  Risse, M. (2023). Political theory of the digital age: Where artificial intelligence might take us. Cambridge University Press.
  Sadowski, J. (2019). When data is capital: Datafication, accumulation, and extraction. Big Data & Society, 6(1), 1–12.
  Van Dijck, J., Poell, T., & de Waal, M. (2018). The platform society: Public values in a connective world. Oxford University Press.
  Zuboff, S. (2019). The age of surveillance capitalism: The fight for a human future at the new frontier of power. PublicAffairs
## Week 4 Work, Labour, and Automation
  Compulsory readings

  Autor, D. H. (2015). Why are there still so many jobs? The history and future of workplace automation. Journal of Economic Perspectives, 29(3), 3–30.
  Casilli, A. A. (2021). Waiting for robots: The ever-elusive myth of automation and the global exploitation of digital labor. Sociologias, 23(57), 112–133.
  Gent, E. (2019, August 29). The ‘ghost work’ powering tech magic. BBC Worklife. https://www.bbc.com/worklife/article/20190829-the-ghost-work-powering-tech-magicLinks to an external site.
  Zuckerberg, M. (2025, July 30). Personal superintelligence: A new era of empowerment. Meta. https://www.meta.com/superintelligence/Links to an external site.
  Recommended readings

  Andrejevic, M. (2019). Automating surveillance. Surveillance & Society, 17(1/2), 7–13.
  Autor, D., & Thompson, N. (2025). Expertise (Working Paper No. 33941). National Bureau of Economic Research.
  Casilli, A. A., & Posada, J. (2019). The platformization of labor and society. In M. Graham & W. H. Dutton (Eds.), Society and the internet: How networks of information and communication are changing our lives (2nd ed., pp. 293–306). Oxford University Press.
  Data & Society Research Institute. (2024). Generative AI and labor: Power, hype, and value at work. https://datasociety.net/library/generative-ai-and-laborLinks to an external site.
  Frey, C. B., & Osborne, M. A. (2017). The future of employment: How susceptible are jobs to computerisation? Technological Forecasting and Social Change, 114, 254–280. [especially for a more pessimistic view on automation]
  Frey, C. B., & Osborne, M. (2023). Generative AI and the future of work: A reappraisal (Working Paper No. 2023). Oxford Martin School, University of Oxford. https://oms-www.files.svdcdn.com/production/downloads/academic/2023-FoW-Working-Paper-Generative-AI-and-the-Future-of-Work-A-Reappraisal-combined.pdfLinks to an external site.
  Gray, M. L., & Suri, S. (2019). Ghost work: How to stop Silicon Valley from building a new global underclass. Houghton Mifflin Harcourt.
  Kellogg, K. C., Valentine, M. A., & Christin, A. (2020). Algorithms at work: The new contested terrain of control. Academy of Management Annals, 14(1), 366–410.
  Rosenblat, A. (2018). Uberland: How algorithms are rewriting the rules of work. University of California Press.
  Steinhoff, J. (2021). Automation and autonomy: Labour, capital and machines in the artificial intelligence industry. Palgrave Macmillan.
  Suchman, L. (2007). Human-machine reconfigurations: Plans and situated actions (2nd ed.). Cambridge University Press.
  Tubaro, P., Casilli, A. A., & Coville, M. (2020). The trainer, the verifier, the imitator: Three ways in which human platform workers support artificial intelligence. Big Data & Society, 7(1), 1–12.
## Week 5 Creativity, Authorship, and AI-Generated Content
  Compulsory readings

  Bridle, J. (2023, February 20). Is creativity over? James Bridle explores how we can collaborate with AI. WePresent by WeTransfer. https://wepresent.wetransfer.com/stories/james-bridle-on-creativity-and-ai-collaborationLinks to an external site.
  Lee, H.-K. (2022) Rethinking creativity: Creative industries, AI and everyday creativity. Media, Culture & Society, 44(3), 601–612.
  Lewis, S. C., Guzman, A. L., & Schmidt, T. R. (2019). Automation, journalism, and human–machine communication: Rethinking roles and relationships of humans and machines in news. Digital Journalism, 7(4), 409–427.
  Recommended readings

  Adami, M. (2023, March 23). Is ChatGPT a threat or an opportunity for journalism? Five AI experts weigh in. Reuters Institute for the Study of Journalism. https://reutersinstitute.politics.ox.ac.uk/news/chatgpt-threat-or-opportunity-journalism-five-ai-experts-weighLinks to an external site.
  Amankwah-Amoah, J., Abdalla, S., Mogaji, E., Elbanna, A., & Dwivedi, Y. K. (2024). The impending disruption of creative industries by generative AI: Opportunities, challenges, and research agenda. International Journal of Information Management, 79, Article 102759.
  Benjamin, W. (1969). The work of art in the age of mechanical reproduction (H. Zohn, Trans.). In H. Arendt (Ed.), Illuminations: Essays and reflections (pp. 217–252). Schocken Books. (Original work published 1935)
  Bolter, J. D. (2023). AI generative art as algorithmic remediation. In: IMAGE. Zeitschrift für interdisziplinäre Bildwissenschaft. Generative Imagery: Towards a ‘New Paradigm’ of Machine Learning-Based Image Production, Jg. 19 (2023), Nr. 1, S. 195–207.
  Broussard, M., Diakopoulos, N., Guzman, A. L., Abebe, R., Dupagne, M., & Chuan, C.-H. (2019). Artificial intelligence and journalism. Journalism & Mass Communication Quarterly, 96(3), 673–695.
  Celis Bueno, C., Chow, P.-S., & Popowicz, A. (2024). Not “what”, but “where is creativity?”: Towards a relational-materialist approach to generative AI. AI & Society, 40, 339–351.
  Chow, P.-S., & Celis Bueno, C. O. (2025). The cloak of creativity: AI imaginaries and creative labour in media production. European Journal of Cultural Studies. OnlineFirst.
  Du Sautoy, M. (2019). The creativity code: Art and innovation in the age of AI. Belknap Press.
  Elgammal, A. (2019). AI is blurring the definition of artist. American Scientist, 107(1), 18–21. https://www.americanscientist.org/article/AI-is-blurring-the-definition-of-artistLinks to an external site.  
  Floridi, L., & Chiriatti, M. (2020). GPT-3: Its nature, scope, limits, and consequences. Minds & Machines, 30, 681–694.
  Hayles, N. K. (2014). Cognition everywhere: The rise of the cognitive nonconscious and the costs of consciousness. New Literary History, 45(2), 199–220.
  Hertzmann, A. (2018). Can computers create art? Arts, 7(2), 18.
  Manovich, L. (2019). AI aesthetics. Strelka Press. https://manovich.net/index.php/projects/ai-aestheticsLinks to an external site.
  Öztaş, Y. E., & Arda, B. (2025). Re-evaluating creative labor in the age of artificial intelligence: A qualitative case study of creative workers’ perspectives on technological transformation in creative industries. AI & Society, 40, 4119–4130.
  Zhou, E., & Lee, D. (2024). Generative artificial intelligence, human creativity, and art. PNAS Nexus, 3(3), Article pgae052.
## Week 6 AI, Relationship, and Intimacy
  Compulsory readings

  Jamieson, L. (2013). Personal relationships, intimacy and the self in a mediated and global digital age. In K. Orton-Johnson & N. Prior (Eds.), Digital sociology: Critical perspectives (pp. 13–33). Palgrave Macmillan.
  Turkle, S. (2011). Authenticity in the age of digital companions. In M. Anderson & S. L. Anderson (Eds.), Machine ethics (pp. 62–76). Cambridge University Press.
  Recommended readings

  Asma, S. T. (2020, March 10). Opinion: Our intimacy with technology may enhance humanity. Undark. https://undark.org/2020/03/10/modern-technology-intimacy/Links to an external site.
  Brandtzaeg, P. B., Skjuve, M., & Følstad, A. (2022). My AI friend: How users of a social chatbot understand their human–AI friendship. Human Communication Research, 48(3), 404–429.
  Brooks, R. (2021). Artificial intimacy: Virtual friends, digital lovers, and algorithmic matchmakers. Columbia University Press.
  Coeckelbergh, M. (2010). Moral appearances: Emotions, robots, and human morality. Ethics & Information Technology, 12, 235–241.
  Guzman, A. L., & Lewis, S. C. (2020). Artificial intelligence and communication: A human-machine communication research agenda. New Media & Society, 22(1), 70–86.
  Ho, A., Hancock, J., & Miner, A. S. (2018). Psychological, relational, and emotional effects of self-disclosure after conversations with a chatbot. Journal of Communication, 68(4), 712–733.
  Illouz, E. (2019). The end of love: A sociology of negative relations. Oxford University Press.
  Li, H., & Zhang, R. (2024). Finding love in algorithms: Deciphering the emotional contexts of close encounters with AI chatbots. Journal of Computer-Mediated Communication, 29(5), zmae015.
  Luger, E., & Sellen, A. (2016). “Like having a really bad PA”: The gulf between user expectation and experience of conversational agents. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (pp. 5286–5297). Association for Computing Machinery.
  Salles, A., Evers, K., & Farisco, M. (2020). Anthropomorphism in AI. AJOB Neuroscience, 11(2), 88–95.
  Shank, D. B., Koike, M., & Loughnan, S. (2025). Artificial intimacy: Ethical issues of AI romance. Trends in Cognitive Sciences, 29(6), 499–501.
  Skjuve, M., Følstad, A., Fostervold, K. I., & Brandtzaeg, P. B. (2021). My chatbot companion: A study of human-chatbot relationships. International Journal of Human-Computer Studies, 149, 102601.
  Turkle, S. (2011). Alone together: Why we expect more from technology and less from each other. Basic Books. [especially Chapter 6: Love’s Labor Lost & Chapter 8: Always On]
  Classical texts on intimacy and social relationships

  Giddens, A. (1992). The transformation of intimacy: Sexuality, love, and eroticism in modern societies. Polity
  Horton, D., & Wohl, R. R. (1956). Mass communication and parasocial interaction: Observations on intimacy at a distance. Psychiatry, 19(3), 215–229.
  Hochschild, A. R. (1983). The managed heart: Commercialization of human feeling. University of California Press.
  Illouz, E. (2007). Cold intimacies: The making of emotional capitalism. Polity.
  Jamieson, L. (1998). Intimacy: Personal relationships in modern societies. Polity.
## Week 7 AI and Surveillance
  The politics of AI-driven surveillance
  Facial recognition, predictive policing, and algorithmic governance
  Ethical and regulatory challenges
## Week 8 Biases and Inequalities
  How AI reproduces and amplifies social, cultural, racial, and economic biases
  Case studies of AI-driven algorithmic discrimination in media and technology
## Week 9 Deepfakes, Synthetic Media, and Disinformation
  Propagative ill-informed practices
  Ethical issues and personal, social harms
## Week 10 Materiality of AI and Sustainability
  The impact of AI on environment
  Extraction of natural resources and colonisation of international trade
## Week 12 AI Ethics, Regulations, and Governance
  Global AI governance debates and media regulation
  Ethical frameworks and policy responses to AI’s impact
## Week 13 Futures of AI
  What kind of AI do we want - human-centred AI vs. a post-human future?
## Assessment components
  20%	 
  Essays

  25%	AI Reflective Essay: Over 7 consecutive days, students will write a diary that records how their chosen AI system mediates the information access, social interactions, daily routines, work practices, or other aspects of everyday life. They will do so by documenting and analysing their personal interaction with one specific AI mediated system (e.g. a social media recommendation system, generative AI tool, virtual assistant, targeted advertising system, AI translation, photo enhancement app, or facial recognition). Students will also reflect on the wider social, ethical, and political implications of your observations.
  Project/Group Project

  35%	In groups, students will focus on a specific application of AI, e.g. inequalities in the AI and algorithmic era; mapping AI labour chains; AI deepfakes and democratic erosion; AI and creative or cultural production; AI and surveillance; AI and sustainability; AI futures and policy visions. The output will be a critical explanatory report (3,000 words) plus one creative piece (e.g. a short video clip, a podcast episode, digital storytelling, an infographic or data visualisation, a fictional policy or corporate brochure, a performance, or an interactive webpage) designed to communicate the gist of the report in a publicly intelligible way. Students are expected to address both the technical possibilities of the chosen AI application and its impacts on local society, and to discuss any relevant controversies as well as ethical and or legal issues.
  Quizzes/Tests

  0%	 
  Laboratory Tests

  0%	 
  Mid-term Test

  0%	 
  Others 1 (if applicable & describe in notes)

  20%	Reading presentation: From Weeks 5 to 12, students will present in pairs (or groups) on one of the set readings each week. Readings will be assigned randomly and shared two weeks in advance to ensure that all students, whether presenting in Week 5 or Week 12, have the same amount of time to prepare. Their presentation will last up to 20 minutes, and each student must present the parts of the discussion they specifically worked on, so that individual contributions are clear within a jointly prepared presentation. You will provide: (a) a brief overview of the reading’s main points, key concepts (where relevant), and major takeaways; and (b) a critical discussion of the reading, including its strengths, limitations, and your analytical evaluation (e.g. what the reading explains well, what it overlooks or simplifies, and how empirically useful (or not) you find it).
  Others 2 (if applicable & describe in notes)

  0%	 
  Others 3 (if applicable & describe in notes)

  0%	 
  Final Exam

  0%	 
  Teaching mode
  The teaching methods outlined are subject to the discretion of the course instructor. Please consult your course instructor if you have any questions regarding how the course will be conducted.
