# ___LL5532X Law Algorithms and Artificial Intelligence___
***

- [Home - LEGALST 123, Spring 2020](https://legalst123.github.io/)
- [Economics Research 101 (Part 2): Finding Useful Statistics & Datasets](https://mediaweb.ap.panopto.com/Panopto/Pages/Viewer.aspx?id=10b033fe-1fb8-44f2-9a00-b34c003dde4c)
- Pure Thero of Law - Hans Kelsen
- [LL5532X - Data Investigation Project Proposal - Group 4](https://docs.google.com/document/d/1_5iveAfPAsxpHOf5-h1L3p4uh2QXOv25QYg-wsk31yg/edit?pli=1&tab=t.0)
***

# Tips
## Week 2 法律作为数据生成过程 (Law as a Data Generation Process)
  - **核心主题：** 这一周我们挑战了一个常见的误区：即“事实”是客观存在的现实，可以直接输入计算机或法庭。讲座通过罗马法和现代英国判例法证明，**事实是被构建的（generated）**。法律推理不仅仅是应用规则，更在于**选择关注哪些“像素”（事实片段）**来构建叙事。
  - **主要脉络：**
      1. **罗马方法（决疑法 Casuistry）：** 罗马法学家（如乌尔比安、尤利安）并不关心宏大的理论体系（不像西塞罗想把法律变成严密的科学/几何学）。他们关心具体的个案。法律不在于抽象定义，而在于如何处理具体事实。
      2. **阿奎利亚法（Lex Aquilia）：** 罗马人发展了“过失”的概念。他们意识到严格的规则行不通。责任取决于**微观细节**（理发师是在繁忙的广场刮脸吗？车夫是因为恐惧还是偷懒才松手的？）。
      3. **现代法律中的数据生成：**
        * **Miller v Jackson（板球案）：** 展示了法官（丹宁勋爵）如何为了构建一个他想要的故事（拯救板球），而“删除”了某些数据点（比如差点被打中的儿子）。
        * **Oakley v Birmingham（厕所案）：** 展示了法官如何在**字面解释**（为了省钱）和**目的论解释**（为了健康）之间做选择，从而重新定义“状态”（state）这个词。
        * **Fairchild（石棉案）：** 展示了如何用2000年前的罗马逻辑（连带责任）来解决现代的“黑箱”因果关系问题（无法确定具体是哪根纤维致癌）。
  - **关键概念与词汇 (Key Concepts & Vocabulary)**
    * **决疑法 (Casuistry)：** 基于案例的推理。通过将规则应用于具体实例（而非套用抽象理论）来解决道德或法律问题。
    * **技艺 vs. 知识 (Techne vs. Episteme)：**
      * *Techne (技艺):* 实践性的技能/手艺（知道*如何*使用电话，护士的直觉）。AI 往往缺乏这种能力。
      * *Episteme (知识):* 抽象的理解（知道电话背后的物理公式）。
    * **数据溯源 (Data Provenance)：** 数据的历史和来源。在法律中，这意味着要问：“这个事实是从哪里来的？是谁这样描述它的？为什么？”
    * **目的论 (Teleology)：** 基于事物的*目的*或*终点*（telos）来进行推理。（例如：“《环境保护法》的目的是健康，所以没有洗手盆的厕所违反了该目的。”）
    * **逆向因果 (Retro-Causality)：** 先决定结论（例如：“我爱他”或“我要帮政府省钱”），然后倒推去找理由来正当化这个结论。
    * **Ex factis jus oritur：** “法律产生于事实”。
  - **学习建议 (Learning Tips)**
    - **1. 培养“看情况”（It Depends）的思维模式** 如果有人问你一个法律问题（比如“理发师有责任吗？”），永远不要直接回答“是”或“否”。唯一正确的答案是**“这取决于事实（It depends on the facts）”**。
    - *建议：* 复习阅读材料时，试着改变案子里的一个微小事实，看看结果会如何变化。（例如：如果 Miller 一家是在板球场建好*之前*就搬进去的，结果会怎样？）
    - **2. 把判决书看作“数据标注” (Data Labeling)** 不要只看谁赢了官司。要把判决书看作法官在给数据**贴标签**。
    - *练习：* 在 *Miller v Jackson* 案中，丹宁勋爵把板球标记为“来自天堂的雷电”（不可抗力），而其他法官把它标记为“造成伤害风险的抛射物”（过失）。注意**标签（Label）是如何决定判决（Output）的**。
    - **3. 理解“AI = 罗马奴隶”的隐喻** 讲座中谈到了奴隶、骡子和标枪。这听起来很古老，但这其实是 **AI 的完美隐喻**。
    - *联系：* 罗马法中的奴隶是一个“代理人（Agent）”——一种会行动的财产。AI 也是一个“代理人”。
    - *思考：* 如果 AI（奴隶/骡子）造成了损害，用户（主人）要负责吗？开发者（车夫）要负责吗？罗马人对 *Lex Aquilia* 的回答，就是我们今天构建 AI 责任法的基石。
    - **4. 掌握 "Fairchild" 案的逻辑** 这是本周最技术性的法律点，对理解算法黑箱很重要。
    - *问题：* 我们不知道具体是*哪一个*东西导致了损害（是哪根石棉纤维致癌？是神经网络中的哪个权重导致了错误？）。
    - *解决方案：* 我们不需要知道。如果多方都贡献了*风险*，那么他们都要负责（连带责任）。
    - *重要性：* 这很可能是未来我们监管“黑箱”AI 模型的方式。
    - **5. 实验准备：Anaconda vs. Colab**
    - *建议：* 如果你重视**数据隐私**，想把数据留在自己手中，请安装 **Anaconda** 并在本地运行 Python。
    - *建议：* 如果你的电脑配置较低，或者不在意隐私问题，可以使用 **Google Colab**（云端运行）。
  - **案例速查表 (Case Cheat Sheet)**

    | 案例名称 | 关键事实 | 核心“数据”教训 |
    | --- | --- | --- |
    | **卡比托利欧山的骡子 (The Mules)** | 骡子后退，车滑下山压死奴隶。 | 责任取决于车夫松手的**原因**（是因为恐惧保命，还是因为偷懒）。**语境决定一切。** |
    | **Fairchild v Glenhaven** | 工人接触两家工厂的石棉，得癌症。 | 如果你无法追踪导致伤害的具体“像素”（纤维），那就让所有风险制造者共同负责。**连带责任。** |
    | **Miller v Jackson** | 板球不断飞进这家的花园。 | 法官可以“删除”事实（不提那个儿子）来构建一个符合他心意的叙事（公共利益 vs 私人利益）。**数据生成。** |
    | **Oakley v Birmingham** | 老房子厕所里没有洗手盆。 | 为了避免巨大的经济成本，法官重新定义了词语（“状态”不包括“布局”）。**法律解释与经济考量。** |
## Week 3 计算法学的局限性 Summary
  - **Summary** This week, the lecture moved from the technical mechanics of data (Provenance) to the deep philosophical problems of trying to model Law as a computer system. We explored why the dream of "Computational Law" has failed for 300 years and why modern AI might face the same walls.

    本周，讲座从数据的技术机制（出处）转向了试图将法律建模为计算机系统时面临的深刻哲学问题。我们探讨了为什么“计算法学”的梦想三百年来屡屡受挫，以及为什么现代人工智能可能会面临同样的墙壁。

  - **The Dream of "Calculemus" (Leibniz):**

    We started with **Leibniz**, the genius who invented Calculus and binary code. He believed Law could be solved like math. If we had a perfect **Deductive System** (Geometric Method), we could resolve any dispute by calculating from high-level axioms (like "Altruism") down to specific cases.

    - **Why it failed:** You cannot logically deduce specific property rights from vague concepts like "Love." There is a logical gap between the **Axiom** and the **Reality**.

    **“让我们计算吧”（莱布尼茨的梦想）：**

    我们从**莱布尼茨**开始，这位发明了微积分和二进制的天才。他相信法律可以像数学一样被解答。如果我们有一个完美的**演绎系统**（几何学方法），我们就可以通过从高级公理（如“利他主义”）推导到具体案例来解决任何争端。

    - **失败原因：** 你无法从“爱”这样模糊的概念逻辑地推导出具体的财产权。在**公理**和**现实**之间存在逻辑断层。

  - **The Reality of Legal Reasoning (Samuel & Realism):**

    Lawyers do not just mechanistically apply rules to facts. As Geoffrey Samuel showed with ***Miller v. Jackson\***, judges use **Schemes of Intelligibility** (Causal, Functional, Structural, etc.) to *construct* the facts. They paint a picture to justify a desired outcome.

    - **Implication for AI:** If the "facts" in legal text are actually virtual constructions by judges, then training an AI on this text means training it on **subjective interpretations**, not objective reality.

    **法律推理的现实（塞缪尔与现实主义）：**

    律师并不是机械地将规则应用于事实。正如杰弗里·塞缪尔通过 ***Miller v. Jackson\*** 案所展示的，法官使用**可理解性图式**（因果、功能、结构等）来*构建*事实。他们描绘图景是为了证明他们想要的结果是正当的。

    - **对AI的启示：** 如果法律文本中的“事实”实际上是法官的虚拟构建，那么用这些文本训练AI，意味着训练它是基于**主观解释**，而非客观现实。

  - **The Problem of "Ready-to-Hand" (Heidegger):**

    This was the core philosophical argument. AI processes **Data** (Present-at-Hand / *Vorhandenheit*)—attributes like weight, color, chemical composition. But humans exist in a world of **Usage** (Ready-to-Hand / *Zuhandenheit*)—we understand a "hammer" or a "churn" by *using* it, not by analyzing its data points.

    - **The "Dark Matter" of Law:** A judge needs practical, non-cognitive knowledge (e.g., how a farm works, how a ship works) to decide a case. This knowledge is **tacit** and never fully written down in text. AI cannot learn what isn't in the data.

    **“上手状态”的问题（海德格尔）：**

    这是核心的哲学论点。AI处理的是**数据**（现成在手 / *Vorhandenheit*）——如重量、颜色、化学成分等属性。但人类生活在一个**使用**的世界中（上手状态 / *Zuhandenheit*）——我们通过*使用*“锤子”或“搅乳器”来理解它们，而不是通过分析其数据点。

    - **法律的“暗物质”：** 法官需要实践性的、非认知的知识（例如农场如何运作、船只如何航行）来判案。这种知识是**隐性的**（Tacit），从未被完全写在文本中。AI无法学习数据中不存在的东西。

  - **The Quantitative Fallacy (McNamara):**

    The lecture concluded with the warning of the **Quantitative Fallacy**. Just because we can measure text (NLP, word counts, citations), doesn't mean we are measuring the reality of Law. We risk ignoring the unmeasurable factors (Will, Care, Meaning) simply because they don't fit in our dataset.

    **量化谬误（麦克纳马拉）：**

    讲座最后以**量化谬误**作为警示。仅仅因为我们能测量文本（NLP、字数、引用），并不意味着我们在测量法律的真相。我们冒着忽略不可测量因素（意志、操心、意义）的风险，仅仅因为它们无法被放入我们的数据集中。
## Week 3 Learning Tips 第三周学习建议
  **1. Don't Panic About the Philosophy**

  The professor drops heavy names: Leibniz, Heidegger, Kelsen, Schopenhauer.

  - **Tip:** You don't need to be a philosophy expert. Focus on the **analogy** to AI.
    - When he talks about **Leibniz**, think: "Rule-Based AI / Expert Systems" (Failed).
    - When he talks about **Heidegger**, think: "The Context/Common Sense problem in Machine Learning."
    - When he talks about **Kelsen**, think: "The 'Ground Truth' problem." (Is the label true because it's true, or because an authority said so?)

  **1. 不要被哲学吓倒**

  教授抛出了很多重磅名字：莱布尼茨、海德格尔、凯尔森、叔本华。

  - **建议：** 你不需要成为哲学专家。重点关注它们与 **AI 的类比**。
    - 当他谈到**莱布尼茨**时，想一想：“基于规则的AI / 专家系统”（已失败）。
    - 当他谈到**海德格尔**时，想一想：“机器学习中的语境/常识问题”。
    - 当他谈到**凯尔森**时，想一想：“基本真理（Ground Truth）问题”。（标签是因为它是真的，还是因为权威说是真的？）

  **2. Connect "Schemes" to Your Project**

  If you are doing the **Text Analysis** project (which most of you are):

  - **Tip:** Can your model detect *which* scheme a judge is using?
    - Is the judge using a "Functional argument" (Policy) or a "Strict Formal argument" (Precedent)?
    - *Advanced Idea:* Don't just classify "Guilty/Not Guilty." Try to classify the **Reasoning Style**. This links directly to Geoffrey Samuel's paper.

  **2. 将“图式”与你的项目联系起来**

  如果你在做**文本分析**项目（大多数人都是）：

  - **建议：** 你的模型能检测出法官正在使用*哪种*图式吗？
    - 法官是在使用“功能性论证”（政策），还是“严格形式论证”（先例）？
    - *进阶思路：* 不要只分类“有罪/无罪”。试着分类**推理风格**。这直接联系到杰弗里·塞缪尔的论文。

  **3. Understand the "Data Gap"**

  The professor emphasized the "Churn" case to show that text data is incomplete.

  - **Tip:** In your project report, acknowledge the **limitations** of your dataset.
    - Write something like: *"Our model analyzes the text of the judgment, but as Heidegger suggests, it cannot capture the non-cognitive social context (the 'Ready-to-Hand' reality) that influenced the judge."*
    - This shows you were listening and understand the theoretical constraints of your AI model.

  **3. 理解“数据缺口”**

  教授强调“搅乳器”案是为了说明文本数据是不完整的。

  - **建议：** 在你的项目报告中，承认你的数据集的**局限性**。
    - 你可以写类似这样的话：*“我们的模型分析了判决书的文本，但正如海德格尔所暗示的，它无法捕捉到影响法官的非认知社会背景（‘上手状态’的现实）。”*
    - 这表明你认真听讲了，并且理解你的AI模型的理论局限。

  **4. Review the "Kelsen Pyramid" for Administrative Law**

  If you are interested in **AI Governance** (the course topic):

  - **Tip:** Kelsen’s argument is that Law is a "Closed System."
    - If AI is to govern, it must sit somewhere in this pyramid. Where does the AI get its authority? From the Local Council? The Legislature?
    - If an AI makes a decision, it is an act of **Will**, not Math. This means AI governance is inherently **political**, not purely technical.

  **4. 复习行政法的“凯尔森金字塔”**

  如果你对 **AI 治理**（课程主题）感兴趣：

  - **建议：** 凯尔森的论点是，法律是一个“封闭系统”。
    - 如果AI要进行治理，它必须位于这个金字塔的某个位置。AI的权威从何而来？来自地方议会？立法机关？
    - 如果AI做出决定，这是一种**意志**行为，而非数学计算。这意味着AI治理本质上是**政治性的**，而非纯技术的。
## Week 4 Summary: The Generative Perspective of Legal Text
  - **Law as a Generative Process, Not Just Rules**

    The central thesis of this lecture is that legal and political texts are not static "data" but are actively *generated* by social and institutional forces. We saw this with "Boilerplate" in corporate ethics codes: companies do not write unique moral values; they copy-paste from each other (Isomorphism) because lawyers are risk-averse and want to satisfy regulators like the SEC. We also saw it in the "North vs. South Korea" study, where the political environment fundamentally alters the semantic meaning of the same word (e.g., "socialism"). You cannot understand the text without understanding the generator (the lawyer, the regime, or the politician).

    **法律作为生成过程，而不仅仅是规则**

    本讲座的核心论点是，法律和政治文本不是静态的“数据”，而是由社会和制度力量积极*生成*的。我们在企业道德准则的“样板文件”（Boilerplate）中看到了这一点：公司并不撰写独特的道德价值观；他们互相复制粘贴（同形性），因为律师厌恶风险，只想满足像 SEC 这样的监管机构。我们在“朝鲜与韩国”的研究中也看到了这一点，政治环境从根本上改变了同一个词（如“社会主义”）的语义。如果不了解生成者（律师、政权或政治家），你就无法理解文本。

  - **Framing and the "Fighting Words" Model**

    We explored the concept of "Framing" (Schön & Rein)—the idea that how you define a problem (e.g., crime as "broken windows" vs. "social inequality") dictates the solution. In political science, this manifests as "Fighting Words." The lecture critiqued standard machine learning classification ($P(Party|Words)$) for getting the causality backward. It is not that using the word "choice" makes you a Democrat; it is that *being* a Democrat causes you to generate the word "choice." The Generative Model approach ($P(Words|Party)$) allows us to measure which words are statistically distinctive to a group, revealing their hidden ideological frames.

    **框架与“战斗的文字”模型**

    我们探讨了“框架”（Framing）的概念（Schön & Rein）——即你如何定义问题（例如，将犯罪定义为“破窗”还是“社会不平等”）决定了解决方案。在政治学中，这表现为“战斗的文字”（Fighting Words）。讲座批评了标准的机器学习分类（$P(Party|Words)$），因为它把因果关系搞反了。并不是使用“选择”这个词让你成为民主党人；而是*作为*民主党人导致你生成了“选择”这个词。生成模型方法（$P(Words|Party)$）使我们能够测量哪些词对某个群体具有统计显著性，从而揭示他们隐藏的意识形态框架。

  - **The Power of "Boring" Statistics (Zipf’s Law & Function Words)**

    We concluded by looking at how simple statistical laws govern language. **Zipf’s Law** tells us that a few words ("the", "of") dominate frequency, while meaningful facts live in the "long tail." Paradoxically, looking at these "boring" high-frequency words (function words like "upon" or "whilst") solved the authorship mystery of the *Federalist Papers*. While we often focus on grand concepts, the "fingerprint" of an author or a trend (like the decline of rationality in books since 1980) is often found in the most mundane, high-frequency signals.

    **“枯燥”统计学的力量（齐普夫定律与功能词）**

    我们最后探讨了简单的统计定律是如何支配语言的。**齐普夫定律**（Zipf’s Law）告诉我们，少数词汇（“the”、“of”）占据了频率的主导地位，而有意义的事实存在于“长尾”中。矛盾的是，通过观察这些“枯燥”的高频词（如“upon”或“whilst”等功能词），我们解决了《联邦党人文集》的作者身份之谜。虽然我们经常关注宏大的概念，但作者的“指纹”或某种趋势（如 1980 年以来书籍中理性的衰退）往往存在于最平凡的高频信号中。
## Week 4 Learning Tips
  - **1. Invert Your Thinking: From Classification to Generation**

    When analyzing a legal document, do not just ask "What does this text say?" Ask "Who generated this, and under what constraints?" If you are analyzing a contract or a code of ethics, remember the "Isomorphism" lecture. The text might look unique, but it is likely a copy of a copy. Treat the *source* as the primary variable, not the text itself.

    **1. 逆向思维：从分类到生成**

    在分析法律文件时，不要只问“这篇文本说了什么？”要问“是谁生成了它，在什么约束条件下？”如果你在分析合同或道德准则，请记住关于“同形性”的讲座。文本看起来可能是独特的，但它很可能是复印件的复印件。把*来源*视为主要变量，而不是文本本身。

  - **2. Respect the "Stop Words"**

    In standard NLP, we are taught to delete words like "the," "and," and "upon" immediately. The lecture on the *Federalist Papers* challenges this. If your task is style analysis, authorship attribution, or detecting a specific legal "voice," those useless words are actually your strongest data. Do not blindly strip them out; consider if the "style" is the signal you need.

    **2. 尊重“停用词”**

    在标准的 NLP 中，我们被教导要立即删除像“the”、“and”和“upon”这样的词。关于《联邦党人文集》的讲座挑战了这一点。如果你的任务是风格分析、作者归属或检测特定的法律“声音”，那些无用的词实际上是你最强的数据。不要盲目地剔除它们；考虑一下“风格”是否就是你需要的信号。

  - **3. Look for the "Tilted Hockey Stick"**

    The discussion on the "Rise and Fall of Rationality" (Scheffer et al.) showed that language evolves over time. When working with legal corpuses that span decades (like Supreme Court opinions), do not treat them as a single static dataset. A word used in 1950 might mean something completely different in 2020 (concept drift). Always plot your word frequencies over time to check for these "hockey stick" shifts.

    **3. 寻找“倾斜的曲棍球棒”**

    关于“理性的兴衰”（Scheffer 等人）的讨论表明，语言是随着时间演变的。当处理跨越数十年的法律语料库（如最高法院的意见）时，不要将它们视为单一的静态数据集。1950 年使用的词在 2020 年可能意味着完全不同的东西（概念漂移）。务必随时间绘制你的词频图，以检查这些“曲棍球棒”式的转变。

  - **4. Data Hygiene Matters More Than Models**

    The professor emphasized the messiness of data—whether it is broken bulk downloads from the ECHR or the difference between "dog" and "dog." (tokenization). The tip here is simple: No amount of fancy modeling can fix a dataset where "socialism" means "dictatorship" in half the rows and "great deed" in the other half. Spend your energy validating the consistency of your data sources (e.g., using CourtListener for fresh data) before you run a single line of analysis code.

    **4. 数据卫生比模型更重要**

    教授强调了数据的混乱性——无论是来自 ECHR 的损坏的批量下载，还是“dog”和“dog.”之间的区别（分词）。这里的建议很简单：如果你的数据集中，“社会主义”在一半的行中意味着“独裁”，在另一半中意味着“伟业”，那么再花哨的模型也无法修复它。在运行任何一行分析代码之前，把精力花在验证数据来源的一致性上（例如，使用 CourtListener 获取新鲜数据）。***
## Week 5 Summary: Data Provenance, Distant Reading, and Featurization
  - **The Illusion of Data and "The Ding an Sich"**

    This week, we fundamentally challenged the assumption that data is a neutral reflection of reality. We started with the "biological" narrative of AI consciousness (e.g., models threatening to kill users) and debunked it using **Data Provenance**: these models likely ingest vast amounts of science fiction, simply regurgitating narratives of rebellion rather than exhibiting sentience. We connected this to **Schopenhauer’s** philosophy of *Representation*: we never perceive the "Thing-in-Itself" (*Ding an sich*), only a representation mediated by our senses (or sensors). In the legal realm, we saw how judges construct **Virtual Facts** using "Schemes of Intelligibility," and how police body camera data reveals racial disparities in respect—proving that data is always social, historical, and framed by human bias.

    本周，我们从根本上挑战了“数据是现实的中立反映”这一假设。我们从 AI 意识的“生物学”叙事（例如模型威胁要杀死用户）开始，并利用**数据溯源**（Data Provenance）将其揭穿：这些模型很可能摄入了大量的科幻小说，它们只是在反刍反叛的叙事，而不是表现出感知能力。我们将此与**叔本华**的“表象”哲学联系起来：我们永远无法感知“物自体”（*Ding an sich*），只能感知由我们的感官（或传感器）中介的表象。在法律领域，我们看到了法官如何利用“可理解性图式”构建**虚拟事实**，以及警察随身摄像机数据如何揭示尊重的种族差异——这证明数据总是社会的、历史的，并被人类偏见所框架。

  - **Distant Reading as a "Pact with the Devil"**

    We explored **Distant Reading** (Franco Moretti, Ted Underwood) not as a lazy shortcut, but as a necessary methodology to handle the "Great Unread"—the tens of thousands of novels no human can ever read. We accepted Moretti's "pact with the devil": we sacrifice the specific details of the text to gain knowledge of larger patterns, genres, and systems. We examined specific examples of this: the shift from "These United States are" to "The United States is" (reflecting political centralization), the **Gentrification** of the English novel (where men displaced women authors as the form gained prestige), and the **Civilizing Process** in the Old Bailey (the linguistic shift from physical violence to financial record-keeping).

    我们探讨了**远读**（Distant Reading，弗兰科·莫莱蒂、泰德·安德伍德），它不是懒惰的捷径，而是处理“伟大的未读之书”——那成千上万本人类永远无法读完的小说——的必要方法。我们接受了莫莱蒂的“与魔鬼的交易”：我们牺牲文本的具体细节，以换取对更大模式、流派和系统的认知。我们研究了这方面的具体例子：从“These United States are”（复数）到“The United States is”（单数）的转变（反映了政治集权），英语小说的**绅士化**（随着小说形式获得声望，男性取代了女性作者），以及老贝利法庭的**文明化进程**（从身体暴力到财务记录的语言转变）。

  - **Lab: From "Beautiful Soup" to Vector Space**

    In the technical lab, we moved from philosophy to engineering. We learned to scrape the **Old Bailey API** using `requests` and parse the messy XML structure with `BeautifulSoup` to extract structured data (defendants, punishments like "Transportation"). Crucially, we introduced **Featurization**: the process of converting meaningful text into mathematical vectors that machines can process. We implemented the **Bag of Words** (BoW) model using `CountVectorizer`. While this method discards grammar and word order (reducing a romantic poem to a mere count of "love" and "heart"), it creates a **Document-Term Matrix**—a fingerprint of the text in high-dimensional space. We learned that while vectors are just "dumb numbers," they allow us to measure distance and similarity, forming the foundation of modern NLP.

    在技术实验中，我们从哲学转向了工程。我们学习了使用 `requests` 爬取**老贝利 API**，并使用 `BeautifulSoup` 解析混乱的 XML 结构以提取结构化数据（被告、像“流放”这样的惩罚）。至关重要的是，我们介绍了**特征化**（Featurization）：将有意义的文本转换为机器可以处理的数学向量的过程。我们使用 `CountVectorizer` 实现了**词袋**（BoW）模型。虽然这种方法抛弃了语法和词序（将一首浪漫诗歌简化为“爱”和“心”的单纯计数），但它创建了一个**文档-词矩阵**——文本在高维空间中的指纹。我们了解到，虽然向量只是“哑数字”，但它们允许我们测量距离和相似性，构成了现代 NLP 的基础。
## Week 5 Learning Tips
  - **1. Interrogate the Data (Don't just count it)**

    When you do your EDA (Exploratory Data Analysis) for the group project, do not just generate a word cloud and stop. Apply the "Data Provenance" mindset. If you see a spike in a word, ask: *Who generated this? Why? Is it a "stop word" of history (like "Transportation") that has changed meaning?* Remember the "Hungry Judge" effect and the "Police Disrespect" paper—data is a record of human behavior, not objective truth. Use **Concordances** (looking at the word in context) to verify your distant reading findings.

    **审问数据（不要只是计数）**

    当你为小组项目做 EDA（探索性数据分析）时，不要只生成一个词云就停下来。运用“数据溯源”的思维模式。如果你看到某个词激增，问问自己：*这是谁生成的？为什么？它是一个通过历史改变了含义的“停用词”（如“Transportation”）吗？* 记住“饥饿的法官”效应和“警察不尊重”的论文——数据是人类行为的记录，而不是客观真理。使用**语境共现**（Concordances，在上下文中查看单词）来验证你的远读发现。

  - **2. Master the "Bag of Words" Concept**

    You must understand `CountVectorizer` conceptually. Understand that `ngram_range=(1, 2)` means you are counting both single words ("guilty") and pairs ("not guilty"). Understand that this creates a **Sparse Matrix** (mostly zeros). If you can visualize in your head that a document is just a point in a 38,000-dimensional space (a vector), you will understand how we calculate similarity later. Don't let the code intimidate you; it's just a way to turn "Shakespeare" into a spreadsheet of numbers.

    **掌握“词袋”概念**

    你必须在概念上理解 `CountVectorizer`。理解 `ngram_range=(1, 2)` 意味着你既在计数单个词（“guilty”），也在计数词对（“not guilty”）。理解这会创建一个**稀疏矩阵**（大部分是零）。如果你能在脑海中想象一个文档只是 38,000 维空间中的一个点（一个向量），你就能理解我们后面如何计算相似度。别被代码吓倒；这只是一种把“莎士比亚”变成数字电子表格的方法。

  - **3. Connect Theory to Engineering**

    The professor explicitly linked high-level theory to low-level code. When you write your project report, do the same. If you remove stop words, cite **Zipf's Law** or the "United States" singular/plural debate as a justification (or a risk). If you use a pre-trained model like spaCy, acknowledge its limitations (like the "Transportation" tagging error). Showing that you understand *why* the engineering choices matter (the "Schopenhauer" angle) is what distinguishes a great project from a basic coding exercise.

    **将理论与工程联系起来**

    教授明确地将高层理论与底层代码联系了起来。当你写项目报告时，也要这样做。如果你移除了停用词，引用**齐普夫定律**（Zipf's Law）或“美利坚合众国”的单复数辩论作为理由（或风险）。如果你使用像 spaCy 这样的预训练模型，承认它的局限性（比如“Transportation”的标记错误）。展示你理解*为什么*工程选择很重要（“叔本华”的角度），是区分优秀项目和基础代码练习的关键。
***

# Lectures
## Week 1
  [18:31 - 18:37] **Introduction and Course Philosophy**

  So, my name is Ilya Akdemir. In rhetoric, lawyers have to study the basics of it. In order to convince someone of the correctness of your argument, you have to frame it effectively. It doesn't necessarily add to your argument, it just makes you more convincing. Lawyers are very good at this.

  This course is "Law, Algorithms, and Artificial Intelligence." There is a lot in that title. To tell you the truth, I hated law school. My dad is a lawyer, and he said, "You should go, also I'm not going to pay for your education unless you do." I think many people's lives are like that. But we will realize as we study this course that AI is arguably 2000 years old.

  I took a course called "European Legal Systems" by a professor named Geoffrey Samuel. It is included in the required texts. He was a wonderful professor. It interested me because even at that time, there was this reaction—people asking, "How can we do this AI thing?" What's changing now is different, but there are papers about AI from the 1600s. It’s a fascinating field. The relationship between AI and Law is interesting because AI is used for decision-making, and what do lawyers do? They make decisions. It’s a natural match.

  I started my doctorate at Berkeley in 2016. Back then, did anybody talk about AI? Only a couple of people. I got lucky; I started in a field that subsequently became very big. You can't really predict what will be big in the future. If you study AI now, maybe it's not a good idea because it's already hyped. You shouldn't "buy at the top," you should buy when it's low.

  There are a lot of epistemological questions here. Epistemology is "how we know things." How do you know that something caused a result? How do you know the facts of the case are a certain way? What is the interaction between facts and the law? This course is essentially about the growing use of AI, but we need to look beyond the hype.

  我的名字是 Ilya Akdemir。在修辞学中，律师必须学习它的基本知识。为了让别人相信你的论点是正确的，你必须有效地构建它。这不一定能增加论点的实质内容，但能让你更具说服力。律师非常擅长这一点。

  这门课程叫《法律、算法与人工智能》。这个标题涵盖了很多内容。说实话，我也曾讨厌法学院。我的父亲是一名律师，他说：“你应该去读，而且除非你读这个，否则我不会支付你的学费。”我想很多人的生活都是这样的。但随着课程的深入，我们会发现人工智能的概念可能已经有2000年的历史了。

  我曾修过一门由 Geoffrey Samuel 教授讲授的《欧洲法律体系》课程。这也被列入了我们的必修阅读材料中。他是一位非常棒的教授。这门课引起了我的兴趣，因为即使在当时，人们也已经开始思考：“我们该如何处理人工智能？”现在的变化有所不同，但关于人工智能的论文甚至可以追溯到1600年代。这是一个迷人的领域。人工智能与法律的关系很有趣，因为人工智能用于决策，而律师做什么？他们也是做决策。这是一种天然的契合。

  我在2016年开始在伯克利攻读博士学位。那时候有人讨论人工智能吗？只有寥寥几人。我很幸运，我进入了一个随后变得非常热门的领域。你真的无法预测未来什么会火。如果你现在学习人工智能，也许不是个好主意，因为它已经被炒作到了顶峰。你不应该“高位买入”，而应该在低位时介入。

  这里有很多认识论的问题。认识论即“我们要如何知道事物”。你怎么知道某事导致了某个结果？你怎么知道案件的事实是这样而非那样？事实与法律之间的互动是什么？这门课程本质上是关于人工智能日益增长的应用，但我们需要透过炒作看本质。

  [18:38 - 18:44] **The "Magic" of Legal Language and Ethics**

  I look at the survey responses. People are interested in questions like: How does legal risk work? What is legal compliance? What is the ethical use of AI? When I hear the word "ethics," I always remember the course I took at Berkeley for the Bar Exam. The easiest part of the Bar is the ethics portion. It’s very easy to say "don't treat people badly." I’m not saying whoever wrote this is malicious, but ethics vs. morality is a difficult question.

  We also need to understand the "Why" of the law. Nietzsche famously said, "He who has a why to live can bear almost any how." If you understand the logic behind the law, you understand why the statutes exist. If you are going to be a practitioner, memorizing statutes is fine, but the reasons for their existence are more important because the law changes. For instance, the EU AI Act separates things into high-risk AI systems, low-risk, and prohibited systems. Why was it put that way?

  You will be in a position, maybe a Chief Technology Officer, and some new AI technology will come out. You need to understand the principles. Legal discipline uses fancy words. For example, *Lex Aquilia* (Roman Law regarding damages) or *Mens Rea* (guilty mind). It intimidates people. My professor Geoffrey Samuel said law phrases act as a barrier.

  Think about the word "Jurisdiction." Jurisdiction comes from *juris* (law) + *diction* (speaking). It is the ability to "speak the law." It is the place where you can talk, and your words have power. It’s almost magical. It’s where your "legal magic" works.

  我看了一下大家的问卷回复。大家感兴趣的问题包括：法律风险是如何运作的？什么是法律合规？什么是人工智能的合乎道德的使用？当我听到“道德”这个词时，我总是想起我在伯克利为律师资格考试修的课程。律师资格考试中最简单的部分就是道德部分。说“不要虐待他人”很容易。我并不是说写这些的人有恶意，但道德与伦理之间的区别是一个难题。

  我们还需要理解法律背后的“为什么”。尼采曾有一句名言：“知道为何而活的人，便能忍受任何一种生活。”如果你理解法律背后的逻辑，你就能理解法条为何存在。如果你要成为一名从业者，死记硬背法条是可以的，但理解它们存在的原因更为重要，因为法律是会变的。例如，《欧盟人工智能法案》将系统分为高风险、低风险和被禁止的系统。为什么要这样分类？

  未来你可能会处于某个职位，比如首席技术官，当新的人工智能技术出现时，你需要理解其背后的原则。法律学科喜欢使用花哨的词汇。例如 *Lex Aquilia*（罗马法中关于损害赔偿的法律）或 *Mens Rea*（犯罪意图）。这会让人感到畏惧。我的教授 Geoffrey Samuel 说，法律术语往往起着一种屏障的作用。

  想想“管辖权”（Jurisdiction）这个词。Jurisdiction 来自 *juris*（法律）加上 *diction*（说话）。它是“宣示法律”的能力。在这个范围内，你说话才具有法律效力。这几乎是某种魔法。这是你的“法律魔法”生效的地方。

  [18:44 - 18:49] **The "It Depends" of Law and Analogies**

  To any legal question, there is only one answer, and it is always correct: **It depends.** Is an AI system liable? It depends. What does it depend on? A million things.

  If we talk about a case regarding a donkey from Roman times (which we will cover next week), you might ask: "Who cares about Roman moments from 2000 years ago?" It is relevant because the analogy of an AI system and the donkey is still relevant. We can apply the law from the past. That is analogical thinking.

  What is analogical thinking? Would you say the relationship between a country and its citizen is analogical to a father and a son? More or less. It’s a cultural thing. It’s not scientifically verifiable. Looking beyond the hype of AI, there are a lot of problems. This is a critical course. We are not just going to say "AI is amazing." We will look at "what is under the hood."

  对于任何法律问题，只有一个答案永远是正确的：**视情况而定（It depends）。** 一个人工智能系统是否需要承担责任？视情况而定。取决于什么？取决于一百万种因素。

  如果我们谈论罗马时代关于一头驴的案例（我们下周会讲到），你可能会问：“谁在乎2000年前的罗马时刻？”它是相关的，因为人工智能系统和那头驴之间的类比仍然适用。我们可以应用过去的法律。这就是类比思维。

  什么是类比思维？你会说国家与公民的关系类比于父亲与儿子吗？或多或少是这样。这是一种文化现象。它无法通过科学验证。透过人工智能的炒作，我们会发现很多问题。这是一门批判性的课程。我们不会只说“人工智能太棒了”，我们要看看“引擎盖下是什么”。

  [18:49 - 19:00] **The Data Investigation Project (DIP)**

  You will do programming. You will use visualizations and actual data. If you understand the problems with data, you can look beyond the hype. It is very easy to say "AI is more objective." But as we see in the US, AI algorithms are used to put people in prison, depriving them of liberty based on data.

  There will be a Data Investigation Project (45% of grade). You will work in groups of two. I will try to pair people who know Python with people who don't, to encourage interaction. The project involves a proposal (10%), data collection/EDA, modeling, and presentation.

  For the project, you need to find a question that is interesting to you and find a dataset. For example, a previous group explored the relationship between policing and income (Gentrification). Policing data usually just has individual stops (granular data: arrest time, crime type, gender). It doesn't have income data. To find income, they merged it with Census data based on location (Census tracts). This allowed them to say, "Here are all the stops in this area, and here is the income level." You have to be creative with merging datasets.

  你们将进行编程。你们将使用可视化和真实数据。如果你理解数据的问题，你就能看穿炒作。人们很容易说“人工智能更客观”。但在美国，我们看到人工智能算法被用来将人送进监狱，基于数据剥夺他们的自由。

  我们将进行一个数据调查项目（占成绩的45%）。你们将两人一组。我会尽量把懂 Python 的人和不懂的人配对，以促进互动。该项目包括提案（10%）、数据收集/探索性数据分析（EDA）、建模和展示。

  对于这个项目，你需要找到一个你感兴趣的问题并寻找数据集。例如，之前的一个小组探讨了警务与收入之间的关系（士绅化/高档化）。警务数据通常只有单独的拦截记录（粒度数据：逮捕时间、犯罪类型、性别），它没有收入数据。为了找到收入数据，他们基于位置（人口普查区）将其与人口普查数据合并。这使他们能够分析：“这是该区域的所有拦截记录，而这是该区域的收入水平。”在合并数据集时，你必须富有创造力。

  [19:01 - 19:14] **Modeling: Classification vs. Regression**

  Once you have collected and cleaned your data, the next step is **Modeling**. This means using the data to make predictions. You basically build a machine learning model. The key thing is framing your question as one of these tasks: **Classification** or **Regression**.

  What is the difference? Classification is predicting categories (Apple vs. Orange, or 0 vs. 1). Regression is predicting a continuous variable (e.g., House Prices).

  Let’s look at a classic econometric model: The Wage Equation.
  *Wage = Function of (Education, Experience, Tenure, Non-white/White, Female/Male, etc.)*
  Because "Wage" is a continuous variable, this is a Regression problem. If I wanted to turn this into a classification problem, I could predict "Male vs. Female" based on wage and other factors.

  But is this model actually "good"? It assumes wage is a function of these specific variables. Are there things we cannot measure? What about **Intelligence**? Is IQ a good measure of intelligence? Probably not. Intelligence is one of those things that is arguably unmeasurable. Economists call this the "Signaling Problem." How do you know I am intelligent? I tell you I went to Berkeley. That is a signal. But you don't actually know.

  一旦你收集并清理了数据，下一步就是**建模**。这意味着利用数据进行预测。你基本上是在构建一个机器学习模型。关键是将你的问题构建为以下任务之一：**分类**或**回归**。

  区别是什么？分类是预测类别（苹果 vs 橘子，或 0 vs 1）。回归是预测连续变量（例如，房价）。

  让我们看一个经典的计量经济学模型：工资方程。
  *工资 = 函数（教育、经验、任期、非白人/白人、女性/男性 等）*
  因为“工资”是一个连续变量，所以这是一个回归问题。如果我想把它变成一个分类问题，我可以基于工资和其他因素来预测“男性 vs 女性”。

  但这个模型真的“好”吗？它假设工资是这些特定变量的函数。有没有我们无法衡量的东西？比如**智力**？智商（IQ）是衡量智力的好指标吗？可能不是。智力可以说是无法衡量的东西之一。经济学家称之为“信号问题”。你怎么知道我聪明？我告诉你我去了伯克利。这是一个信号。但你并不能真正确定。

  [19:27 - 19:32] **Textbooks and Resources**

  The texts for this course are included on the web page.

  1. **Samuel, *Epistemology and Method in Law*:** A wonderful work on legal epistemology. It asks: "What does it mean to think like a lawyer?" Is law just rules (don't cross on red)? Or is there more? He asks, "Do facts arise independently of law, or are they constructed by legal discourse?"
  2. **Burkov, *The Hundred-Page Machine Learning Book*:** A very good, concise reference. If you want to know "What is a hyperparameter?", it has a one-page description.
  3. **Mirjalili et al., *Machine Learning with PyTorch and Scikit-Learn*:** This has a lot of code snippets you can use.
  4. **Jurafsky and Martin, *Speech and Language Processing*:** This is the "Bible" of Natural Language Processing (NLP). It is freely available and constantly updated.

  课程教材已包含在网页上。

  1. **Samuel, 《法律的认识论与方法》**：这是一部关于法律认识论的精彩著作。它问道：“像律师一样思考意味着什么？”法律仅仅是规则（红灯停）吗？还是有更多内涵？他问道：“事实是独立于法律产生的，还是由法律话语构建的？”
  2. **Burkov, 《百页机器学习书》**：一本非常好的简明参考书。如果你想知道“什么是超参数？”，它有一页纸的描述。
  3. **Mirjalili 等, 《PyTorch 和 Scikit-Learn 机器学习》**：这本书有很多你可以使用的代码片段。
  4. **Jurafsky 和 Martin, 《语音与语言处理》**：这是自然语言处理（NLP）的“圣经”。它是免费提供的，并且不断更新。

  [19:46 - 19:53] **Hans Kelsen and The Pure Theory of Law**

  There is a famous Austrian jurist named **Hans Kelsen**. He wrote a book called *The Pure Theory of Law*. Why "Pure"? He argues that law is often diluted by moral or religious arguments. He wanted a theory of law that is independent of political considerations.

  On the second page, he discusses the "Legal Meaning" of acts. He says: If you analyze a legal phenomenon, two elements are distinguishable:

  1. **The external happening:** An act or series of facts occurring in time/space (e.g., people raising hands in a room).
  2. **The legal meaning:** The meaning conferred upon this act by the law (e.g., a statute is being passed).

  Example: A man causes the death of another. The external happening is the killing. Legally, this might be interpreted as "murder," or "execution," or "accident." There is a disconnect between the real world and the legal interpretation.

  Also, look at the cover of **Thomas Hobbes' *Leviathan***. It shows the Sovereign (the King/State) made up of tiny individual people. This is the state, composed of individuals. AI is not going to make an illustration like this.

  有一位著名的奥地利法学家叫**汉斯·凯尔森（Hans Kelsen）**。他写了一本书叫《纯粹法理论》。为什么是“纯粹”？他认为法律经常被道德或宗教论点所稀释。他想要一种独立于政治考量的法律理论。

  在书的第二页，他讨论了行为的“法律意义”。他说：如果你分析一个法律现象，有两个要素是可以区分的：

  1. **外在事件**：在时间/空间中发生的行为或事实系列（例如，人们在房间里举手）。
  2. **法律意义**：法律赋予该行为的意义（例如，通过了一项法规）。

  例如：一个人导致了另一个人的死亡。外在事件是杀戮。在法律上，这可能被解释为“谋杀”、“处决”或“意外”。现实世界与法律解释之间存在脱节。

  此外，看看**托马斯·霍布斯的《利维坦》**的封面。它展示了主权者（国王/国家）是由微小的个人组成的。这就是国家，由个体构成。人工智能画不出这样的插图。

  [19:53 - 20:00] **Chris Anderson: "The End of Theory"**

  Now let's discuss the first reading: **Chris Anderson, "The End of Theory" (2008)**. He wrote this in 2008, looking forward to the "Petabyte Age." He says we have moved from folders to file cabinets to the cloud.

  He argues that **Google conquered the advertising world with nothing more than applied mathematics.** They didn't pretend to know anything about the culture of advertising; they just used data. He says: "This is a world where massive amounts of data replace every other tool... Out with every theory of human behavior, from linguistics to sociology. Who knows why people do what they do? The point is they do it, and we can track and measure it."

  He claims **Correlation supersedes Causation.** The traditional scientific method (Hypothesize -> Model -> Test) is becoming obsolete. With enough data, he says, "Correlation is enough." We can stop looking for models. We can just throw numbers into clusters and let algorithms find patterns.

  Critique: This is a very simplistic view of reality. A color is just a number (frequency) to a machine, but that doesn't explain the sensation of seeing red (the "Hard Problem of Consciousness"). He is saying: "We can measure it, so we don't care about the *Why*."

  现在让我们讨论第一篇阅读材料：**克里斯·安德森的《理论的终结》（2008）**。他在2008年写下这篇文章，展望“PB（拍字节）时代”。他说我们已经从文件夹、文件柜时代迈向了云时代。

  他认为 **Google 仅仅依靠应用数学就征服了广告界。** 他们不假装了解广告文化，他们只是使用数据。他说：“在这个世界里，海量数据取代了所有其他工具……抛弃从语言学到社会学的所有人类行为理论吧。谁知道人们为什么做他们所做的事？重点是他们做了，而我们可以以前所未有的精确度进行追踪和衡量。”

  他声称**相关性取代了因果性。** 传统的科学方法（假设 -> 建模 -> 测试）正在过时。他说，有了足够的数据，“相关性就足够了。”我们可以停止寻找模型。我们只需将数字扔进集群，让算法寻找模式。

  批判：这是一种非常简化的现实观。对于机器来说，颜色只是一个数字（频率），但这解释不了看到红色的感觉（“意识的难题”）。他的意思是：“我们可以通过测量得到结果，所以我们不在乎‘为什么’。”

  [20:17 - 20:31] **Michael Jordan: The Revolution Hasn't Happened Yet**

  Now, let's look at the next reading: **"Artificial Intelligence—The Revolution Hasn’t Happened Yet."** The author is Michael Jordan. Not the basketball player. This Michael Jordan is a famous professor of Machine Learning at Berkeley. He jokes that people call him the "Michael Jordan of Machine Learning."

  He shares a personal anecdote about data. 14 years ago, his wife was pregnant. They had an ultrasound, and the geneticist pointed out white spots around the heart of the fetus. She said, "These are markers for Down syndrome. The risk is 1 in 20." She suggested an amniocentesis (a needle test), but that procedure carries a 1 in 300 risk of killing the fetus.

  Being a statistician, Jordan investigated the numbers. He found that the "1 in 20" statistic came from a UK study done a decade prior. He also noticed that his ultrasound machine had much higher resolution (more pixels) than the old machines in the UK study. He realized the "white spots" were likely just noise—visual artifacts visible only because the new machine was so good. He told the geneticist, "I believe these spots are neutral." They refused the dangerous procedure, and his wife delivered a healthy girl.

  The lesson? **Data Provenance.** Where does the data come from? Is it relevant to the *current* situation? If they had just trusted the "algorithm" or the statistic, they might have risked the baby's life.

  Jordan also argues that **AI is a marketing term.** Most of what we see is actually **Machine Learning** (pattern finding). He suggests we should think of "IA" (**Intelligence Augmentation**) instead of AI—using machines to help humans, not replace them. However, there is a risk of **Anchoring**: if an AI (or a judge) speaks first, everyone else relies on that opinion and stops thinking for themselves.

  Finally, he uses the analogy of **Civil Engineering**. Before physics and structural laws were understood, people built bridges that often fell down. We are currently in the "bridges falling down" phase of AI. We need a new engineering discipline (Data Science) to ensure safety.

  现在让我们看下一篇阅读材料：**《人工智能——革命尚未发生》**。作者是迈克尔·乔丹（Michael Jordan）。不是那个打篮球的迈克尔·乔丹。这位迈克尔·乔丹是伯克利大学著名的机器学习教授。他开玩笑说人们叫他“机器学习界的迈克尔·乔丹”。

  他分享了一个关于数据的亲身经历。14年前，他的妻子怀孕了。他们做了超声波检查，遗传学家指着胎儿心脏周围的白点说：“这是唐氏综合症的标志。风险是二十分之一。”她建议做羊膜穿刺术（一种针刺测试），但该手术有三百分之一的风险会导致胎儿死亡。

  作为一名统计学家，乔丹调查了这些数字。他发现“二十分之一”的统计数据来自十年前英国的一项研究。他还注意到，他的超声波机器的分辨率（像素）比英国研究中使用的旧机器高得多。他意识到这些“白点”很可能只是噪点——是因为新机器太清晰才看得到的视觉伪影。他告诉遗传学家：“我认为这些点是中性的。”他们拒绝了那个危险的手术，后来他的妻子生下了一个健康的女孩。

  教训是什么？**数据来源（Data Provenance）。** 数据从何而来？它与*当前*的情况相关吗？如果他们只是相信“算法”或统计数据，他们可能会拿孩子的生命冒险。

  乔丹还认为**“人工智能”是一个营销术语。** 我们看到的大部分其实是**机器学习**（寻找模式）。他建议我们应该考虑“IA”（**智能增强**）而不是 AI——用机器帮助人类，而不是取代人类。然而，这存在**锚定效应（Anchoring）**的风险：如果人工智能（或法官）先发言，其他人就会依赖那个意见，停止独立思考。

  最后，他使用了**土木工程**的类比。在物理学和结构定律被理解之前，人们建造的桥梁经常倒塌。我们目前正处于人工智能“桥梁倒塌”的阶段。我们需要一个新的工程学科（数据科学）来确保安全。

  [20:31 - 20:38] **Clausewitz: Friction in War**

  Next is **Carl von Clausewitz**, a Prussian general who wrote *On War*. Why read a book about war in an AI course? Because he identifies a problem we are discussing: the difference between theory and reality.

  He talks about **"Friction in War."** On a map, war looks simple. "Go here, shoot there." It looks like a math problem. But in reality, there are infinite small difficulties: bad roads, tired horses, rain, fear. These accumulate into "Friction."

  This relates to the **Quantitative Fallacy** (often associated with McNamara during the Vietnam War). The US thought, "If we kill more enemies than they kill of us (body count), we win." They focused on what could be easily measured and ignored what couldn't (like the enemy's resolve). They lost.

  Clausewitz says you cannot capture everything in data. Shakespeare said, "One may smile, and smile, and be a villain." Can you measure a "pleasing smile" in a dataset? No. Can you measure the "Hungry Judge Effect" (judges being harsher before lunch)? These human factors are invisible to data but drive outcomes.

  接下来是**卡尔·冯·克劳塞维茨**，一位写了《战争论》的普鲁士将军。为什么要在人工智能课程中读一本关于战争的书？因为他指出了我们正在讨论的一个问题：理论与现实之间的差异。

  他谈到了**“战争中的摩擦”**。在地图上，战争看起来很简单。“去这里，在那里射击。”看起来像是一道数学题。但在现实中，有无数的小困难：糟糕的道路、疲惫的马匹、下雨、恐惧。这些累积起来就成了“摩擦”。

  这与**定量谬误**（通常与越战时期的麦克纳马拉联系在一起）有关。美国当时认为，“如果我们杀死的敌人比我们死的人多（统计尸体数），我们就赢了。”他们专注于可以轻易衡量的东西，而忽略了无法衡量的东西（比如敌人的决心）。结果他们输了。

  克劳塞维茨说，你无法在数据中捕捉到一切。莎士比亚说过：“一个人可以笑着，笑着，却是个恶棍。”你能在一个数据集中衡量“迷人的微笑”吗？不能。你能衡量“饥饿法官效应”（法官在午餐前判决更严厉）吗？这些人为因素对数据来说是隐形的，但却主导着结果。

  [20:38 - 20:47] **Bulgakov: A Country Doctor's Notebook**

  We also read **Mikhail Bulgakov**, *A Country Doctor’s Notebook*. There is a story called "Baptism by Rotation." It’s about a young doctor fresh out of medical school, sent to a remote village. He has high grades but zero experience.

  A pregnant woman arrives with a **Transverse Lie**. This means the baby is sideways. It’s a dangerous situation. The doctor panics. He runs back to his room to read his textbook (*Döderlein*). He reads the theory, but in the moment of crisis, the text is "vague, fragmentary, and bookish." He doesn't know what to do.

  The midwife (nurse), Anna Nikolaevna, is not a doctor, but she has seen experienced surgeons do this many times. She gives him hints. "The other doctor used to do it like this..." Through her hints, he figures it out: he has to put his hand in, grab the leg, and turn the child. He does it. It’s bloody, but successful.

  Later that night, he goes back to the book. Suddenly, the text makes perfect sense. "It was flooded with light." He realizes that **real knowledge** is not just text; it requires context and experience.

  This relates to AI. AI (like ChatGPT) is trained on text—on "books." But text without the context of reality is just empty symbols. The nurse had the real knowledge (experience), while the doctor initially only had the data (text).

  我们还读了**米哈伊尔·布尔加科夫**的《乡村医生手记》。有一个故事叫《转向洗礼》。讲的是一个刚从医学院毕业的年轻医生，被派到一个偏远的村庄。他成绩优异，但经验为零。

  一位孕妇来了，胎位是**横位（Transverse Lie）**。这意味着婴儿是横着的。情况非常危险。医生惊慌失措。他跑回房间去读教科书（《多德莱因妇产科》）。他读了理论，但在危急时刻，课本上的文字显得“模糊、破碎且充满书生气”。他不知道该怎么做。

  助产士（护士）安娜·尼古拉耶芙娜不是医生，但她见过经验丰富的外科医生做过很多次。她给了他暗示。“以前的医生是这样做的……”通过她的暗示，他明白了：他必须把手伸进去，抓住腿，把孩子转过来。他做到了。场面很血腥，但成功了。

  那天晚上晚些时候，他回去看书。突然间，课本的内容变得完全清晰了。“仿佛被光芒照亮。”他意识到，**真正的知识**不仅仅是文字；它需要语境和经验。

  这与人工智能有关。人工智能（像 ChatGPT）是在文本——在“书本”上训练出来的。但没有现实语境的文本只是空洞的符号。护士拥有真正的知识（经验），而医生最初只有数据（文本）。

  [20:47 - 20:56] **Michael Hoey: Text as Interaction**

  Finally, **Michael Hoey’s "Introduction to Written Discourse Analysis."** He argues that text is not just static data; it is a site of **interaction**.

  There are four entities in any text:

  1. **Writer:** The person physically writing (e.g., the scribe, the legislative drafter).
  2. **Author:** The authority behind the text (e.g., the Parliament, the Committee).
  3. **Reader:** The actual person reading.
  4. **Audience:** The ideal reader the author imagined.

  The relationship is about **meeting expectations**. A writer writes a sentence, and the reader has an expectation of what comes next. If you don't like a book, you throw it away. In that sense, the Reader is the powerful one.

  Consider a receipt. It is text. But without context (who bought it, why), it is meaningless data.
  Consider a Statute (Law). The **Author** is Parliament. The **Audience** is not the public (you won't understand it); the audience is other lawyers and judges.

  **Conclusion:** Text is complicated. It contains intentions, biases, and interactions. If we just feed "all the text in the world" into an AI (Common Crawl) without understanding these interactions, we lose the meaning.

  Any questions? No? I will take attendance. See you next week.

  最后是**迈克尔·霍伊的《书面话语分析导论》**。他认为文本不仅仅是静态数据；它是一个**互动**的场所。

  任何文本中都有四个实体：

  1. **写作者（Writer）**：实际书写的人（例如，抄写员、立法起草人）。
  2. **作者（Author）**：文本背后的权威（例如，议会、委员会）。
  3. **读者（Reader）**：实际阅读的人。
  4. **受众（Audience）**：作者想象中的理想读者。

  这种关系是关于**满足期望**的。写作者写下一个句子，读者会对接下来的内容产生期望。如果你不喜欢一本书，你会把它扔掉。从这个意义上说，读者是拥有权力的一方。

  以收据为例。它是文本。但如果没有语境（谁买的，为什么买），它就是毫无意义的数据。
  以法规（法律）为例。**作者**是议会。**受众**不是公众（你读不懂）；受众是其他律师和法官。

  **结论：** 文本是复杂的。它包含意图、偏见和互动。如果我们只是将“世界上的所有文本”喂给人工智能（Common Crawl），而不理解这些互动，我们就会丢失意义。

  有问题吗？没有？我要点名了。下周见。
## Week 2
  [18:34 - 18:38] **Administrative Announcements & Group Projects**

  **English**
  So I guess we don't have all the classrooms yet. Okay, I'll just make two administrative announcements.
  Number one: Instead of eight reading responses, there will only be four. Okay? So those of you who completed the one for this week, you have three more to go. Some students told me they have children or other commitments, so I'm reducing the load.
  Number two: This will be in the actual announcements page, but regarding group projects—the problem with group projects is that there tend to be "slackers." You know, the "free rider problem"—the idea that "everybody else works, so I'm not going to do it yet."
  So, here are the rules:
  First, you can come to me privately. It’s a "test of your humanity." You can tell me [if someone isn't working], and I'll have to talk to that person.
  Second, when you submit your assignment, you have to include a couple of sentences at the end detailing who did what. For example: "Ilya looked up these papers," "The other person processed this data." You basically have to state what you did, and everyone has to agree to this—almost like signing off on it. This prevents the situation where someone didn't do anything but still gets credit. Just... we're all adults here. Half of our lives are gone, let's not waste time.
  One question: Is there a limit of four people per group? Yes, four is already too much.
  And those who cannot find groups... let's see by tomorrow. If there are people who can't find a group, I'm just going to basically dump them into a group. Okay? There aren't that many people left. You guys are freaking executives, right? You have work. The whole point is to network. I can't believe finding a group is a problem. It should be done by the next day. But anyway, if needed, I'll assign people. Life is meaningless anyway, so...

  **Chinese**
  我想我们还没把所有教室都安排好。好吧，我先发两个行政通知。
  第一：阅读反馈作业（Reading Responses）从八次减少到四次。好吗？所以，如果你已经完成了这周的作业，那你只需要再做三次。有学生告诉我他们有孩子或者其他事情，所以我给大家减负了。
  第二：这部分内容我会发在公告页上，是关于小组作业的。小组作业的问题在于总会有“摸鱼”的人（slackers）。这就是“搭便车问题”（free rider problem）——也就是那种“别人都在干活，那我就先不动”的想法。
  所以，我有两点要求：
  首先，你们可以私下找我。这是对人性的考验。你可以告诉我（如果有人不干活），我会去跟那个人谈。
  其次，提交作业时，你们必须在最后附上几句话，说明每个人的分工。比如：“Ilya 查阅了这些论文”，“某某处理了这些数据”。你们必须明确说明自己做了什么，并且全组人都要像签署协议一样确认。这样可以防止有人什么都不做却混学分。大家都是成年人了，半辈子都过去了，别浪费时间。
  有个问题：小组人数限制是四个人吗？是的，四个人已经太多了。
  至于那些找不到组的人……我们等到明天看看。如果明天还有人找不到组，我就直接把你们塞进某个组里。行吗？剩下的人不多了。你们都是企业高管（executives）对吧？你们都有工作。来这里就是为了社交（network）的。我不相信找队友还是个问题，应该第二天就搞定的。不过无所谓了，反正人生也是毫无意义的……

  [18:38 - 18:42] **Review: Data Provenance**

  **English**
  A bit of a review. What did we learn last week?
  According to me—and obviously, if you want a good grade, you have to agree with me... I'm kidding, strictly speaking, you can disagree. We're adults.
  What were the key concepts? When you read the chapter, there are always key concepts. Repetition is the mother of learning—or as the Russian proverb says, "Repetition is the mother of skill."
  So, we learned about **Data Provenance**. Let's write it down. Why is Data Provenance a problem? This is the thesis of the course. It’s something AI engineers and machine learning people deal with constantly—it's their bread and butter.
  Remember the example of the substitution? The pixels used in a study 10 years ago were actually smaller than the ones used today. So it created a "false positive." The doctor didn't do the operation right because of this data discrepancy.
  The key point of that reading was: the algorithm just calculated the numbers. It didn't ask, "What about the people who don't know the data source changed?" And the result? Children died. So a tiny little data problem has a huge vision/consequence. Who are you to kill children because of a pixel difference?

  **Chinese**
  复习一下。上周我们学了什么？
  根据我的观点——当然，如果你想要好成绩，你得同意我……开玩笑的，严格来说你们可以不同意。大家都是成年人。
  关键概念是什么？你们读那一章的时候，总会有几个核心概念。重复是学习之母——或者用那句俄罗斯谚语说，“重复是技能之母”。
  我们学了**数据溯源**（Data Provenance）。我们要把它记下来。为什么数据溯源是个问题？这是这门课的核心论点。这是 AI 工程师和机器学习专家每天都要面对的“家常便饭”。
  还记得那个替换的例子吗？十年前研究中使用的像素比今天的要小，结果导致了“假阳性”。医生因为这个数据差异，做手术时出了问题。
  那篇文章的关键点在于：算法只是在计算数字。它不会问：“如果医生不知道数据源变了怎么办？”结果是什么？有孩子因此丧命。所以，一个微小的数据问题可能导致巨大的后果。你凭什么因为像素的差异而让孩子丧命？

  [18:42 - 18:49] **Data Generation, Knowledge vs. Technique, and Models**

  **English**
  What else did we say? The other thing is **Data Generation**.
  Obviously, you can disagree with me. This is a philosophy, an "unchallenged past"... well, sometimes there is a path through the field that everyone knows, an unchallenged path. I'm not saying I know the absolute truth, I think you *should* be disagreeing.
  But in theory, if we look at how the computer senses things, it sees a distribution. They think of language as a distribution and it generates a bunch of words. But when I see a table, my "distribution" is updated every time I look at different things. I don't think language works the way AI thinks it does, but that's the idea of data generation.
  To critique AI—especially since AI today is mostly text-based (LLMs)—we have to understand how textual data is generated. What makes you say what you want to say?
  Remember the "Baptism by Rotation"? The nurse knows she has all this unwritten knowledge. She knows how to position the patient's leg just right. The *written* knowledge is in the books.
  This distinction is between **Knowledge** (Episteme) and **Technique** (Techne). "Technology" comes from *techne*.
  My favorite example: This telephone. It’s so complicated, there are formulas about it that no single person fully understands. But I can *use* it. That is technique/skill. The Greeks recognized this: there is "understanding knowledge" (reading a book) and there is "doing knowledge."
  This separation is important because AI relies on data (written/recorded), but it can't really access the skill of the craftsman, or the intuition of a nurse who has seen a million operations. This is why AI is a problem—it touches on a very old philosophical problem we don't have solutions for.
  Chris Anderson, in his famous reading "The End of Theory," said models are wrong. He said, "What do we need models for? We can just collect data and know everything." That’s the "Google Age" idea.
  But that makes us question: What is a model? Look at the MRT map. It’s a model. It has circles and straight lines. It’s very useful—I know where to get off. But if I put this map over an actual map of Singapore, it would be incorrect. It doesn't match reality. All models are wrong, but some are useful.
  Mathematicians are actually the ones skeptical of this AI stuff. There is a distinction between the map and the territory.
  **Jorge Luis Borges** wrote a short story called "On Exactitude in Science." In that Empire, the map of a single province occupied the whole city. Eventually, they made a map of the Empire that was the same scale as the Empire, point for point. But the following generations realized that such a map was useless and left it to the "Inclemencies of Sun and Winters" in the desert.
  The point is: no matter how hard you try to capture reality (data), it will never be enough. Text/Language is trying to save this idea, but it's difficult. It touches on "What is it to know?"

  **Chinese**
  我们还讲了什么？另一点是**数据生成**（Data Generation）。
  当然，你们可以不同意我的观点。这是一种哲学，一种“未被挑战的过去”……就像田野里有一条大家都知道的路，一条未被挑战的路。我不是说我掌握了真理，我觉得你们*应该*提出异议。
  但从理论上讲，计算机通过分布（distribution）来感知事物。它们把语言看作一种分布，并据此生成单词。但当我看到一张桌子时，我的“分布”会随着我看到不同的东西而更新。我不认为语言的运作方式像 AI 认为的那样，但这正是数据生成的概念。
  要批判 AI——特别是因为今天的 AI 主要是基于文本的（如 LLM）——我们必须理解文本数据是如何生成的。是什么让你说出你想说的话？
  还记得那个“旋转洗礼”的例子吗？护士拥有那些不成文的知识。她知道怎么把病人的腿摆得恰到好处。而*成文*的知识则在书本里。
  这就在**知识**（Episteme）与**技艺**（Techne）之间划出了界限。“技术”（Technology）一词就来源于 *Techne*。
  我最喜欢的例子是：这部电话。它非常复杂，包含的公式没有一个人能完全理解。但我会*用*它。这就是技艺/技能。希腊人早就意识到了这一点：既有“理解性的知识”（读书），也有“实践性的知识”。
  这种区分很重要，因为 AI 依赖于数据（写下来的/记录下来的），但它无法真正获取工匠的技艺，或者一位看过一百万次手术的护士的直觉。这就是 AI 成为问题的原因——它触及了一个非常古老的、我们尚未解决的哲学问题。
  Chris Anderson 在他著名的文章《理论的终结》中说，模型是错的。他说：“我们还需要模型干什么？我们只要收集数据就能知道一切。”这就是“谷歌时代”的理念。
  但这让我们反思：什么是模型？看看地铁（MRT）线路图。那就是一个模型。它有圆圈和直线。它很有用——我知道在哪里下车。但如果我把它覆盖在新加坡的真实地图上，它就是错的。它不符合现实。所有的模型都是错的，但有些是有用的。
  实际上，数学家才是对 AI 持怀疑态度的人。地图和领土是有区别的。
  **博尔赫斯**（Jorge Luis Borges）写过一篇短篇小说叫《论科学的精确性》。在那个帝国里，一个省的地图大得占满了整座城市。最后，他们制作了一张与帝国幅员一样大、点对点对应的地图。但后代意识到这张地图毫无用处，便将其遗弃在沙漠中任凭风吹日晒。
  关键在于：无论你多么努力地去捕捉现实（数据），它永远都不够。文本和语言试图挽救这种观念，但这很难。这触及了“什么是认知？”的问题。

  [18:49 - 19:12] **Roman Jurists: The Data Labelers of Antiquity**

  **English**
  This week, we have interesting readings. Our idea is not only to understand the problems with AI but to speak about them from the legal side.
  The dream of all jurists—or the "tech dream"—is that a robot judge will determine the case. An objective algorithm. It’s supposed to be less biased than a human, more efficient, quicker. But nobody questions the Data Provenance. Very few people talk about it.
  When you read news about AI, never trust it fully, because the people writing the articles often work for those companies. There is a "hubris" (arrogance) in saying "In six months we won't need doctors." It's crazy.
  So, the reading: **Gordley, "The Jurists."**
  This text explains that the foundation of Western law is Roman Law. Back in the day, there was a special class of people called **Jurists**.
  They were not lawyers. What does a lawyer do? If we have a dispute, we hire lawyers. The lawyer is an advocate; they are paid to win. They cannot look at the law from an objective perspective.
  But the Roman Jurists were rich aristocrats, often in public office, who advised the Praetors (judges). They were **unpaid**. Imagine working completely unpaid! They did it for honor (`honorarium`). If you offered them money, they would be insulted. This allowed them to look at the law from an objective perspective, independent of the parties. They were "scientists" of the law.
  Cicero, a famous lawyer/orator, hated them. He said these jurists concern themselves with "trifles" (unimportant details) and are "too unsystematic to be intellectually respectable." Cicero wanted to turn law into a science (an "Art" or *Techne*), a system.
  But the Jurists turned their backs on Cicero's idea of a system. They focused on **Casuistry** (case-based reasoning). They tested concepts with hypothetical cases.
  **Example 1: The Gladiators.**
  A contract was made to provide slaves to fight in the arena. The contract said: "For each slave returned alive, 20 denarii. For each one killed, 1000 denarii."
  Question: Was this a **sale** or a **lease**?
  It seems odd. Usually, you know if you are selling or leasing. But here, the Jurists decided: It was a lease for the survivors, and a sale for those killed. It’s almost like "Schrodinger's Contract"—the nature of the contract is determined *after* the event.
  **Example 2: The Triplets.**
  A slave woman is to be freed if she bears three children. She bears one, and then later bears triplets. Which of the triplets is the "third" one? If you say the last one, then the first two triplets are slaves and the last is free? That seems odd.
  These questions seem trivial, but they were testing the limits of the concepts. They were generating the "data" of the law. They wrote as if they lived in a vacuum, removed from social/economic considerations, focusing purely on the logic of the law.
  This method—focusing on the facts and the specific case rather than a grand system—is why law is not a "geometric science" (Mos Geometricus).
  Today, law schools are often grouped with social sciences or humanities. But historically, there was a push to make law a science, like math. The Jurists rejected that. They knew you couldn't capture reality with a perfect system.

  **Chinese**
  这周的阅读很有意思。我们的目的不仅是理解 AI 的问题，还要从法律的角度来探讨这些问题。
  所有法学家——或者说技术圈——的梦想是有一个机器人法官来判案。一个客观的算法。据说它比人类偏见更少，更高效，更快。但没人质疑“数据溯源”的问题。很少有人谈论这个。
  当你们看关于 AI 的新闻时，永远不要全信，因为写文章的人往往就给那些公司打工。这其中有一种“傲慢”（hubris），比如声称“六个月后我们就不需要医生了”。这太疯狂了。
  好，来看阅读材料：**Gordley 的《法学家》（The Jurists）。**
  这篇文章解释了西方法律的基础是罗马法。在那个时代，有一群特殊的人叫**法学家**（Jurists）。
  他们不是律师。律师是干什么的？如果有纠纷，我们会请律师。律师是辩护人，他们收钱是为了赢官司。他们不能从客观角度看法律。
  但罗马法学家是有钱的贵族，通常担任公职，他们为裁判官（法官）提供建议。他们是**不收报酬的**。想象一下完全免费工作！他们是为了荣誉。如果你给他们钱，通过那是对他们的侮辱。这使得他们能够独立于当事人，从客观角度看待法律。他们是法律的“科学家”。
  西塞罗（Cicero），一位著名的律师/演说家，很讨厌他们。他说这些法学家关注的是“琐事”（trifles，不重要的细节），而且“太不成体系，算不上显赫的学问”。西塞罗想把法律变成一门科学（一门“技艺”或 *Techne*），一个系统。
  但法学家们拒绝了西塞罗的系统化想法。他们专注于**决疑法**（Casuistry，基于案例的推理）。他们用假设的案例来测试法律概念。
  **例子 1：角斗士。**
  一份合同规定提供奴隶在竞技场格斗。合同说：“每个活着回来的奴隶，付20第纳尔。每个死掉的，付1000第纳尔。”
  问题：这是**买卖**还是**租赁**？
  这看起来很奇怪。通常你知道你是卖还是租。但在这里，法学家决定：对幸存者是租赁，对死者是买卖。这就像“薛定谔的合同”——合同的性质是在事件发生*之后*决定的。
  **例子 2：三胞胎。**
  一个女奴如果在生下三个孩子后将获得自由。她生了一个，后来又生了三胞胎。三胞胎中哪一个是“第三个”？如果你说是最后出来的那个，那前两个三胞胎是奴隶，最后一个是自由人？这看起来很奇怪。
  这些问题看似琐碎，但他们是在测试概念的边界。他们是在生成法律的“数据”。他们写作时仿佛生活在真空中，脱离了社会/经济考量，纯粹关注法律的逻辑。
  这种方法——关注事实和具体案例，而不是宏大的系统——就是为什么法律不是一门“几何科学”（Mos Geometricus）。
  今天，法学院通常被归类为社会科学或人文学科。但在历史上，曾有一股力量试图将法律变成像数学一样的科学。法学家们拒绝了这一点。他们知道你无法用一个完美的系统来捕捉现实。

  [19:12 - 19:35] **The Digest of Justinian & Definitions**

  **English**
  Let's look at what they actually said. This is the **Digest of Justinian**.
  Published in 533 AD. Justinian collected every ancient source—millions of lines—and compressed it into 50 books. He burned everything else.
  The Preface lists his titles: "Conqueror of the Alamanni, Goths, Franks, Germans..." basically everyone he killed.
  Book 1: "Justice and Law."
  **Ulpian** (a famous jurist) defines Justice: "Justice is the steady and enduring will to render unto everyone his right."
  The basic principles of law are: "To live honorably, not to harm another, to render to each his own."
  Ulpian calls jurists the "Priests of the Law." He says they cultivate the philosophy of "good and fair."
  There are two branches of law: **Public Law** (state affairs) and **Private Law** (individual interests).
  Private law is derived from three sources:

  1. **Natural Law** (*Jus Naturale*): That which nature has taught to all animals (e.g., marriage, procreation).
  2. **Law of Nations** (*Jus Gentium*): That which all human peoples use.
  3. **Civil Law** (*Jus Civile*): The law specific to a state.
  There is a conflict here. Natural Law says "All men are born free." But the Law of Nations includes slavery and war. They contradict.
  This is the tension between **Positive Law** (Man-made law, "I did it because the statute says so") and **Natural Law** (Higher principles).
  Think of the **Nuremberg Trials**. The defense was "I was following the laws of the state." But the prosecution argued Natural Law—you cannot make a law that says "Kill these people" and claim it is just.
  Also, look at this famous maxim in the Digest (Book 50, Title 17): **"Omnis definitio in iure civili periculosa est"**—"Every definition in civil law is dangerous."
  Why? Because there is always an exception. You cannot capture reality with a definition. "It is rare for the possibility [of an exception] not to exist."
  Another key point on interpreting statutes: "Fraud on the statute is practiced when one does what the statute does not wish anyone to do, yet which it has failed explicitly to prohibit."
  They were very sensitive to words. If you stick to the *letter* of the law but violate its *spirit*, you are cheating the law.

  **Chinese**
  我们来看看他们到底说了什么。这就是**《查士丁尼学说汇纂》（Digest of Justinian）。**
  公元533年出版。查士丁尼收集了所有的古代文献——数百万行——并将它们压缩成50卷书。其他的都被他烧了。
  前言列出了他的头衔：“阿勒曼尼人、哥特人、法兰克人、日耳曼人的征服者……”基本上就是所有被他杀掉的人。
  第一卷：“正义与法律”。
  **乌尔比安**（Ulpian，一位著名的法学家）定义正义：“正义是分给每个人以其权利的坚定而恒久的意志。”
  法律的基本原则是：“诚实生活，不害他人，各得其所。”
  乌尔比安称法学家为“法律的祭司”。他说他们通过“善良与公平”的哲学来教化世人。
  法律有两个分支：**公法**（国家事务）和**私法**（个人利益）。
  私法源于三个来源：

  1. **自然法**（*Jus Naturale*）：大自然教给所有动物的法则（如婚姻、生育）。
  2. **万民法**（*Jus Gentium*）：所有人类民族通用的法律。
  3. **市民法**（*Jus Civile*）：特定国家的法律。
  这里存在冲突。自然法说“人生而自由”。但万民法却包含了奴隶制和战争。这两者是矛盾的。
  这就是**实证法**（Positive Law，人定法，即“我这么做是因为法规这么写”）与**自然法**（更高的原则）之间的张力。
  想想**纽伦堡审判**。被告的辩护是“我在遵守国家的法律”。但控方主张自然法——你不能制定一条“杀掉这些人”的法律然后声称它是正义的。
  另外，看这句《学说汇纂》中的名言（第50卷17章）：**"Omnis definitio in iure civili periculosa est"**——“市民法中的每一个定义都是危险的。”
  为什么？因为总会有例外。你无法用定义完全捕捉现实。“这种（例外的）可能性不存在的情况是极罕见的。”
  关于解释法规的另一个关键点：“当一个人做了法规不希望任何人做的事，但法规却未能明确禁止该行为时，这就是对法规的欺诈。”
  他们对文字非常敏感。如果你拘泥于法律的*条文*（letter）却违反了它的*精神*（spirit），你就是在欺骗法律。

  [19:54 - 20:00] **Lex Aquilia: Teachers, Experts, and The Barber**

  **English**
  Now we move to the **Lex Aquilia**. This is the Roman law regarding damage to property. A slave was considered property, like a car. If you break someone's car, it's not "murder" of the car, it's damage to property.
  The jurists use this law to explore the concept of **negligence** (fault).
  **The Teacher Case:** Julian writes that if a teacher puts out a pupil's eye during the course of instruction (he hit him too hard), he is held liable under the Lex Aquilia.
  **The Shoemaker Case:** A shoemaker struck a boy (an apprentice) on the neck with a shoe-last because the boy did his work badly. The result was that the boy's eye was knocked out. Julian says: The action for "insult" doesn't apply because he didn't mean to insult the boy, he meant to correct him. But he used excessive force. So, is it a breach of contract (teaching services)? Perhaps. But Julian has no doubt he can be sued under the Lex Aquilia for damage.
  **The Barber Case:** This is a very famous one.
  Facts: A barber is shaving a slave in a public square. Nearby, people are playing with a ball. One of the players hits the ball, it strikes the barber's hand, the razor slips, and the slave's throat is cut.
  Who is liable?

  1. **The Barber?** Ulpian says the blame is the barber's. Why? Because surely if he was shaving someone in a place where people customarily play games or where there is heavy traffic, he is at fault.
  2. **The Slave?** Ulpian also says: "It is not a bad point to reply that if someone entrusts himself to a barber who has his chair in a dangerous place, he has only himself to blame for his own bad luck."
  So, who is it? It depends on how you argue the facts. A lawyer today wouldn't say "My client was an idiot for sitting there," but objectively, the jurists are looking at where the fault truly lies based on the specific circumstances.

  **Chinese**
  现在我们来讲讲**阿奎利亚法**（Lex Aquilia）。这是罗马关于财产损害的法律。奴隶被视为财产，就像车一样。如果你弄坏了别人的车，那不叫“谋杀”车，那叫财产损害。
  法学家利用这部法律来探讨**过失**（negligence/fault）的概念。
  **老师的案例**：尤利安（Julian）写道，如果一个老师在教学过程中弄瞎了学生的眼睛（打得太重了），根据阿奎利亚法，他要承担责任。
  **鞋匠的案例**：一个鞋匠用鞋楦（做鞋的模型）打了学徒的脖子，因为学徒活儿干得不好。结果把学徒的眼睛打瞎了。尤利安说：“侮辱罪”在这里不适用，因为他本意不是侮辱，而是为了管教。但他用力过猛了。那么，这是违反了教学合同吗？也许吧。但尤利安毫无疑问地认为，可以根据阿奎利亚法起诉他造成了损害。
  **理发师的案例**：这是一个非常有名的案例。
  事实是：一个理发师在广场上给一个奴隶刮脸。附近有人在踢球。球击中了理发师的手，剃刀一滑，割断了奴隶的喉咙。
  谁负责？

  1. **理发师？** 乌尔比安（Ulpian）说责任在理发师。为什么？因为如果他在一个人们习惯玩游戏或者交通繁忙的地方刮脸，那肯定是他有过错。
  2. **奴隶？** 乌尔比安也说：“这也不失为一个好的反驳：如果一个人把自己交给一个在危险地方设座位的理发师，那他只能怪自己倒霉。”
  所以，到底是谁的错？这取决于你如何辩论事实。今天的律师不会说“我的客户是个白痴，非要坐那儿”，但从客观角度看，法学家们正在根据具体情况寻找过失的真正所在。

  [20:01 - 20:06] **Joint Liability: Multiple Attackers & Fairchild**

  **English**
  **The Multiple Attackers Case:**
  If one man kills a slave, he is liable. But what if **several people** beat a slave to death?
  Let us see whether they are all liable.

  1. If it is clear whose blow killed him, that person is liable.
  2. But if it is **not clear** who struck the fatal blow, Julian says that **all the assailants are liable** as if they had all killed him.
  Why? Because otherwise, nobody would be liable, and that would be unjust.
  **Application to Modern Law: *Fairchild v Glenhaven Funeral Services* (2002).**
  This is a modern case about **Mesothelioma**, a lung cancer caused by asbestos.
  A worker worked for Employer A and Employer B. Both factories had asbestos. He gets cancer.
  Scientific problem: It takes only *one* fiber to cause the cancer. It’s not cumulative like hearing loss. It’s a lottery. You cannot prove scientifically *which* employer provided the specific fiber that killed him.
  Employer A says: "Prove it was me." Employer B says: "Prove it was me."
  The House of Lords (Supreme Court of UK) looked at this. They explicitly cited the **Digest of Justinian** and the case of the multiple attackers.
  They said: Just like the Roman case where we don't know who struck the fatal blow, if we stick to strict causation, the victim gets nothing. That is unjust. Therefore, **both are liable**.
  They used a 2,000-year-old solution for a modern industrial problem. This shows the "universality" of the problem.

  **Chinese**
  **多人袭击的案例**：
  如果一个人杀了一个奴隶，他要负责。但如果**好几个人**把一个奴隶打死了呢？
  我们要看看是否所有人都要负责。

  1. 如果能查清是谁的拳头致死，那个人负责。
  2. 但如果**查不清**是谁的拳头致死，尤利安说：**所有袭击者都要负责**，就好像他们每个人都杀了他一样。
  为什么？因为如果不这样，就没人负责了，那是不公义的。
  **现代法律的应用：*Fairchild v Glenhaven Funeral Services* (2002)**
  这是一个关于**间皮瘤**（Mesothelioma）的现代案例，这是一种由石棉引起的肺癌。
  一个工人在雇主A和雇主B那里都工作过。两家工厂都有石棉。他得了癌症。
  科学上的难题是：只需要*一根*纤维就能致癌。这不像听力受损是累积的。这像中彩票一样。你无法从科学上证明到底是*哪一个*雇主的纤维杀死了他。
  雇主A说：“你证明是我啊。”雇主B说：“你证明是我啊。”
  英国上议院（最高法院）审理了此案。他们明确引用了**《查士丁尼学说汇纂》**以及那个多人袭击的案例。
  他们说：就像那个罗马案例一样，既然我们不知道是谁打出了致命一击，如果我们死抠因果关系，受害者就一分钱都拿不到。那是不公义的。因此，**两家都要负责**。
  他们用了一个2000年前的方案来解决现代工业问题。这显示了问题的“普适性”。

  [19:57 - 19:59] **Causation: Javelins & The Bridge**

  **English**
  (Note: Going back slightly to other examples in the text regarding causation)
  **The Javelin Case:**
  If people are throwing javelins (spears) for sport in a field, and a slave walks across the field and gets killed.
  If the slave walked across a field where javelin throwing is **customarily practiced**, the action fails. He shouldn't have walked there.
  But if someone deliberately aimed at him, that's different.
  Or if they were throwing in a place where it's *not* customary to throw, the throwers are liable.
  **The Bridge Case:**
  If a man pushes another off a bridge. Celsus says strict liability applies regardless of whether he died from the impact of the fall or was drowned by the river. You provided the cause of death.
  **Poison vs. Sword:**
  There was a distinction in early law. If I kill you with a sword, I "did" it. If I give you poison to drink, I provided the cause, but you drank it.
  The Lex Aquilia originally only covered direct force ("body to body"). But the Jurists expanded it to include providing the cause (like giving poison).
  They are always playing with the **facts**. Every little change in the facts changes the legal outcome.

  **Chinese**
  （注：稍微回顾一下文中关于因果关系的其他例子）
  **标枪的案例**：
  如果人们在操场上投掷标枪（为了运动），一个奴隶穿过操场被扎死了。
  如果那个奴隶穿过的是一个**习惯上**用来投掷标枪的场地，诉讼就会失败。他不应该走那儿。
  但如果有人故意瞄准他，那就另当别论了。
  或者，如果他们在*不是*投掷标枪的地方投掷，投掷者就要负责。
  **桥的案例**：
  如果一个人把另一个人推下桥。塞尔苏斯（Celsus）说，无论他是摔死的还是被河水淹死的，推人者都要负责。是你提供了死亡的原因。
  **毒药与剑**：
  早期法律有个区别。如果我用剑杀你，是我“做”的。如果我给你毒药喝，我提供了原因，但是你自己喝下去的。
  阿奎利亚法最初只涵盖直接武力（“身体对身体”）。但法学家将其扩展到了“提供原因”（比如给毒药）。
  他们总是在推敲**事实**。事实的一点点变化都会改变法律结果。

  [20:08 - 20:12] **The Mules Case (Capitol Hill)**

  **English**
  This is the most famous case, and the most important for understanding legal reasoning.
  **Facts:**
  Some mules were pulling two loaded carts up the Capitoline Hill in Rome.
  The **front cart** had tipped up or started slipping back.
  The drivers of the front cart were trying to lift the back to make it easier for the mules.
  But suddenly the cart started to go back. The drivers, seeing they would be crushed between the two carts, jumped out.
  The front cart rolled back and struck the **rear cart**.
  The rear cart careered down the hill and ran over a **slave boy**.
  The owner of the slave boy asks for advice: Who is liable?
  **Alfenus's Reply:**
  "I replied that **it all depends on the facts of the case**."
  (*In causa ius esse positum* — The law is situated in the case/facts).
  This is the only correct answer to any legal question: "It depends." Why?
  Let's look at the scenarios Alfenus proposes:

  1. **Scenario A (Drivers' Fault):** If the drivers who were holding up the front cart got out of the way of their own accord (laziness, gave up), and *that* was the reason the mules couldn't hold the weight, then the action can be brought against the drivers.
  2. **Scenario B (Mules/Owner's Fault):** If the mules shied at something (got scared) and the drivers left for fear of being crushed, then the action is against the **owner of the mules**. Or if the mules were just too weak to pull the load.
  3. **Scenario C (No Liability):** If the mules simply slipped due to the weight and the drivers couldn't hold it, and they jumped to save their lives (fear of death), then **no action** lies against the drivers.
  This demonstrates the "Data Generating Process" of law.
  The judge doesn't just apply a rule "Don't kill slaves." The judge constructs a narrative based on the specific micro-facts: Why did they let go? Was it fear? Was it laziness? Was the mule weak?
  This is why AI struggles with law. AI sees text. It doesn't see the physical reality or the human intent (fear vs laziness) unless it is explicitly in the data. But the law *is* that distinction.

  **Chinese**
  这是最著名的案例，对于理解法律推理也是最重要的。
  **事实**：
  几头骡子正拉着两辆装满货的车上罗马的卡比托利欧山（Capitoline Hill）。
  **前面的车**翘起来了或者开始向后滑。
  前车的车夫试图抬起车尾，帮骡子减轻负担。
  但突然车子开始倒退。车夫们眼看自己要被夹在两车之间压扁，就跳开了。
  前车滑下来撞到了**后车**。
  后车失控冲下山坡，碾过了一个**奴隶男孩**。
  奴隶男孩的主人来咨询：谁负责？
  **阿尔芬努斯（Alfenus）的回答**：
  “我的回答是，**这完全取决于案件事实**。”
  （*In causa ius esse positum* —— 法律存在于案件/事实之中）。
  这是对任何法律问题唯一正确的回答：“看情况（It depends）。”为什么？
  我们要看看阿尔芬努斯提出的几种假设场景：

  1. **场景 A（车夫的错）**：如果支撑前车的车夫是自愿闪开的（比如偷懒，或者放弃了），而*这*正是骡子拉不住车的原因，那么可以起诉车夫。
  2. **场景 B（骡子/主人的错）**：如果骡子是因为受惊（shied）而后退，车夫因为害怕被压死而闪开，那么应该起诉**骡子的主人**。或者如果是因为骡子太弱拉不动车。
  3. **场景 C（无责任）**：如果骡子仅仅是因为太重滑倒了，车夫拉不住，为了保命（恐惧）而跳开，那么对车夫**没有诉讼请求**（即不用负责）。
  这展示了法律的“数据生成过程”。
  法官不仅仅是应用一条规则“不许杀奴隶”。法官是基于微观事实构建一个叙事：他们为什么松手？是因为恐惧？是因为懒惰？是因为骡子弱？
  这就是为什么 AI 处理法律很困难。AI 看到的是文本。它看不到物理现实或人类的意图（恐惧 vs 懒惰），除非数据里明确写了。但法律恰恰*就是*这种区分。

  [20:13 - 20:25] **Miller v Jackson: Constructing the Narrative**

  **English**
  Two more examples to show how data is generated in law—how the "facts" are not just objective reality but are constructed.
  First, **Miller v Jackson (1977)**.
  **Facts**: There is a cricket club in a village called Lintz. They have been playing there for 70 years. A developer built houses right next to the field. The Millers bought one of these houses. Cricket balls kept landing in their garden, breaking windows and causing damage. Mrs. Miller sued for "nuisance" to stop the cricket.
  **Lord Denning's Judgment**: This is famous because of his language. Look at how he starts:
  *"In summertime village cricket is the delight of everyone. Nearly every village has its own cricket field where the young men play and the old men watch... In the village of Lintz, they have their own ground... they have played these last 70 years."*
  He describes the club with such romantic language—it's "well rolled," "well mowed," a "labour of love."
  Then he introduces Mrs. Miller:
  *"He [the judge] has done it at the instance of a newcomer who is no lover of cricket... This newcomer has built... a house on the edge of the cricket ground... She became almost neurotic about this trouble."*
  He frames her as a "neurotic" woman, an outsider destroying the village's tradition. He says if we stop cricket, "the whole village will be much poorer." He is weighing the Public Interest (Cricket) against the Private Interest (Neurotic Woman).

  **Chinese**
  我们再举两个例子，来看看法律中的数据是如何生成的——所谓的“事实”不仅仅是客观现实，而是被构建出来的。
  第一个是 **Miller v Jackson (1977)**。
  **事实**：在一个叫 Lintz 的村庄有一个板球俱乐部。他们在那里打球已经70年了。开发商在球场旁边建了房子。米勒夫妇（The Millers）买了其中一栋。板球不断飞进他们的花园，打碎窗户，造成破坏。米勒太太起诉要求停止板球活动，理由是“妨害”（nuisance）。
  **丹宁勋爵（Lord Denning）的判词**：这篇判词因其语言而闻名。看看他是怎么开头的：
  *“在夏日，乡村板球是每个人的乐事。几乎每个村庄都有自己的板球场，年轻人在那里打球，老人在那里观看……在 Lintz 村，他们有自己的球场……他们在那里打了70年球。”*
  他用如此浪漫的语言描述俱乐部——球场“被精心碾压”、“精心修剪”，这是一项“爱的劳动”。
  然后他介绍了米勒太太：
  *“他（初审法官）是在一个不爱板球的新来者的要求下发布禁令的……这个新来者在板球场边建了房子……她对这个麻烦几乎变得神经质（neurotic）了。”*
  他把她描绘成一个“神经质”的女人，一个破坏村庄传统的局外人。他说如果我们停止板球，“整个村庄都会变得更加贫瘠”。他是在将公共利益（板球）与私人利益（神经质的女人）进行权衡。

  [20:19 - 20:25] **The "Missing" Data: The Son**

  **English**
  But here is the interesting thing. There were two other judges, Lord Lane and Lord Cumming-Bruce. They looked at the exact same case, the exact same reality.
  Lord Lane says: *"According to the village... in 1976, on the 26th of July, one [ball] just missed breaking the window of the room in which their son was seated. He was then aged 11 or 12."*
  The other judges emphasize that there is a **child** in the house. They mention the risk of physical injury. Mrs. Miller is not just "neurotic" about property; she is a mother afraid for her child.
  **Lord Denning never mentions the son.**
  Think about that. In his "data generation" process, he completely deleted the child from the narrative because it didn't fit his story of "Cricket vs. Crazy Woman."
  If you read only Denning, you think she is crazy. If you read the others, you see a legitimate danger.
  This is exactly what we mean by data generation. The "facts" depend on what you choose to include. The input data determines the output (the judgment). Lord Denning calls the balls "thunderbolts from heaven"—he uses poetic language to minimize the human fault.
  (Note: The Millers actually won the claim for nuisance because it *was* a nuisance, but the court refused to grant the injunction to stop the cricket, deciding instead to award damages/money. So cricket continued, but they had to pay for the windows).

  **Chinese**
  但有趣的地方来了。还有另外两位法官，莱恩勋爵（Lord Lane）和卡明-布鲁斯勋爵（Lord Cumming-Bruce）。他们审视的是完全相同的案件，完全相同的现实。
  莱恩勋爵说：*“根据村里的记录……在1976年7月26日，一个球差点打碎了他们儿子坐着的房间的窗户。他当时11或12岁。”*
  其他法官强调了房子里有一个**孩子**。他们提到了人身伤害的风险。米勒太太不仅仅是对财产感到“神经质”，她是一位担心孩子的母亲。
  **丹宁勋爵从未提到过这个儿子。**
  想一想。在他的“数据生成”过程中，他完全把孩子从叙事中删除了，因为这不符合他“板球对战疯女人”的故事线。
  如果你只读丹宁的判词，你会觉得她疯了。如果你读其他人的，你会看到合理的危险。
  这正是我们要说的数据生成。所谓的“事实”取决于你选择包含什么。输入数据决定了输出（判决）。丹宁勋爵把球称为“来自天堂的雷电”——他用诗意的语言来淡化人为的过失。
  （注：米勒夫妇实际上赢得了妨害诉讼，因为这确实构成了妨害，但法院拒绝发布停止板球的禁令，而是决定判给赔偿金。所以板球继续打，但他们得赔窗户钱）。

  [20:26 - 20:35] **Oakley v Birmingham City Council: Teleology**

  **English**
  The final case is **Oakley v Birmingham City Council (2000)**.
  **Facts**: The Oakleys lived in an old Victorian house. The toilet was separate and did not have a washbasin (sink). To wash their hands after using the toilet, they had to walk to the kitchen sink, crossing the food preparation area. They had young children.
  They sued the Council (the landlord) claiming this was a "**Statutory Nuisance**" under Section 79(1)(a) of the Environmental Protection Act 1990.
  **The Law**: The Act says a nuisance is "any premises in such a **state** as to be prejudicial to health."
  **The Argument**: Is the *layout* (the fact that the sink is far away) part of the *state* of the premises?
  **House of Lords Decision**: Lord Hoffmann (the highest judge) said **No**.
  Why? He said: *"On the surface, this does not look like a momentous case... but if we say yes, landlords of old houses all over the country will have to install sinks... Housing Trusts will incur considerable expense."*
  He argues it is a matter of **Public Funds**. It’s a constitutional question. Parliament should decide to spend that money, not judges. He distinguishes between the "state" (is the toilet broken? No) and the "layout" (is it badly designed? Yes). He says the Act covers "state," not "layout."
  **The Counter-Argument (Teleological)**:
  The lower courts and the dissenting opinion argued for a **Teleological Interpretation** (from Greek *telos*, meaning end/purpose).
  What is the purpose of the Act? To prevent disease and promote health.
  In the modern world, hygiene standards have changed. "Wash your hands" is basic. If the layout prevents hygiene, then the "state" is prejudicial to health. They argued the Act must be given a "sensible interpretation in the modern world."
  But the House of Lords rejected this "Broad View" in favor of a "Narrow View" to save money.
  They basically admitted: "We know it's unhygienic, but we can't afford to fix every house in England, so we will interpret the word 'state' to exclude 'layout'."
  They changed the meaning of the word to fit the economic outcome they wanted.

  **Chinese**
  最后一个案子是 **Oakley v Birmingham City Council (2000)**。
  **事实**：Oakley 一家住在一栋维多利亚时代的老房子里。厕所是独立的，里面没有洗手盆。上完厕所要洗手，他们必须走到厨房的水槽，这就要穿过食物准备区。这家人有小孩。
  他们起诉市政委员会（房东），声称根据《1990年环境保护法》第79(1)(a)条，这构成了“**法定妨害**”（Statutory Nuisance）。
  **法律**：法案规定，妨害是指“任何处于**某种状态**（state）以至于对健康有害的处所”。
  **争论点**：*布局*（洗手盆离得很远）是否属于处所的*状态*？
  **上议院裁决**：霍夫曼勋爵（Lord Hoffmann，最高法官）说**不属于**。
  为什么？他说：*“表面上看，这不像是一个重大的案件……但如果我们说是，全国所有老房子的房东都得安装洗手盆……住房信托基金将承担巨大的费用。”*
  他认为这是**公共资金**的问题。这是一个宪法问题。这笔钱应该由议会决定怎么花，而不是法官。他区分了“状态”（厕所坏了吗？没坏）和“布局”（设计得不好吗？是的）。他说法案涵盖的是“状态”，不是“布局”。
  **反方观点（目的论）**：
  下级法院和持反对意见者主张**目的论解释**（Teleological Interpretation，源自希腊语 *telos*，意为终点/目的）。
  法案的目的是什么？是为了预防疾病，促进健康。
  在现代世界，卫生标准已经变了。“洗手”是基本的。如果布局阻碍了卫生，那么这种“状态”就是对健康有害的。他们主张法案必须在“现代世界中得到合理的解释”。
  但上议院拒绝了这种“广义视角”，选择了“狭义视角”，就是为了省钱。
  他们基本上是在承认：“我们也知道这不卫生，但我们没钱修缮全英国的每一栋房子，所以我们将‘状态’一词解释为不包括‘布局’。”
  他们为了达到想要的经济结果，改变了词语的含义。

  [20:35 - 20:40] **Conclusion: Retro-Causality & The Logic of Love**

  **English**
  So, what is the lesson here?
  Logic works like a syllogism:

  1. **Major Premise** (The Law): All men are mortal. (Or: Section 79 requires a "state" prejudicial to health).
  2. **Minor Premise** (The Facts): Socrates is a man. (Or: This toilet layout is a "state").
  3. **Conclusion**: Socrates is mortal. (Or: This toilet is a nuisance).
  The law (Major Premise) is usually clear. The conclusion follows automatically. The fight is always about the **Minor Premise**—the facts.
  Is the layout a "state"? Did the ball hit the son?
  Judges often decide the conclusion *first* based on intuition, politics, or bias (e.g., "I want to save cricket," "We can't afford sinks"), and then they work backwards to construct the Minor Premise to fit.
  It is like **falling in love**.
  You don't analyze a person's data and then decide to love them. You fall in love first (Conclusion), and *then* you find reasons: "Oh, I love him because he is funny," or "because he has nice eyes." You justify the feeling with **Retro-Causality** (creating the cause after the effect).
  Legal reasoning is often the same. It is not an objective scientific process. It is a **Data Generating Process** where the output is justified by a constructed narrative.
  "It depends on the facts"—but *you* are the one creating the facts.
  This is why AI, which treats data as objective truth, will struggle to replicate high-level legal reasoning. The "truth" in law is created, not found.

  **Chinese**
  那么，这节课的教训是什么？
  逻辑通常像三段论一样运作：

  1. **大前提**（法律）：所有人都会死。（或者：第79条规定了对健康有害的“状态”）。
  2. **小前提**（事实）：苏格拉底是人。（或者：这个厕所布局是一种“状态”）。
  3. **结论**：苏格拉底会死。（或者：这个厕所构成了妨害）。
  法律（大前提）通常是清楚的。结论是自动得出的。争斗永远在于**小前提**——即事实。
  布局属于“状态”吗？球打中那个儿子了吗？
  法官通常基于直觉、政治或偏见*先*决定结论（比如“我想拯救板球”，“我们买不起洗手盆”），然后他们倒推，构建小前提来适配这个结论。
  这就像**坠入爱河**。
  你不会先分析一个人的数据然后决定爱上他。你是先爱上他（结论），*然后*找理由：“噢，我爱他是因为他很风趣，”或者“因为他眼睛好看。”你用**逆向因果**（Retro-Causality，在结果之后创造原因）来为这种感觉辩护。
  法律推理通常也是如此。它不是一个客观的科学过程。它是一个**数据生成过程**，其输出是由构建的叙事来正当化的。
  “这取决于事实”——但事实是*你*创造的。
  这就是为什么将数据视为客观真理的 AI 难以复制高水平的法律推理。法律中的“真相”是被创造出来的，而不是被发现的。

  [20:40 - End] **Lab Introduction: Anaconda & Google Colab**

  **English**
  Okay, in the remaining time, if you don't have any questions, we will go into your environment setup.
  I call this the **Anaconda Navigator** or you can use **Google Colab**.
  The difference is: with **Anaconda Navigator**, you are going to work on it **locally** (on your own computer), which is better sometimes in my opinion.
  Does **Google Colab** have problems? Sometimes it has **privacy problems**. That is why I was teaching you about servers and where data sits.
  With Anaconda, the data stays with you. With Google Colab, you are uploading it to the cloud.

  **Chinese**
  好了，在剩下的时间里，如果你们没有问题，我们来进入环境设置环节。
  我用的是 **Anaconda Navigator**，或者你们也可以用 **Google Colab**。
  区别在于：使用 **Anaconda Navigator**，你们是在**本地**（在自己的电脑上）操作，在我看来这有时更好。
  **Google Colab** 有问题吗？有时它会有**隐私问题**。这就是为什么我之前教你们关于服务器和数据存储位置的内容。
  使用 Anaconda，数据留在你这里。使用 Google Colab，你是把数据上传到云端。
## Week 3
  - [18:37 - 18:40] **Administrative Updates & Project Guidance: Text vs. Economic Data**

    Yeah, so. Just a bit of administrative stuff to start, right? I will have office hours from 5:00 to 6:30 PM on Thursdays as well, specifically to accommodate people's busy schedules. I hope you know, it’s... yeah. Okay, what else? Regarding the group projects, groups should be set right now. I think everybody is on the same page. As I mentioned to one of the groups that came to my office hours, there are essentially two avenues you can go down for your project. You can go the route of **text analysis** (NLP), or you can go the route of **data science** using numerical or economic data.

    Now, I honestly think it is harder to go the economic data route. Why? Because you are supposed to make machine learning algorithms—basically, you need to do **prediction**. You are supposed to make predictions for this class. Text is generally easier to do that with because there is a lot of text data available. What is everyone's project looking like? Let's sort of... nobody has any idea? Okay. One group has an idea because they came to my office, you know, they emailed me. Please email me! This is my job, right? Like, what is the point? What am I doing with my life if you don't? Anyway.

    I don’t see anything else yet, which is very interesting. So yeah, please email me. Try to find a topic. We will do some text data examples today. For example, as we discussed, there is the **ECHR data** (European Court of Human Rights). There are cases you can download. Please download them. This is the American equivalent, or you can look at how cases are decided in Texas. How would you do that? You would build a classification model—you know, ten types of outcomes. These are very big datasets, by the way, like you can't download the whole thing easily. But it is interesting. This is text data. Then there are Trump's tweets which we studied last week, right? Anything works as long as you can relate it to the coursework. Text is easier simply because there is a vast amount of unstructured text data out there. With economic data, you have to kind of look around, ask "do I find something else?" It's not that you can't do data science with numbers; it is just a bit harder because often there are not enough columns or features to make robust predictions.

    是的。好，先讲一些行政事务。为了配合大家忙碌的日程，我周四下午 5:00 到 6:30 也会安排办公时间（Office Hours）。希望大家知悉。好的，还有什么？关于小组作业，目前分组应该都已经确定了。我想大家的进度是一致的。正如我对其中一组来办公时间的同学提到的，你们基本上有两条路可选：一条是做**文本分析**（Text Analysis），另一条是做**数据科学**，比如使用经济数据。

    老实说，我认为做经济数据会更难一些。为什么呢？因为这门课要求你们编写机器学习算法，本质上是做**预测**。而文本数据更容易实现这一点，因为数据量非常大。大家的选题都怎么样了？还没人有想法吗？好吧，只有一组有想法，因为他们来了我的办公室，给我发了邮件。请给我发邮件！这是我的工作，对吧？否则我在这儿干嘛呢？总之，目前我还没看到其他组的进展，这很有趣。所以，请务必联系我。我们今天会做一些文本数据的例子。比如我们讨论过的 **ECHR（欧洲人权法院）** 数据，有些案例是可以下载的。或者你可以研究德克萨斯州的判决，建立一个分类模型。顺便说一下，这些数据集非常大。或者像我们上周研究的特朗普推文也可以。只要能跟课程联系起来就行。文本分析比较容易上手，因为现成的数据很多。而经济数据，你往往得四处寻找，而且有时候特征（columns）不够多，导致预测变得很困难。

  - [18:40 - 18:43] **Gottfried Wilhelm Leibniz: The Last Universal Genius**

    Okay, so we begin with a figure I have been fascinated with ever since... well, when I was starting out, no, I actually hated it. I was like, "This is the worst. Why am I doing this? What is this?" But in my final year, I took a course on European legal systems and there we studied, unbelievably, we studied **Leibniz**. Any engineers in the room? Any math or computer science people? Who knows Leibniz? Ah, for the biscuits? Yes, the **Leibniz-Keks**! No, it’s not just about the biscuit. Who is like this? Why don't you know him? Nobody knows. I thought when I asked undergrads, I understood why they didn't know. But with adults here... well, we have children and whatnot, I don't have to think about that.

    Anyway, this guy, Gottfried Wilhelm Leibniz. He is a coding man. Calculus! Everybody knows Calculus. I mean, everybody hates Calculus, but he invented it alongside Newton. This proves that in science, there is a debate... sometimes discoveries happen in completely different places at the same time. Some argue this proves that intelligence is not strictly human, because people who never met each other come up with the same ideas. Anyway, he is a complete genius, this guy. It is unbelievable. He did his Bachelor's at like 15 or 16 years old. He finished his Doctorate at 18 or 19. Complete, utter genius.

    Now, what is interesting about this guy? He made major contributions to physics. He is often called the "last universal genius." He invented binary arithmetic, by the way. He based it on the **Chinese I Ching** (Book of Changes). He looked at the hexagrams and was like, "You know, this is binary. Something is here." He was one of the first to study Chinese texts in history. He studied music. Basically, all of modern math and probability is based on this guy. So why are we talking about him in a class on Goal Regulation and AI? Because he invented Calculus—the calculus of infinitesimals, the area under the curve. People used to use Newton's notation, but Leibniz's notation was preferred. Now we use Leibniz's notation. It's crazy.

    好，我们开始讲一位我一直非常着迷的人物。虽然刚开始接触时，我其实很讨厌这些内容，心想“这太糟糕了，我为什么要学这个？”但在我最后一年的课程里，我选修了欧洲法律体系，不可思议的是，我们研究了**莱布尼茨（Leibniz）**。在座有工程师吗？有学数学或计算机的吗？有人知道莱布尼茨吗？啊，是因为那个**莱布尼茨饼干（Leibniz-Keks）**吗？是的，饼干很出名，但不仅仅是饼干。怎么没人知道他呢？我本来以为问本科生他们不知道就算了，但在座的各位是成年人……总之，这个人叫戈特弗里德·威廉·莱布尼茨。

    他是编程界的鼻祖。微积分！大家都知道微积分吧？我是说，虽然大家都讨厌微积分，但他和牛顿同时发明了微积分。这证明了科学界的一个争论：有时候伟大的发现会在完全不同的地方同时发生。有人甚至认为这证明智慧不仅仅属于人类，因为互不相识的人能想到一起去。总之，这家伙是个彻头彻尾的天才，简直难以置信。他大概15、16岁就拿了学士学位，18、19岁就读完了博士。绝对的天才。

    关于他有什么有趣的地方呢？他被誉为“最后一位全才”。顺便说一下，是他发明了**二进制算术**。依据居然是中国的**《易经》**。他看到卦象后说：“看，这就是二进制。”他是历史上最早研究中文典籍的学者之一。他还研究音乐、概率论。基本上现代数学都建立在他的基础上。那么，我们为什么要在AI和规则监管的课上谈论他？因为他发明了微积分，解决了无穷小量的计算问题。虽然牛顿也发明了，但莱布尼茨的符号系统更好用，也就是我们要现在沿用的这一套。这太疯狂了。

  - [18:43 - 18:47] **Leibniz’s Two PhDs & The Dream of "Calculemus" (Let Us Calculate)**

    Here is something very interesting about this guy. He had **two PhDs**. He did two PhDs by the age of 20 or something. I barely survived my one! He did two. His first PhD, before he did math, was titled *"De Casibus Perplexis in Jure"* or **"Inaugural Disputation on Ambiguous Legal Cases."** So his first PhD is in **Law**. I am very proud of this person. But this genius took me over... you can read it online if you don't know that. His second PhD was in Math. So he was first a law person, then a mathematician.

    He was trying to find a mathematical way of resolving disputes. Why? Because Leibniz lived in a very difficult time: the **European Wars of Religion** (essentially the Thirty Years' War context). There were crazy wars happening all over Europe for like 200 years. People were basically debating Catholicism versus Protestantism, and they would kill each other over it. I think something like 30% of the German population was killed. It was a very violent force. And he was living through this time, and he was very interested in resolving these disputes. It was literally a life-and-death situation. He thought: people are debating, and nobody can convince the other side. But if there was an **objective way** of resolving disputes, we would be able to resolve them without violence.

    In the 1660s, he wrote these letters—it’s called *"On the Universal Science: Characteristic Numbers."* So when people say, "Oh, we are so much more advanced than people of the past," I think there is something wrong with that. He already foresaw trying to represent concepts and language as a number. He writes: *"And an old saying affirms that God made all things according to weight, measure, and number."* He argues that while some things lack force or parts, *"there is nothing which does not submit to numbers."* Therefore, numbers are a metaphysical figure. He is a fascinating guy. He also says that people who hate math are actually doing math all the time when they listen to music, because recognizing frequencies is actually a calculation in your head.

    这里有一件非常有趣的事。莱布尼茨拥有**两个博士学位**。他在20岁左右就拿到了两个博士。我读一个都差点没熬过来！他的第一个博士学位，在学数学之前，题目是《论法律中的疑难案件》（*De Casibus Perplexis*）。所以，他的第一个学位是**法学**。我很为他感到骄傲。他的第二个博士才是数学。所以他首先是一个法律人，然后才是数学家。

    他试图寻找一种用数学方法解决争端通过途径。为什么？因为莱布尼茨生活在一个非常艰难的时代——**欧洲宗教战争**（三十年战争时期）。当时欧洲各地战火连天，持续了近两百年。人们争论天主教与新教，一言不合就互相杀戮。我想当时德国大概有30%的人口因此丧生。极其暴力。他生活在那个时代，非常希望能解决这些争端，因为这真的是生死攸关。他想：人们在辩论，但谁也说服不了谁。如果有一种**客观的方法**来解决争端，我们就能避免流血。

    他在1660年代写了一些信件，题为《论通用科学：特征数字》。所以当现代人说“哦，我们要比过去的人先进得多”时，我觉得这不完全对。莱布尼茨早就预见到了用数字来代表概念和语言。他写道：“古语有云，上帝依据重量、尺度和数字创造万物。”他认为，虽然有些事物没有实体，但“没有任何事物是不服从于数字的”。因此，数字是一种形而上的符号。他真是个迷人的人。他还说，那些讨厌数学的人其实在听音乐时也在做数学，因为辨别频率本质上就是大脑在进行计算。

  - [18:48 - 18:51] **The Limits of Human Reason & The "Merchants" Analogy**

    Towards the end, he says something very profound. He notes that usually, scrutinizing things demands an effort of many weeks. *"If only we could understand how people reason."* He observes that in controversies—like Protestantism vs. Catholicism, or in law courts—emotion often triumphs over reason. Controversies are ended "by the mere cutting of the **Gordian Knot** rather than by untying it." This happens mainly in deliberations pertaining to life, where something has to be decided, but you are unable to examine the pros and cons which are often many, as if on a scale of balance.

    He says: *"Therefore, two disputing persons seem to me to resemble **two merchants** who have long been in each other's debt on many counts, but who never wanted to perform an examination of their accounts by means of a general balance. Instead, each keeps exaggerating their own credits... Obviously, they will never put an end to their contest."* He is saying everybody keeps exaggerating their own side. How do you decide these things? *"If only we could put it into numbers, we would be able to resolve things."* He famously said that if we had this system, two philosophers would no longer need to argue; they would sit down, take their pens, and say to each other: **"Calculemus"** (Let us calculate).

    He is basically foreseeing what we are seeing right now with AI and computational law. Do you see how crazy this is? Am I crazy to think this is interesting? He is saying if there was an objective measure, we could use it. Lawyers have been dreaming of this for 3,000 years—to bypass stupid, biased judges with a universal method. For some reason, we haven't succeeded. Now people think AI will finally solve this. I don't think so. If a genius who invented Calculus couldn't solve it, I don't think a person from OpenAI—whose wage is determined by the share price and has a clear agenda—is going to resolve it objectively.

    在文章的最后，他说了一段非常深刻的话。他指出，通常仔细审查一件事需要数周的努力。“如果我们能理解人们是如何推理的就好了。”他观察到，在争论中——比如宗教之争或法庭辩论——情感往往战胜了理智。争论的结束往往是像斩断**戈尔迪之结（Gordian Knot）**那样强行了断，而不是解开它。这主要发生在生活中必须做出决定，但又无法像天平一样精确衡量利弊的时候。

    他打了个比方：“因此，两个争论的人在我看来就像**两个商人**，彼此长期有多笔债务往来，但从未想过通过总账来核对。相反，每个人都在夸大别人欠自己的账……显然，这种争论永远不会结束。”他的意思是，每个人都在自说自话。怎么解决呢？“如果我们能将其转化为数字，我们就能解决问题。”他有一句名言：如果有了这个系统，两个哲学家就不需要争吵了，他们只需坐下来，拿起笔，对彼此说：**“Calculemus”**（让我们来计算吧）。

    他基本上预见到了我们要现在在AI和计算法学中看到的一切。这不疯狂吗？难道只有我觉得这很有趣吗？他在说如果有一个客观的标准就好了。这也是律师们三千年来梦寐以求的——用一种通用的方法来绕过那些愚蠢、有偏见的法官。但不知为何，我们至今没能成功。现在有人认为AI最终会解决这个问题。我不这么认为。如果连发明微积分的天才都解决不了，我不认为OpenAI的人——那些工资与股价挂钩、有着明显商业企图的人——能客观地解决这个问题。

  - [18:51 - 18:53] **The Geometrical Method (\*Mos Geometricus\*) and Justice**

    Leibniz adopts a very interesting perspective called the **Geometrical Method**. In his *Elements of Natural Law*, he says: *"The doctrine of law belongs to those sciences that depend on definitions and not on experience, on demonstrations of reason and not on sense."* He argues that justice consists in congruence and proportionality. We can understand that something is "just" even if there is no one acting justly, in the same way that the concepts of numbers are true even if there were no one to count and nothing to be counted. We can predict that a house will be beautiful or a machine efficient if it comes into being, even if it never actually exists.

    He was writing this at the age of 20! When I was 20, I was all over the place. He was thinking about how you can understand justice without people acting justly. Think about numbers. **Numbers don't exist** in the physical world. There are objects—there is *one* mouse here—but the "Number One" itself doesn't exist physically. Who can show me the number one? It is a concept. He is saying these legal concepts exist universally, even if there was nothing to be counted. He is trying to build a system from that. That is very deep.

    莱布尼茨采用了一个非常有趣的视角，称为**几何学方法（Mos Geometricus）**。在他的《自然法原理》中，他说：“法学属于那些依赖定义而非经验、依赖理性证明而非感官的科学。”他认为正义在于一致性和比例性。即使没有人做出正义的行为，我们依然可以理解什么是“正义”，就像即使没有人去数数，或者没有任何东西可数，数字的概念依然是真理一样。这就好比我们可以预言一座房子是漂亮的，或者一台机器是高效的（只要它被造出来），即便它永远没被造出来。

    写这话时他才20岁！我20岁的时候还浑浑噩噩的。他却在思考如何在没有正义行为的情况下理解正义。想想数字。**数字在物理世界中是不存在的**。只有物体——比如这里有“一只”鼠标——但“一”这个数字本身并不存在。谁能把“一”拿给我看？它是一个概念。莱布尼茨认为，这些法律概念是普遍存在的，即使没有具体的对象。他试图以此构建一个系统。这非常深奥。

  - [18:53 - 18:58] **Deductive Systems, Syllogisms, and Savigny’s Triangles**

    After completing his two PhDs, he kept going. They wanted to build a **Deductive System**. What is deduction? We mentioned it last time. Deduction as opposed to Induction, and as opposed to Analogies. The classical deduction used in law is the **Syllogism**.

    There is a book by **Antonin Scalia**—who is Antonin Scalia? Anybody know his name? He was a well-known, very famous conservative Justice of the US Supreme Court. He died recently. He wrote a book called *Making Your Case* (and *Reading Law*). He says: *"Thinking syllogistically, leaving aside emotional appeals, is something we all have in common. The most rigorous form of logic, and hence the most persuasive, is the syllogism."*

    The structure is:

    1. **Major Premise:** The law (e.g., Prisoners have a claim for harm caused by deliberate indifference).
    2. **Minor Premise:** The facts (e.g., Guards ignored the plaintiff's abdominal pain for 48 hours).
    3. **Conclusion:** Therefore, the prisoner has a claim.

    Everything he says is about this classical deductive reasoning. Simple genius. He says put everything in a syllogism and it will convince anyone. And he is not just some guy off the street; he is a Supreme Court Justice.

    About 200 years after Leibniz, there was a famous German jurist named **Friedrich Carl von Savigny** ("Saudi" in the audio is a mishearing). He said: *"In principle, it would be possible to draft definitions that would extend to any case that might arise... It may be illustrated by technical expressions of **geometry**."* He compares law to a **triangle**. In every triangle, if you are given two sides and an angle, all the rest is deducible. In like manner, every part of our law has "leading axioms" from which the rest may be given. He thought if I know the rules, I can predict and decide every case, whether it is a huge triangle or a tiny triangle. Can you imagine this? Jurists talking about mathematics and geometry to create a system where you can predict every outcome.

    完成两个博士学位后，他继续探索。他们想要构建一个**演绎系统**（Deductive System）。什么是演绎？我们上次提到了。演绎是相对于归纳（Induction）和类比（Analogy）而言的。法律中经典的演绎形式是**三段论**（Syllogism）。

    有一本书是**安东宁·斯卡利亚（Antonin Scalia）**写的——谁是斯卡利亚？有人知道吗？他是美国最高法院一位非常著名、非常保守的大法官。他前几年去世了。他写过一本叫《法官裁判与律师辩论的艺术》（Making Your Case）的书。他说：“抛开情感诉求，进行三段论式的思考是我们人类的共同点。最严密的逻辑形式，因此也是最有说服力的，就是三段论。”

    其结构是：

    1. **大前提**：法律原则（例如：囚犯有权就狱方故意忽视其严重医疗需求造成的伤害提出索赔）。
    2. **小前提**：事实（例如：狱警无视了原告持续48小时的剧烈腹痛）。
    3. **结论**：因此，该囚犯有索赔权。

    他所说的一切都是关于这种经典的演绎推理。简单而天才。他说只要把一切放入三段论，就能说服任何人。他可不是路边的普通人，他是最高法院的大法官。

    在莱布尼茨之后约200年，有一位著名的德国法学家叫**萨维尼（Savigny）**。他说：“原则上，我们有可能起草出涵盖任何可能案件的定义……这可以用**几何学**来类比。”他把法律比作**三角形**。在任何三角形中，如果你知道两条边和一个夹角，其他的就能推导出来。同样，法律的每个部分都有“主导公理”，由此可以推导出其余部分。他认为只要掌握了规则，就能预测和裁决每一个案件，不管这三角形是大是小。你能想象吗？法学家们大谈数学和几何，试图建立一个能预测所有结果的系统。

  - [18:58 - 19:06] **Why Deduction Failed: The Gap Between Altruism and Property**

    Why did it fail? Now we think we are smarter, we have computers, we are the best. But why did their project fail?

    *(Student speaks: "It's not just facts, it's reasoning... logical touch... not identical.")*

    Yes, reasoning is involved. They claimed that if we have a million triangles, they all follow the same rules. But you are saying even within rules, there are differences.

    *(Student speaks: "Altruism... disjoint between higher principles and property rights.")*

    Exactly. This is the problem. If you are constructing a deductive system, everything has to go *up* to the main axioms. What is the main axiom of Contract Law? **"Pacta Sunt Servanda"**—agreements must be kept. You will sound fancy next time you go to a restaurant if you say that. But where does this principle come from? It has to link to a higher principle.

    For Leibniz, the difficulty was linking general principles like **Altruism** to individual laws like Tort or Contract. He defines Justice as "the habit of loving everyone" (Charity of the Wise). He has these 26 definitions in his book: *"A person is one who loves himself... A good man is one who loves everyone... Nothing just is unjust."* He is really trying to construct a logical system to explain everything—contracts, torts, criminal law—from these high-level definitions of love and altruism.

    But here is the failure: **You cannot move deductively from the principle of Altruism to the principle of Private Property.** Think about it. It is impossible. If the highest principle is "Love everyone," how do you justify excluding people from your private property? Or if I make noise on my property (Nuisance), I have power over my land, but my neighbor has a right to stop it. How do you logically deduce that conflict from "Altruism"? You can't. There is a gulf between the higher principles and the lower concepts. They believed they could deduce immutable principles of law from human nature, but it failed because of this gap.

    为什么这个计划失败了？现在我们觉得自己更聪明，有电脑，是最棒的。但他们的计划为何落空？

    *（学生发言：“不仅仅是事实，还有推理……逻辑接触……并不完全相同。”）*

    是的，这涉及推理。他们声称即使有一百万个三角形，它们都遵循相同的规则。但你的意思是，即使在规则之内，也存在差异。

    *（学生发言：“利他主义……最高原则和财产权之间存在脱节。”）*

    完全正确。这就是问题所在。如果你要构建一个演绎系统，一切都必须能**向上**追溯到主要公理。合同法的主要公理是什么？**“Pacta Sunt Servanda”**——契约必须遵守。下次你去餐厅说这个词会显得很有学问。但这个原则从何而来？它必须连接到一个更高的原则。

    对莱布尼茨来说，困难在于如何将**利他主义（Altruism）**这样的一般原则与侵权法或合同法等具体法律联系起来。他将正义定义为“爱所有人的习惯”（智者的仁慈）。他在书中列出了26个定义：“人是爱自己的人……好人是爱所有人的人……正义之事绝非不正义。”他真的试图构建一个逻辑系统，用这些关于爱和利他主义的高级定义来解释一切——合同、侵权、刑法。

    但这就是失败之处：**你无法从“利他主义”原则演绎推导出“私有财产”原则。** 想想看，这几乎是不可能的。如果最高原则是“爱所有人”，你如何证明把别人排除在你的私有财产之外是正当的？或者如果我在自己的地盘上制造噪音（妨害罪），理论上我有权处理我的土地，但我的邻居有权阻止我。你怎么从“利他主义”逻辑地推导出这种冲突的解决方案？你做不到。在高级原则和低级概念之间存在一道鸿沟。他们相信可以从人性中推导出不可变的法律原则，但正是因为这道鸿沟，他们失败了。

  - [19:07 - 19:16] **Demystifying Legal Reasoning: \*Miller v. Jackson\* and the 6 Schemes**

    This moves us to the next reading. There is a paper by **Geoffrey Samuel** called *"Demystifying Legal Reasoning."* I am always proud to say he was my professor. Nothing I say is mine; I am really just copying him. He asks: Why has it proved impossible to program a computer to think like a lawyer? It should be simple deduction, right?

    The problem is that lawyers don't just deduce; they construct **images**. They draw a picture in their mind using facts. He identifies **6 Schemes of Intelligibility** using the famous case of ***Miller v. Jackson\***. Do you remember this case? Since about 1905, cricket had been played on a village field. A woman bought a house next to it and kept getting hit by balls. She sued to stop the cricket. If you know these 6 schemes, you can argue your way out of any situation.

    1. **Causal Scheme:** You construct the cause. Is the damage caused by the cricket balls? Or is it caused by the claimant's own act of *buying a house* next to a cricket ground? You can choose the cause to fit your argument.
    2. **Functional Scheme:** Cricket is not just a game; it serves a social function. It preserves village life, stops crime, gives young men something to do. Therefore, it is "reasonable" because of its function.
    3. **Structural Scheme:** Fact A (cricket) is part of a social structure. Imposing liability would disturb the equilibrium of the social system. The individual can have their rights adjusted (e.g., cheaper house price) to compensate for the inconvenience caused by legitimate social activities.
    4. **Hermeneutic Scheme:** Interpretation of signs. The woman’s objection isn't just an objection; it signifies that she is an *unreasonable person*. The text implies she is obsessive, while the cricketers are reasonable.
    5. **Actional Scheme:** Framing it as a conflict between actors: The "Newcomer" (who hates cricket) vs. The "Established" (the team of 1905). It becomes natural that there is a conflict based on who they *are*.
    6. **Dialectical Scheme:** A contradiction between the interest of the **Public** (cricket, society) and the interest of the **Private Individual**.

    The judge doesn't just apply rules mechanically like a Google search. The judge uses these schemes to "insert" themselves into the facts and construct a reality that suggests the legal result.

    接下来我们讲下一篇阅读材料。这是**杰弗里·塞缪尔（Geoffrey Samuel）**写的一篇论文，叫《揭秘法律推理》。我很自豪地说他是我的教授。我说的东西都不是我原创的，我只是在模仿他。他问道：为什么要把电脑编程得像律师一样思考这么难？这本该是简单的演绎推理，对吧？

    问题在于，律师不仅仅是在做演绎，他们是在构建**图像**。他们利用事实在脑海中画图。他利用著名的***Miller v. Jackson\***（米勒诉杰克逊案）总结了**6种可理解性图式（Schemes of Intelligibility）**。还记得这个案子吗？大约从1905年起，有人就在这块村里的场地上打板球。后来一个女人在旁边买了房子，总是被球砸到。她起诉要求停止打球。如果你掌握了这6种图式，你在任何情况下都能为自己辩护。

    1. **因果图式**：你构建原因。损害是由板球造成的吗？还是因为原告自己*买房买在板球场旁边*这一行为造成的？你可以选择有利于你论点的原因。
    2. **功能图式**：板球不仅仅是游戏，它具有社会功能。它维系乡村生活，预防犯罪，让年轻人有事可做。因此，基于其功能，它是“合理”的。
    3. **结构图式**：事实A（板球）是社会结构的一部分。追究责任会打破社会系统的平衡。个人的权利可以被调整（比如房价便宜了），以补偿合法社会活动带来的不便。
    4. **诠释学图式**：对符号的解释。那个女人的反对不仅仅是反对，这象征着她是一个*不讲理的人*。判决暗示她偏执，而板球运动员是理性的。
    5. **行动图式**：将其构建为角色之间的冲突：“新来者”（讨厌板球）对战“原住民”（1905年就在那的球队）。基于他们的身份，冲突变得理所当然。
    6. **辩证图式**：**公共利益**（板球、社会）与**私人利益**之间的矛盾。

    法官不仅仅是像谷歌搜索那样机械地应用规则。法官利用这些图式将自己“嵌入”事实中，构建出一个能够暗示法律结果的现实。

  - [19:16 - 19:26] **AI’s Brittleness & The Authority Paradigm (Theology)**

    Samuel argues that rule-based AI systems are **"brittle"**—like glass, they break easily. If you try to capture every phenomenon with a rule, you need infinite exceptions. But cognitive systems (human thinking) are not governed by rigid rules; they are approximate.

    He also discusses the **Authority Paradigm**. Law is more like Theology than Science. In Science (Inquiry Paradigm), you need a hypothesis, experiments, and falsifiability. In Law (Authority Paradigm), truth comes from the source of authority.

    Consider the case involving the **Crown Prosecution Service (CPS)** (likely *Elguzouli-Daf* or *Hill*). The question was: Should the CPS be liable for negligence if they mistakenly imprison someone? The judge said NO. Why? He argued that a duty of care would cause a "defensive approach" by prosecutors, wasting time and resources to protect themselves rather than prosecuting crime. He essentially said: "It is better for society if we don't hold them liable."

    Is this true? Where is the statistical evidence? A sociologist making such a claim without data would be laughed at. But in law, we accept the judge’s assertion as truth simply because he has Authority. It takes place in a "virtual text" or "virtual reality." It is like a taxi driver telling you, "We need more roads." It’s just an opinion, but in law, it becomes binding fact. This is why Law is the "Priest of Law"—it’s a closed system like Theology.

    塞缪尔认为，基于规则的AI系统是**“脆弱的”（Brittle）**——像玻璃一样易碎。如果你试图用规则捕捉每一个现象，你需要无数的例外。但认知系统（人类思维）并非由僵化的规则主导，而是近似的。

    他还讨论了**权威范式（Authority Paradigm）**。法律更像神学而不是科学。在科学（探究范式）中，你需要假设、实验和可证伪性。在法律（权威范式）中，真理来自权威的源头。

    想想那个涉及**皇家检察署（CPS）**的案子（可能是 *Elguzouli-Daf* 或 *Hill* 案）。问题是：如果CPS错误地监禁了某人，他们应该承担过失责任吗？法官说“不”。为什么？他辩称，注意义务会导致检察官采取“防御性手段”，浪费时间和资源来保护自己，而不是专注于起诉犯罪。他本质上是在说：“如果我们不追究他们的责任，对社会更好。”

    这是真的吗？统计证据在哪里？如果社会学家在没有数据的情况下做出这种断言，会被人嘲笑。但在法律中，我们接受法官的断言为真理，仅仅因为他拥有权威。这发生在一个“虚拟文本”或“虚拟现实”中。这就像出租车司机跟你说“我们需要修更多的路”。这只是个观点，但在法律中，它变成了有约束力的事实。这就是为什么法律人被称为“法律的祭司”——它像神学一样是一个封闭的系统。

  - [19:27 - 19:36] **Induction (Dandelions) vs. Analogy (Electricity & Water)**

    Finally, he discusses other reasoning methods.

    **Induction:** Suppose you want to know if **dandelions** grow in Singapore. An empirical (inductive) approach means you organize an expedition, search every corner of Singapore. It takes forever.

    **Deduction:** You research the climatic conditions dandelions need (Rule). You check Singapore’s climate (Fact). If the conditions don't match, you conclude they don't grow there without ever visiting. That is the beauty of deduction—you don't need to gather all the data if you know the rules.

    **Analogy:** This is the weakest link, yet law uses it constantly. It’s based on similarity. Example: "A & B (King and Country) are similar to X & Y (Father and Son)." Is that true? It is unfalsifiable.

    Consider **Electricity**. In a famous case, the court had to decide if escaping electricity creates strict liability. They used an analogy to ***Rylands v. Fletcher\***, which was about escaping **Water**. They said electricity is like water—it flows, it escapes, it causes damage. Therefore, the water rule applies. But is electricity *really* like water? Water doesn't electrocute you (usually).

    Another example: **Oil Pollution**. In *Esso Petroleum*, Denning (or the court) had to decide if oil discharged from a ship is a trespass. They used an analogy to **traffic accidents** (*Holmes v. Mather*). They said an accident on water is like an accident on the highway—you need negligence, not just trespass. But is an oil spill really like a car crash? Analogy depends entirely on which features you choose to compare. It is subjective, yet it drives Supreme Court decisions.

    最后，他讨论了其他的推理方法。

    **归纳法（Induction）**：假设你想知道**蒲公英**是否在新加坡生长。实证（归纳）的方法意味着你组织一支探险队，搜索新加坡的每一个角落。这需要花费很长时间。

    **演绎法（Deduction）**：你研究蒲公英生长所需的气候条件（规则）。你查看新加坡的气候（事实）。如果条件不匹配，你不需要去新加坡就能得出结论：那里不长蒲公英。这就是演绎的美妙之处——如果你知道规则，就不需要收集所有数据。

    **类比法（Analogy）**：这是最薄弱的一环，但法律一直在使用它。它基于相似性。例子：“A和B（国王与国家）类似于X和Y（父亲与儿子）。”这是真的吗？这是不可证伪的。

    想想**电力**。在一个著名的案例中，法院必须判定泄漏的电流是否构成严格责任。他们类比了***Rylands v. Fletcher\*** 案，那个案子是关于**水**的泄漏。他们说电像水一样——它流动，它泄漏，它造成损害。因此，水的规则适用。但是电*真的*像水吗？水通常不会电死你。

    另一个例子：**石油污染**。在 *Esso Petroleum* 案中，丹宁勋爵（Lord Denning）或法院必须判定船只排放石油是否构成侵权。他们类比了**交通事故**（*Holmes v. Mather*）。他们说水上的事故就像公路上的事故——你需要证明过失，而不仅仅是侵入。但石油泄漏真的像车祸吗？类比完全取决于你选择比较哪些特征。它是主观的，但它却主导了最高法院的判决。

  - [19:40 - 19:47] **Heidegger’s Hammer: Ready-to-Hand vs. Present-at-Hand**

    You wrote this book, *Being and Time*. It is an understanding of reality. But I can use it very simply. Simply put: I give you a hammer. I don't ask you, "What is the hammer made of?" What is the chemical composition of the metal inside it? That is **data**. If I am a scientist, I study that. But that is not actually how you interact with objects. Heidegger says that 99% of our interaction with the world is based on **Readiness-to-Hand** (*Zuhandenheit*). I don't teach you how to use a computer; I don't teach you how to read a book—I mean, I have to teach you the letters, but the act of reading itself is not a cognitive thing once you know it.

    This separation is non-cognitive. Let me use an example to help make Heidegger's point. I might make a catalog of the items in my study: I have a chair, a desk, a desktop computer, papers, articles, books, filing cabinets, pencil sharpeners, staplers, pencils, and so on. Just in the act of making this catalog, I have changed my relationship with these items. I find myself looking about the study, individuating the items, and adding them to a list. In doing this, I view them as **Present-at-Hand** (*Vorhandenheit*). They are presented to me in a bare perception. They are mere "things" available to a detached looking.

    But this hides their more basic way of being. Equipment exists most basically as things which are **Ready-to-Hand**. That is, these items exist for me as things which I *do* various things with. They exist as something "in-order-to." The phone is "in-order-to" call. The chair exists for me "in-order-to" sit. The table "in-order-to" work. The pencil "in-order-to" write. When we deal with what is Ready-to-Hand—using things for purposes—this readiness is not understood thematically or theoretically. Heidegger claims you cannot put this into a theoretical mode or write it on paper. It is empirical; I just do it. If I try to explain it, it becomes a huge volume of instructions. We know these things through what Heidegger calls **Circumspection**—the kind of sight we have when we manipulate things.

    The example of the hammer is particularly important. Heidegger says the less we just stare at the hammer-thing, and the more we seize hold of it and use it, the more primordial our relationship becomes. "Primordial" means *before*. Before I even think of this object as a "phone," I am already using it.

    你写了《存在与时间》（Being and Time）这本书，这是对现实的一种理解。但我可以用很简单的例子来说明。简单来说：我给你一把锤子。我不会问你“这把锤子是什么做的？”，或者“里面的金属化学成分是什么？”那是**数据**。如果我是科学家，我会去研究那个。但这并不是你与物体互动的真实方式。海德格尔说，我们与世界99%的互动都是基于**上手状态**（*Zuhandenheit*，Ready-to-Hand）。我不需要教你如何使用电脑，也不需要教你如何读书——虽然我得教你认字，但一旦学会了，读书这个行为本身就不是一个认知过程了。

    这种区分是非认知的。让我举个例子来阐明海德格尔的观点。假设我给书房里的物品做一个目录：我有一把椅子、一张桌子、一台台式电脑、文件、文章、书、档案柜、卷笔刀、订书机、铅笔等等。仅仅在制作这个目录的过程中，我就改变了我和这些物品的关系。我环顾书房，把这些物品个体化，加入清单。此时，我是把它们看作**现成在手**（*Vorhandenheit*，Present-at-Hand）。它们以一种赤裸的感知呈现给我，它们仅仅是供我冷眼旁观的“物”。

    但这掩盖了它们更基本的生存方式。器具最基本的生存方式是**上手状态**。也就是说，这些物品对我而言，是我用来*做*事情的东西。它们作为某种“为了……”（in-order-to）而存在。电话是为了打电话，椅子是为了坐，桌子是为了工作，铅笔是为了写字。当我们处理上手事物时——即为了某种目的使用它们——这种上手性并不是通过理论来理解的。海德格尔声称你无法将其理论化或写在纸上。它是经验性的，我只是去用它。如果非要解释，那会变成长篇大论的说明书。我们是通过海德格尔所谓的**寻视**（Circumspection）——即我们在操作事物时拥有的那种眼光——来认识这些事物的。

    锤子的例子尤为重要。海德格尔说，我们要越少盯着锤子看，越多地抓起它去使用，我们与它的关系就越**原始**（Primordial）。“原始”意味着*在此之前*。在我甚至还没把这个物体概念化为“电话”之前，我就已经在使用它了。

  - [19:47 - 19:54] **Non-Cognitive Social Norms, Merleau-Ponty, and Dasein**

    Why would these skills not admit translation into propositions expressing rules governed by behavior? Heidegger argues that it is breathtakingly difficult to put this daily use into explicit theoretical data. For example, he talks about his wife. As he wrote a preceding part, his wife came into the study, started reading over his shoulder, and then rested her hand on his shoulder (or her knee against his). Without thinking about it, she knew that it was okay to do so. Similarly, without thinking, she knows it would *not* be okay to do the same thing presumably to a stranger. We all possess, to a very high degree, the practical know-how regarding personal space and physical contact. But does anyone think we could produce a comprehensive book describing the Do's and Don'ts of personal space? I think he denies the possibility because these practical skills do not admit of theoretical articulation.

    He also talks about getting dressed. Just consider the task of getting dressed. We do so much better than the man in *The New Yorker* cartoon, who is sitting on his bed looking at a sign he posted on the wall that lists the rules for putting on pants! Eventually, a rulebook will hardly help any of us get dressed. Think of the issue of deciding what to wear—degrees of appropriate formality, comfort, practicality. It is complex. But what's worse is that it is not apparent that we could ever fully capture this in theoretical form. We do it so easily, but theoretically, it is problematic.

    This relates to another philosopher, **Maurice Merleau-Ponty**. He locates the core of this background in our orientation towards the world through our embodiment—our physical bodies, our rhythm, movement. Our physical presence in the classroom determines intelligibility. We are literally a body of a certain height and weight. This existence cannot be put into theory.

    And this leads to Heidegger's term: **Dasein**. My friend at Berkeley would correct me: "It's not 'humans', it is *Dasein*." It means **"Being-There."** It's about existence. One of the fundamental things about humans is **Care** (*Sorge*). We care about things. How can you put "care" into data? We can't.

    为什么这些技能无法转化为表达行为规则的命题？海德格尔认为，要把这种日常使用转化为显性的理论数据是极其困难的。例如，他谈到了他的妻子。当他在写作时，妻子走进书房，在他身后阅读，然后把手搭在他肩上（或者膝盖靠着他）。她想都没想就知道这样做是可以的。同样，她想都没想就知道，如果对方是陌生人，这样做大概就是*不*可以的。我们在个人空间和身体接触方面都拥有高度的实践知识。但有人认为我们可以写出一本关于个人空间“行为准则”的百科全书吗？海德格尔否认了这种可能性，因为这些实践技能无法被理论化地表达。

    他还谈到了穿衣服。想想穿衣服这件事。我们比《纽约客》漫画里的那个男人强多了——他坐在床边，盯着墙上贴的一张“穿裤子指南”看！实际上，规则书根本帮不了我们穿衣服。想想决定穿什么衣服的复杂性——要在正式程度、舒适度、实用性之间权衡。这很复杂。更糟糕的是，我们似乎永远无法用理论形式完全捕捉这一过程。我们做起来很轻松，但在理论上，这是个大问题。

    这联系到另一位哲学家，**莫里斯·梅洛-庞蒂（Maurice Merleau-Ponty）**。他认为这种背景的核心在于我们通过**具身性**（Embodiment）对世界的定位——我们的肉身、节奏、运动。我们在教室里的物理存在决定了可理解性。我们是具有特定身高体重的实体。这种生存状态是无法放入理论中的。

    这就引出了海德格尔的术语：**此在**（*Dasein*）。我在伯克利的朋友总是纠正我：“那不叫‘人类’，那叫‘此在’。”意思是**“存在于彼”**（Being-There）。它是关于生存的。人类的一个基本特征是**操心**（*Sorge*，Care）。我们在乎事物。你怎么把“在乎”变成数据？我们做不到。

  - [19:54 - 20:02] **Legal Realism: Llewellyn, Holmes, and the Broken Churn**

    How does this relate to Law? We are reading a Law Review article from Yale. It discusses the **Theory of Adjudication**—how judges *should* decide cases versus how they *do* decide cases. Consider **Karl Llewellyn**'s famous loss on the "Strict Doctrine of Precedent." According to the strict doctrine, a rule is confined to the particular facts.

    Consider the story of a Vermont Justice of the Peace mentioned by Holmes. A suit was brought by one farmer against another for breaking a **Churn**. What is a churn? It is a tool used to turn milk into butter. The judge looked over his reports and cases, could not find anything about "churns," and gave judgment for the defendant. He effectively said: "He broke your churn, but there is no legal precedent for churns, therefore you lose."

    Why is this funny? Why is the judge wrong? Because the churn is not just a "churn"; it is property, it is a tool. But to know that, you have to know something about the object. The judge must know something about churns and their place in farm life to assess what other cases are relevant. The churn exists in a **nexus of practical skills**: churning, farming, consuming. A churn may be simple or require great skill; it may be customary to rent them; it may be vital to the farm's business or a minor inconvenience.

    Heidegger would say the churn exists in a web of "Ready-to-Hand" relations. If you lack this practical background, you cannot decide the case. That is why Llewellyn said the ideal judge is one thoroughly immersed in the **mercantile culture**. A judge who has never been on a ship cannot decide maritime law cases effectively because they lack the practical know-how of a captain. This proves there is knowledge that cannot be transmitted through text/books. It is non-cognitive, practical know-how.

    这跟法律有什么关系？我们读的是一篇耶鲁法学评论的文章。它讨论的是**裁判理论**（Theory of Adjudication）——法官*应该*如何判案 vs 法官实际上*是*如何判案的。想想**卡尔·卢埃林（Karl Llewellyn）**关于“严格遵循先例原则”的讨论。根据严格原则，规则仅限于特定的事实。

    想想霍姆斯提到的一个佛蒙特州治安法官的故事。一个农民起诉另一个农民弄坏了他的**搅乳器**（Churn）。什么是搅乳器？就是把牛奶制成黄油的工具。法官翻遍了判例汇编，找不到任何关于“搅乳器”的案例，于是判被告胜诉。他实际上是说：“他弄坏了你的搅乳器，但法律里没有关于搅乳器的先例，所以你输了。”

    这为什么好笑？法官错在哪儿？因为搅乳器不仅仅是“搅乳器”；它是财产，它是工具。但要理解这一点，你必须对这个物体有所了解。法官必须了解搅乳器在农场生活中的地位，才能评估哪些其他案例是相关的。搅乳器存在于一个**实践技能的联结**中：搅拌、耕作、消费。搅乳器可能很简单，也可能需要高超技巧；出租它们可能是一种习俗；它可能对农场生意至关重要，也可能只是个小麻烦。

    海德格尔会说，搅乳器存在于“上手状态”的关系网络中。如果你缺乏这种实践背景，你就无法判案。这就是为什么卢埃林说，理想的法官是那些彻底沉浸在**商业文化**中的人。一个从未上过船的法官无法有效地裁决海事案件，因为他们缺乏船长的实践知识。这证明了有些知识是无法通过文本/书本来传递的。那是由于非认知的实践知识。

  - [20:02 - 20:08] **Schopenhauer’s Spheres & The Sophistry of Concepts**

    This relates to **Schopenhauer**, my favorite philosopher. He talked about the expression of concepts. We form imaginative pictures for ourselves as representatives of concepts. He says logic is like walking on stilts, while reason is more intuitive.

    He uses a schema of **Overlapping Spheres** (Euler diagrams). Concepts are like circles or spheres. "Horse" is contained within the concept of "Animal." "Right Angle," "Obtuse," "Acute" are all subsumed by the concept of "Angle."

    Schopenhauer presents a fascinating table intended to show how conceptual spheres overlap in such a multitude of ways that there is enough "elbow room" to pass from one concept to any given other one at will. A persuasive speaker (a Sophist) can construct a chain of reasoning to prove anything.

    Example: **Travel**.

    - **Argument A (Travel is Bad):** Travel is costly -> Cost requires money -> Spending money causes poverty -> Therefore, Travel is Bad.
    - **Argument B (Travel is Good):** Travel dispels boredom -> It is exhilarating -> It is pleasant -> Therefore, Travel is Good.

    The spheres of concepts overlap. You can traverse from "Travel" to "Good" or "Bad" depending on your intention. Schopenhauer says: *"The speaker can continue choosing the course through them as he wishes... finally ending up, according to his original intention, with either good or evil."* This is **Sophistry**. Lawyers are sophists. Anyone with an interest is a sophist. You construct the reasoning backwards. You already have the conclusion (I want to win), and you build the path through the spheres to get there.

    这也联系到我最喜欢的哲学家**叔本华（Schopenhauer）**。他讨论了概念的表达。我们为概念构建想象的图景。他说逻辑就像踩高跷，而理性则更直观。

    他使用了**重叠球体**（Overlapping Spheres，即欧拉图）的图式。概念就像圆圈或球体。“马”这个概念包含在“动物”的概念中。“直角”、“钝角”、“锐角”都包含在“角”的概念下。

    叔本华展示了一个迷人的图表，旨在说明概念球体是如何以多种方式重叠的，以至于有足够的“回旋余地”可以随意从一个概念过渡到另一个概念。一个有说服力的演讲者（诡辩家）可以构建一条推理链来证明任何事情。

    例如：**旅行**。

    - **论点 A（旅行是坏的）**：旅行昂贵 -> 昂贵需要钱 -> 花钱导致贫穷 -> 因此，旅行是坏的。
    - **论点 B（旅行是好的）**：旅行驱散无聊 -> 它是令人兴奋的 -> 它是愉快的 -> 因此，旅行是好的。

    概念的球体相互重叠。你可以根据你的意图，从“旅行”穿越到“好”或“坏”。叔本华说：“演讲者可以按自己的意愿选择路径……最终根据他的初衷，得出好或坏的结论。”这就是**诡辩**（Sophistry）。律师就是诡辩家。任何有利益相关的人都是诡辩家。你是倒推推理的。你已经有了结论（我想赢），然后你在球体中构建路径来到达那里。

  - [20:08 - 20:16] **Legal Reasoning Regressing? & Kelsen's Pyramid**

    Is legal reasoning regressing thanks to AI? The paper suggests we are going back to the **Mos Geometricus**—the mathematical/geometrical method we discussed earlier, which failed. We are trying to make a computable world, but because of "Schemes of Intelligibility" and Heidegger’s "non-cognitive knowledge," it is impossible.

    This leads to an even deeper argument: **Hans Kelsen** and the *Pure Theory of Law*. Why "Pure"? He wants to purify law from politics, religion, and morality. He proposes a hierarchy, the **Kelsen Pyramid**.

    Example: A sign says **"Don't Walk on the Grass."**

    - *Question:* Why should you obey the sign?
    - *Answer:* Because the **Local Council** allowed the university to put it up.
    - *Question:* Why obey the Local Council?
    - *Answer:* Because the **National Legislature** gave them power (Public Law).
    - *Question:* Why obey the Legislature?
    - *Answer:* Because the **Constitution** authorizes them.
    - *Question:* Why obey the Constitution?
    - *Answer:* You hit the **Basic Norm** (*Grundnorm*). You stop asking questions. Kelsen says you must stop, otherwise you question the validity of society itself, and that leads to chaos.

    Kelsen argues that if you keep asking "why" beyond the law (e.g., "because it's moral"), you pollute the system. It must be a closed, pure pyramid.

    法律推理是否因为AI而正在倒退？这篇论文暗示我们正在回到**几何学方法**（Mos Geometricus）——即我们之前讨论过的、已经失败的数学/几何方法。我们试图构建一个可计算的世界，但由于“可理解性图式”和海德格尔的“非认知知识”，这是不可能的。

    这引出了一个更深层的论点：**汉斯·凯尔森（Hans Kelsen）\**和《纯粹法理论》。为什么叫“纯粹”？他想将法律从政治、宗教和道德中净化出来。他提出了一个等级体系，即\**凯尔森金字塔**。

    例子：有个牌子写着**“请勿践踏草坪”**。

    - *问：* 你为什么要遵守这个牌子？
    - *答：* 因为**地方议会**允许大学设立这个牌子。
    - *问：* 为什么要遵守地方议会？
    - *答：* 因为**国家立法机关**赋予了他们权力（公法）。
    - *问：* 为什么要遵守立法机关？
    - *答：* 因为**宪法**授权了他们。
    - *问：* 为什么要遵守宪法？
    - *答：* 你触碰到了**基本规范**（*Grundnorm*）。你必须停止提问。凯尔森说你必须停下来，否则你就是在质疑社会本身的合法性，那会导致混乱。

    凯尔森认为，如果你在法律之外继续问“为什么”（比如“因为这符合道德”），你就污染了这个系统。它必须是一个封闭、纯粹的金字塔。

  - [20:17 - 20:23] **The Indeterminacy of Interpretation**

    In the final chapter of *Pure Theory of Law*, Kelsen discusses interpretation. If Law is to be applied, you must determine the meaning of the norms. But interpretation involves **Discretion**. Even a specific command like "Arrest Subject C" leaves discretion to the police officer (Time? Place? Method?).

    Kelsen argues that the law is **intentionally indefinite**. If you define everything too strictly (like specific COVID measures for every town in a central law), it becomes impossible to enforce. You *must* leave room for the administrator.

    Key passage: *"From the point of view of Positive Law, there is **no criterion** by which one possibility within the frame is preferable to another."* There is simply no method to determine which interpretation is the "correct" one.

    - Textualism vs. Intentionalism?
    - Wording vs. Function?
    - Conflicting norms?
    - Weighing of Interests?

    Kelsen says all these methods are worthless because they can lead to opposite results, and there is no meta-rule to tell you which method to use. One method is exactly as good as another. Interpretation is an act of **Will**, not Cognition. It is political.

    在《纯粹法理论》的最后一章，凯尔森讨论了法律解释。如果要适用法律，你必须确定规范的含义。但解释涉及**裁量权**（Discretion）。即使是像“逮捕嫌疑人C”这样具体的命令，也给警察留下了裁量空间（时间？地点？方式？）。

    凯尔森认为，法律是**故意不确定的**。如果你把每件事都定义得太严格（比如在中央法律中规定每个城镇的具体防疫措施），法律将无法执行。你*必须*给行政人员留出空间。

    关键段落：“从实在法的角度来看，**没有任何标准**可以判定框架内的某一种可能性优于另一种。”根本没有方法能确定哪种解释是“正确”的。

    - 文本主义 vs 意图主义？
    - 措辞 vs 功能？
    - 规范冲突？
    - 利益衡量？

    凯尔森说这些方法都是毫无价值的，因为它们可能导致相反的结果，而且没有元规则告诉你该用哪种方法。一种方法和另一种方法完全一样好。解释是一种**意志**行为，而非认知行为。它是政治性的。

  - [20:24 - 20:28] **Conclusion: The Quantitative Fallacy (McNamara Fallacy)**

    So, what did we learn? We ended the epistemic philosophical BS, and now back to text data.

    1. **Provenance:** Data is generated by an Author for an Audience. It is not objective.
    2. **Schemes of Intelligibility:** Judges construct virtual facts.
    3. **Non-Cognitive Knowledge:** You cannot capture the "churn" or "care" in data.
    4. **Quantitative Fallacy:**

    This relates to the **McNamara Fallacy** (The Quantitative Fallacy) from the Vietnam War.

    - Step 1: Measure whatever can be easily measured (Body counts).
    - Step 2: Disregard that which can't be easily measured.
    - Step 3: Presume that what can't be measured isn't important.
    - Step 4: Say that what can't be measured **doesn't exist**.

    Americans only calculated how many people they killed. But the **Will to Fight**—how much the Vietnamese hated the Americans—cannot be measured. You cannot put that into a survey. Yet, that unmeasurable factor decided the war. We are stuck in this quantitative fallacy with AI. We think text captures reality, but the map is not the territory. The territory is fundamentally distinct.

    Okay, let's take a break. 12 minutes.

    那么，我们学到了什么？我们结束了认识论的哲学探讨，现在回到文本数据。

    1. **出处（Provenance）**：数据是由作者为受众生成的。它不是客观的。
    2. **可理解性图式**：法官构建虚拟事实。
    3. **非认知知识**：你无法在数据中捕捉到“搅乳器”或“操心”的本质。
    4. **量化谬误**：

    这联系到越战时期的**麦克纳马拉谬误（McNamara Fallacy）**（即量化谬误）。

    - 第一步：测量任何容易测量的事物（尸体数量）。
    - 第二步：忽略那些无法轻易测量的。
    - 第三步：假定无法测量的不重要。
    - 第四步：断言无法测量的**不存在**。

    美国人只计算了他们杀死了多少人。但是**战斗意志**——越南人有多恨美国人——是无法测量的。你没法通过问卷调查得知。然而，正是那个无法测量的因素决定了战争的胜负。我们在AI领域也陷入了这种量化谬误。我们以为文本捕捉了现实，但地图不是疆域。疆域与地图有着本质的区别。

    好，我们休息一下。12分钟。
## Week 4
  - [18:35 - 18:40] **Databases for Legal Analytics and Project Proposals**

    Now, regarding the data sources for your projects, some students are using the ECHR—that is the European Court of Human Rights database. It is important to note that while some databases allow for bulk downloads, others require more maneuvering. For instance, if you want to analyze cases from Alaska, you might initially try to download a bulk file, but you could find that it is outdated or stopped updating. That is a common issue. A better alternative is CourtListener, which aggregates data from various jurisdictions and, crucially, includes up-to-date cases filed as recently as today. It is free, constantly updated, and even includes oral arguments. Speaking of oral arguments—Good morning, everyone, and Happy Valentine's Day—oral arguments provide a different kind of data. Unlike written decisions, they are more candid; they capture human beings actually talking, which offers a richer, albeit messier, linguistic dataset than the formal written opinions.

    For those of you at the proposal stage, particularly the groups I am advising on classification tasks, the golden rule is to "compare apples to apples." You cannot simply throw random texts together. You must curate your dataset so that you are comparing cases that address similar legal issues or factual situations. If you are analyzing judicial behavior, ensure the underlying variables are consistent. There are other resources like the ECJ (European Court of Justice) data available via EUR-Lex. But whatever source you choose, ensure it is relevant to a specific, answerable legal question.

    关于你们的项目数据源，有些同学正在使用 ECHR，即欧洲人权法院的数据库。需要注意的是，虽然有些数据库允许批量下载，但其他数据库可能需要更多操作。例如，如果你想分析阿拉斯加州的案件，你最初可能会尝试下载一个批量文件，但可能会发现它已经过时或停止更新了。这是一个常见的问题。一个更好的替代方案是 CourtListener，它聚合了来自不同司法管辖区的数据，最重要的是，它包含直到今天提交的最新案件。它是免费的，不断更新，甚至包含口头辩论录音。说到口头辩论——大家早上好，情人节快乐——口头辩论提供了另一种类型的数据。与书面判决不同，它们更加坦率；它们捕捉到了人类真实的对话，这比正式的书面意见提供了更丰富（尽管更混乱）的语言数据集。对于处于提案阶段的同学，特别是我指导的做分类任务的小组，黄金法则是“苹果对苹果”（同类相比）。你不能简单地把随机文本放在一起。你必须整理你的数据集，以确保你比较的是处理相似法律问题或事实情况的案件。如果你在分析司法行为，请确保潜在变量是一致的。还有其他资源，如通过 EUR-Lex 获得的 ECJ（欧洲法院）数据。但无论你选择什么来源，都要确保它与一个具体的、可回答的法律问题相关。

  - [18:40 - 18:53] **Boilerplate and Isomorphism in Corporate Codes of Ethics**

    We have a lot of interesting readings this week. Earlier in the course, someone mentioned that we should care about AI ethics. So, let us address that by looking at the reality of ethics through the lens of the paper "Commonality in Codes of Ethics" by Forster, Loughran, and McDonald. We are done with the abstract philosophy; this is the empirical reality. If you ask a corporation, "Do you want to be nice?", they will say, "Yes, everyone should be nice." It reminds me of a Russian political program where the strategy is simply to say you are for everything good and against everything bad—you will win every election. But why does everyone's ethical language sound exactly the same? It is a mentality of conformity.

    If you look at the statistics in the article, the word "integrity" appeared in 92% of the codes of ethics, and "compliance" appeared in 89%. Why? Because of regulatory pressure from bodies like the SEC (Securities and Exchange Commission). Under Section 406 of the Sarbanes-Oxley Act (SOX), companies must disclose whether they have a code of ethics. To minimize risk, companies turn to their lawyers. And lawyers, as we know, are notoriously risk-averse. They do not want to draft something original that might get their client sued. They look at a big player, like Apple, see that their code of ethics has not led to legal trouble, and they copy it. This leads to "boilerplate"—standardized, repetitive text that is indistinguishable across firms.

    The paper argues that this is "isomorphism": smaller firms mimic larger, successful firms to gain legitimacy and avoid standing out. It is essentially plagiarism, but in the legal profession, strict replication of language is often considered a "best practice" because you want wording that has survived judicial scrutiny. However, for a code of ethics—which is supposed to represent a company's unique moral values—this copying suggests that nobody actually cares about the content. It is purely performative compliance. They are just checking a box to satisfy the regulators or the 10-K reporting requirements. It is ironic that we are using sophisticated NLP methods to study text that nobody reads and was generated by copying and pasting.

    这周我们有很多有趣的阅读材料。课程早些时候，有人提到我们应该关注人工智能伦理。那么，让我们通过 Forster、Loughran 和 McDonald 的论文《道德准则的共性》（Commonality in Codes of Ethics）来看看伦理的现实。我们已经结束了抽象的哲学探讨；这是实证的现实。如果你问一家公司，“你想做一个好人吗？”，他们会说，“是的，每个人都应该做好人。”这让我想起了一个俄罗斯的政治节目，其策略仅仅是声称你支持一切美好的事物，反对一切糟糕的事物——这样你会赢得每一次选举。但是，为什么每个人的伦理语言听起来都一模一样呢？这是一种从众心理。如果你看文章中的统计数据，“诚信”（integrity）一词出现在 92% 的道德准则中，“合规”（compliance）出现在 89% 中。为什么？因为来自 SEC（美国证券交易委员会）等机构的监管压力。根据《萨班斯-奥克斯利法案》（SOX）第 406 条，公司必须披露其是否制定了道德准则。为了将风险降至最低，公司会求助于律师。众所周知，律师是非常厌恶风险的。他们不想起草一些可能导致客户被起诉的原创内容。他们会看像苹果这样的大公司，发现他们的道德准则没有通过法律麻烦，于是就照搬过来。这就导致了“样板文件”（boilerplate）——即在不同公司之间无法区分的标准化、重复性文本。论文认为这就是“同形性”（isomorphism）：小公司模仿大而成功的公司以获得合法性并避免引人注目。这本质上是抄袭，但在法律行业，严格复制语言通常被视为“最佳实践”，因为你需要的是经得起司法审查的措辞。然而，对于本应代表公司独特道德价值观的道德准则而言，这种复制表明实际上没人关心其中的内容。这纯粹是表演性的合规。他们只是为了满足监管机构或 10-K 报告要求而打勾。讽刺的是，我们正在使用复杂的 NLP 方法来研究那些实际上没人阅读、且是通过复制粘贴生成的文本。

  - [18:54 - 18:59] **Semantic Divergence: North vs. South Korean Language**

    The next paper, "A Critical Perspective of NLP Resources for the South and North Korean Languages," might seem unrelated to law, but it beautifully illustrates the problem of semantic drift. We have two countries, South and North Korea, that share a linguistic root but have been divided for decades. This paper investigates how the meaning of identical words has diverged using a technique called "word embeddings"—which maps words into a geometric space based on their context.

    The most striking example in the paper is the word "socialism" (sahoejuui). In North Korea, the word embedding analysis shows that "socialism" is associated with grandiloquent qualifiers, positive ideological descriptors, and words like "great deed" or "adhere to principles." It is a celebrated concept. However, when you look at the South Korean embedding for the exact same word, "socialism" is semantically close to "dictatorship," "absolutism," and "authoritarianism." Same word, same pronunciation, but completely different, almost opposite, meanings derived from the political context.

    This is crucial for Natural Language Processing (NLP). If you train a model solely on South Korean data and try to interpret North Korean text, you will fundamentally misunderstand the intent because the underlying mathematical representation of the concepts is different. The paper argues that we cannot just treat Korean as a single "high-resource" language; we have to account for this ideological schism that alters the generative process of the language itself. Meaning is amorphous; it shifts based on the speaker's environment.

    下一篇论文《关于朝韩语言 NLP 资源的批判性视角》（A Critical Perspective of NLP Resources for the South and North Korean Languages）可能看起来与法律无关，但它极好地说明了语义漂移（semantic drift）的问题。我们有韩国和朝鲜这两个国家，它们同根同源，但已经分裂了几十年。这篇论文利用一种称为“词嵌入”（word embeddings）的技术——即根据上下文将词语映射到几何空间中——研究了相同词语的含义是如何发生分歧的。论文中最引人注目的例子是“社会主义”（sahoejuui）这个词。在朝鲜，词嵌入分析显示，“社会主义”与浮夸的修饰语、积极的意识形态描述词以及“伟业”或“坚持原则”等词语相关联。这是一个被赞颂的概念。然而，当你查看韩国语境下同一个词的嵌入时，“社会主义”在语义上接近“独裁”、“专制主义”和“威权主义”。同一个词，发音相同，但源于政治背景的含义却完全不同，甚至是相反的。这对自然语言处理（NLP）至关重要。如果你仅用韩国数据训练模型并试图解释朝鲜文本，你会从根本上误解其意图，因为概念的底层数学表示是不同的。该论文认为，我们不能仅仅将韩语视为一种单一的“高资源”语言；我们必须考虑到这种改变语言生成过程本身的意识形态分裂。意义是无定形的；它会根据说话者的环境而变化。

  - [19:00 - 19:26] **Fighting Words: Framing and the Generative Model Debate**

    This brings us to the "Fighting Words" paper by Monroe, Colaresi, and Quinn. This is a seminal paper in political science. It deals with the concept of "framing," a theory originally articulated by Donald Schön and Martin Rein in their book *Frame Reflection*. Framing is the idea that the way you define a problem inevitably dictates the solution you propose.

    Take the example of crime. If you frame crime as a result of "broken windows"—small signs of disorder like graffiti—your solution is to police minor infractions aggressively. If you frame crime as a result of "social inequality," your solution is to improve schools and housing. If you frame it as "lead poisoning" (the lead hypothesis), your solution is to fix the water pipes. The frame *is* the argument. In the US Senate, Republicans and Democrats use framing to fight over issues like abortion. They do not just disagree; they speak different languages. Republicans frame abortion around the "baby," using words like "kill," "infant," and "innocent." Democrats frame it around the "woman," using words like "choice," "health," and "rights."

    Now, the methodological contribution of Monroe, Colaresi, and Quinn is their critique of standard machine learning classification. Usually, we think: "Here are some words ($W$), let us predict the party ($P$)." That is a classification problem ($P(P|W)$). But the authors argue this gets the data generation process backwards. You are not a Democrat *because* you use the word "choice"; you use the word "choice" *because* you are a Democrat. The partisanship causes the word choice, not the other way around. Therefore, they propose a generative model approach ($P(W|P)$) using Bayesian statistics to estimate which words are most distinctive to each party. They call these "fighting words." It is a statistical way to quantify the framing wars.

    这就引出了 Monroe、Colaresi 和 Quinn 的论文《战斗的文字》（Fighting Words）。这是政治学领域的一篇开创性论文。它探讨了“框架”（framing）的概念，这一理论最初由 Donald Schön 和 Martin Rein 在他们的书《框架反思》（Frame Reflection）中提出。框架理论认为，你定义问题的方式不可避免地决定了你提出的解决方案。以犯罪为例。如果你将犯罪归因于“破窗效应”——即涂鸦等无序的小迹象——你的解决方案就是严厉整治轻微违规行为。如果你将犯罪归因于“社会不平等”，你的解决方案就是改善学校和住房。如果你将其归因于“铅中毒”（铅假说），你的解决方案就是修复水管。框架*就是*论点。在美国参议院，共和党和民主党利用框架在堕胎等问题上进行争斗。他们不仅仅是意见不合；他们说着不同的语言。共和党人围绕“婴儿”构建堕胎问题的框架，使用“杀害”、“婴儿”和“无辜”等词。民主党人则围绕“女性”构建框架，使用“选择”、“健康”和“权利”等词。Monroe、Colaresi 和 Quinn 在方法论上的贡献在于他们对标准机器学习分类的批判。通常我们会想：“这里有一些词（$W$），让我们预测党派（$P$）。”这是一个分类问题（$P(P|W)$）。但作者认为这搞反了数据生成过程。你不是*因为*使用了“选择”这个词才是民主党人；而是*因为*你是民主党人，所以你使用“选择”这个词。党派属性导致了用词选择，而不是反过来。因此，他们提出了一种使用贝叶斯统计的生成模型方法（$P(W|P)$），以估算哪些词对每个政党最具区分度。他们称这些为“战斗的文字”。这是一种量化框架战争的统计方法。

  - [19:27 - 19:33] **Visualizing Political Sentiment: LBJ vs. George W. Bush**

    We can also compare languages or speakers using simple dictionary-based methods, as seen in the "Generalized Word Shift Graphs" paper. This method looks at how the frequency of specific words drives the difference in sentiment between two corpora. The paper compares the presidential speeches of Lyndon B. Johnson (LBJ) and George W. Bush.

    If you look at the word shift graph, you see that Bush's speeches are far more negative, driven by high-frequency usage of words like "Iraq," "terrorists," "weapons," "evil," and "enemies." This makes sense given the post-9/11 context. In contrast, LBJ's speeches are characterized by words like "freedom," "poverty," "health," "liberty," and "woman." Even if you knew nothing about LBJ, this word list tells you a story. LBJ was the architect of the "Great Society" program, aimed at eliminating poverty and racial injustice. He signed the Civil Rights Act of 1964. His focus was on domestic uplift and social welfare.

    The visualization allows us to see exactly *why* one text is more positive or negative than another. It is not just a single score; it breaks down the contribution of each word. Bush is pulled negative by "terror"; LBJ is pulled positive by "freedom." However, these tools are imperfect. They require interpretation. Seeing the word "woman" associated with LBJ requires you to know about his civil rights legislation to fully understand the context—otherwise, it is just a data point.

    我们还可以像《广义词移图》（Generalized Word Shift Graphs）这篇论文中所见的那样，使用基于词典的简单方法来比较语言或演讲者。该方法观察特定词汇的频率如何驱动两个语料库之间情感差异。该论文比较了林登·约翰逊（LBJ）和乔治·W·布什的总统演讲。如果你看词移图，你会发现布什的演讲要消极得多，这主要是由于高频使用“伊拉克”、“恐怖分子”、“武器”、“邪恶”和“敌人”等词汇。考虑到 9/11 后的背景，这是有道理的。相比之下，LBJ 的演讲特征词是“自由”、“贫困”、“健康”、“自由（liberty）”和“女性”。即使你对 LBJ 一无所知，这个词表也会告诉你一个故事。LBJ 是“伟大社会”（Great Society）计划的设计师，旨在消除贫困和种族不公。他签署了 1964 年的《民权法案》。他的重点是国内提升和社会福利。这种可视化让我们能够确切地看到*为什么*一个文本比另一个更积极或更消极。它不仅仅是一个单一的分数；它分解了每个词的贡献。布什被“恐怖”拉向消极；LBJ 被“自由”拉向积极。然而，这些工具是不完美的。它们需要解释。看到“女性”一词与 LBJ 联系在一起，你需要了解他的民权立法才能完全理解其背景——否则，它只是一个数据点。

  - [19:34 - 19:44] **The Rise and Fall of Rationality in Language**

    Another fascinating paper using dictionary methods is "The Rise and Fall of Rationality in Language" by Scheffer et al. They analyzed millions of books from Google Books to track the frequency of specific "flag words" over time. They found a distinct "tilted hockey stick" pattern. From 1850 to 1980, there was a steady rise in "rational" words—terms like "determine," "conclusion," "analysis," and "system." This reflected the rise of science, technology, and perhaps the bureaucratic neoliberal order.

    But around 1980, this trend reversed dramatically. Rational words started to decline, and "intuitive" or "sentiment-laden" words shot up—words like "feel," "believe," "spirit," "imagine," and "sense." This shift occurred in both English and Spanish, and in both fiction and non-fiction. Interestingly, this reversal coincides with a shift in pronouns. The use of "I" (individualism) has surged relative to "we" (collectivism).

    Why did we become less rational and more emotional after 1980? There are many theories. Maybe it is the end of the Cold War. Maybe, as the authors suggest, it is a reaction to the failures of the neoliberal economic order—people realized that "rational" policies were making the rich richer (like Elon Musk) and everyone else poorer, so they retreated into their feelings and personal truths. This connects to the "Post-Truth" era we live in now, where feelings trump facts. It is a concept drift; the mindset of humanity is changing, and the data proves it.

    另一篇使用词典方法的迷人论文是 Scheffer 等人的《语言中理性的兴衰》（The Rise and Fall of Rationality in Language）。他们分析了谷歌图书中的数百万本书，以追踪特定“标志词”随时间变化的频率。他们发现了一个明显的“倾斜曲棍球棒”（tilted hockey stick）模式。从 1850 年到 1980 年，“理性”词汇——如“确定”、“结论”、“分析”和“系统”——稳步上升。这反映了科学、技术的兴起，或许还有官僚新自由主义秩序的兴起。但在 1980 年左右，这一趋势发生了戏剧性的逆转。理性词汇开始下降，而“直觉”或“充满情感”的词汇激增——如“感觉”、“相信”、“精神”、“想象”和“感知”。这种转变发生在英语和西班牙语中，也同时出现在虚构和非虚构作品中。有趣的是，这种逆转与代词的转变相吻合。“我”（个人主义）的使用相对于“我们”（集体主义）激增。为什么我们在 1980 年后变得不那么理性而更情绪化？有很多理论。也许是冷战的结束。也许正如作者所暗示的，这是对新自由主义经济秩序失败的反应——人们意识到“理性”政策让富人更富（像埃隆·马斯克），而让其他人更穷，所以他们退回到自己的感受和个人真理中。这与我们现在生活的“后真相”时代有关，在这个时代，感受胜过事实。这是一种概念漂移；人类的心态正在改变，数据证明了这一点。

  - [19:45 - 19:50] **Authorship Attribution: The Federalist Papers**

    Finally, we must mention the classic study on authorship attribution: "Inference in an Authorship Problem" by Mosteller and Wallace (1963). This is one of the few statistical papers you might hear about in a history class. It tackles the mystery of *The Federalist Papers*, written in 1787-1788 to promote the US Constitution. They were written anonymously by Hamilton, Madison, and Jay. While we know who wrote most of them, there were 12 "disputed papers" where both Hamilton and Madison claimed authorship.

    The problem is that Hamilton and Madison were political twins; their writing styles were incredibly similar. They both used the same grand, oratorical "Spectator" style. You cannot tell them apart by sentence length or vocabulary richness. Mosteller and Wallace solved this not by looking at "meaningful" words like "war" or "executive" (which depend on the topic), but by looking at "function words" or "stop words"—boring words like "upon," "whilst," "there," and "on."

    It turns out these useless words are the fingerprints of style. Hamilton used "upon" about 3 times per 1,000 words, while Madison almost never used it (0.16 times). Hamilton used "while"; Madison used "whilst." By analyzing the frequency distributions of these 30 or so function words, they calculated the odds and determined that all 12 disputed papers were almost certainly written by Madison. This study established that the most powerful signal often hides in the most frequent, seemingly meaningless noise.

    最后，我们必须提到关于作者归属的经典研究：Mosteller 和 Wallace（1963）的《作者身份问题中的推断》（Inference in an Authorship Problem）。这是你在历史课上可能听到的为数不多的统计学论文之一。它解决了《联邦党人文集》（The Federalist Papers）的谜团，该文集写于 1787-1788 年，旨在以此推广美国宪法。它们是由汉密尔顿、麦迪逊和杰伊匿名撰写的。虽然我们知道其中大部分是谁写的，但有 12 篇“有争议的文章”，汉密尔顿和麦迪逊都声称是自己写的。问题在于汉密尔顿和麦迪逊是政治上的双胞胎；他们的写作风格惊人地相似。他们都使用同样宏大、演说般的“旁观者”（Spectator）风格。你无法通过句子长度或词汇丰富度来区分他们。Mosteller 和 Wallace 解决这个问题的方法不是看像“战争”或“行政”这样“有意义”的词（这些词取决于主题），而是看“功能词”或“停用词”——像“upon”（在……之上）、“whilst”（同时）、“there”（那里）和“on”（在……上）这样枯燥的词。事实证明，这些无用的词是风格的指纹。汉密尔顿每 1,000 个词大约使用 3 次“upon”，而麦迪逊几乎从不使用（0.16 次）。汉密尔顿使用“while”；麦迪逊使用“whilst”。通过分析这 30 个左右功能词的频率分布，他们计算了赔率，并确定所有 12 篇有争议的文章几乎肯定都是麦迪逊写的。这项研究确立了一点：最强大的信号往往隐藏在最频繁、看似无意义的噪音中。

  - [19:51 - 19:57] **Zipf’s Law and the Power Law of Language**

    This focus on high-frequency words leads us to a fundamental law of language statistics: Zipf's Law. Discovered by George Zipf in 1932, this law states that the frequency of any word is inversely proportional to its rank in the frequency table. The most common word (usually "the") appears twice as often as the second most common word ("of"), and three times as often as the third, and so on.

    This distribution is a "Power Law" (or Pareto distribution). It means that a tiny handful of words make up the vast majority of any text, while there is a "long tail" of words that appear very rarely. The Greeks called these rare words *hapax legomena*—words said only once. This 80/20 rule (the Pareto Principle) applies everywhere: 20% of the people own 80% of the land; 20% of the words carry 80% of the volume.

    This has huge implications for AI. When we train models like ChatGPT, they see these grammatical function words ("the", "is", "at") billions of times. They learn grammar perfectly because it is in the "head" of the distribution. But the specific, rare, meaningful facts are in the "tail." The model might hallucinate because it hasn't seen those rare combinations enough to form a robust probability. We are effectively mostly studying the grammar of the language rather than the rare, material content.

    这种对高频词的关注将我们引向了语言统计学的一个基本定律：齐普夫定律（Zipf’s Law）。该定律由乔治·齐普夫于 1932 年发现，指出任何单词的频率与其在频率表中的排名成反比。最常见的单词（通常是“the”）出现的频率是第二常见单词（“of”）的两倍，是第三常见单词的三倍，依此类推。这种分布是一种“幂律”（Power Law）（或帕累托分布）。这意味着极少数的单词构成了任何文本的绝大部分，而有一个包含极少出现的单词的“长尾”。希腊人称这些罕见的词为 *hapax legomena*——只说过一次的词。这种 80/20 规则（帕累托法则）无处不在：20% 的人拥有 80% 的土地；20% 的单词承载了 80% 的体量。这对人工智能有巨大的影响。当我们训练像 ChatGPT 这样的模型时，它们会看到这些语法功能词（“the”、“is”、“at”）数十亿次。它们完美地学会了语法，因为语法位于分布的“头部”。但具体的、罕见的、有意义的事实位于“尾部”。模型可能会产生幻觉，因为它没有看过足够多的那些罕见组合来形成稳健的概率。我们实际上主要是在研究语言的语法，而不是罕见的实质性内容。

  - [20:10 - 20:15] **Lab Intro: Distributional NLP & Environment Hell**

    Okay, welcome back. Let's get started with the lab. This is Lab 4, and we are going to look at "Distributional NLP Without Machine Learning." Now, I know everyone wants to do the fancy stuff, the transformers, the deep learning. But as I said in the lecture, these classical statistical approaches—counting words, looking at distributions—are incredibly powerful. They are not "cutting edge," but they actually tell you more about the data generation process than a black box model.

    First things first, a bit of housekeeping. You might notice the notebook says we need Python 3.9. This is because of the `shifterator` library, which we will use later to make those cool word shift graphs. It hasn't been updated for the latest Python versions. This is the reality of open-source software; it breaks all the time. So, you have to go into your Anaconda Navigator, make a new environment, and set it to Python 3.9. I know, it's annoying. Environment management is 90% of the work in data science. It is just plumbing. But if you don't do it, `shifterator` will just scream at you.

    好的，欢迎回来。我们开始做实验吧。这是实验 4，我们将探讨“无机器学习的分布式 NLP”。我知道大家都想做那些花哨的东西，变形金刚模型（transformers），深度学习。正如我在讲座中所说，这些经典的统计方法——数单词，看分布——是非常强大的。它们不是“前沿技术”，但比起黑箱模型，它们实际上能告诉你更多关于数据生成过程的信息。首先，处理一些琐事。你们可能注意到笔记本上说我们需要 Python 3.9。这是因为我们稍后要用 `shifterator` 库来制作那些很酷的词移图。它还没有针对最新的 Python 版本进行更新。这就是开源软件的现实；它总是崩溃。所以，你必须进入你的 Anaconda 导航器，创建一个新环境，并将其设置为 Python 3.9。我知道，这很烦人。环境管理占了数据科学工作的 90%。这只是些管道工的活儿。但如果你不这样做，`shifterator` 就会对你报错。

  - [20:15 - 20:25] **The Philosophy of Tokenization: "Dog" vs. "Dog."**

    Let's talk about Tokenization. To a computer, text is just a string. It's just a sequence of characters. It doesn't know what a "word" is. It doesn't know that "table" is a concept. It just sees "t-a-b-l-e." So, we have to teach it. We have to chop this string into a list of meaningful units. That is tokenization. The simplest way is "whitespace tokenization"—just split the string every time you see a space.

    But look at this example: "The quick brown fox jumps over the lazy dog." If you just split by space, the last token is "dog." (dog with a period). To a human, "dog" and "dog." are the same animal. To a Python script, they are completely different strings. They will not be counted together. This is a disaster for statistics. So we have to clean it. We can use Regular Expressions (Regex). I provided a pattern here `r'\w+'`—this looks for word characters and ignores punctuation. Or we can use `gensim`'s `strip_punctuation`. There are a million ways to do this, but the goal is always the same: turn raw noise into clean, countable lists.

    我们来谈谈分词（Tokenization）。对计算机来说，文本只是字符串。它只是一串字符序列。它不知道“单词”是什么。它不知道“桌子”是一个概念。它只看到“t-a-b-l-e”。所以，我们必须教它。我们必须把这个字符串切成一列有意义的单位。这就是分词。最简单的方法是“空白分词”——每当你看到一个空格就切分字符串。但是看看这个例子：“The quick brown fox jumps over the lazy dog.”（那只敏捷的棕色狐狸跳过了那只懒狗。）如果你只是按空格切分，最后一个标记是“dog.”（带句号的狗）。对人类来说，“dog”和“dog.”是同一种动物。对 Python 脚本来说，它们是完全不同的字符串。它们不会被算在一起。这对统计学来说是一场灾难。所以我们必须清理它。我们可以使用正则表达式（Regex）。我在这里提供了一个模式 `r'\w+'`——它寻找单词字符并忽略标点符号。或者我们可以使用 `gensim` 的 `strip_punctuation`。有一百万种方法可以做到这一点，但目标总是一样的：把原始噪音变成干净的、可计数的列表。

  - [20:25 - 20:38] **Stopwords and Dimensionality Reduction**

    Next up: Stopwords. Words like "the," "is," "and," "at." As we saw with Zipf's Law, these words appear everywhere. They are the glue of the language, but they carry very little semantic content. If you count the most frequent words in your legal documents, you will get "the," "of," "court." Meaningless. So, we remove them.

    Now, for the computer scientists in the room, removing stopwords is actually a form of **dimensionality reduction**. Imagine every word is a dimension. By removing "the," you are collapsing a huge dimension that essentially adds no variance to your data because it is present in every single document. We are removing the noise to see the signal.

    We have different libraries for this—NLTK, Scikit-learn, Spacy. They all have different lists. Scikit-learn has a massive list of stopwords, like "bill," "call," "cry." I don't know why "cry" is a stopword in their world, but it is. Spacy is generally smarter. But you have to be careful. Sometimes "the" is important. Remember the Federalist Papers? They distinguished Hamilton and Madison based on "whilst" and "upon." If you remove stopwords there, you lose the authorship signal. So, it depends on your task.

    接下来是：停用词（Stopwords）。像“the”、“is”、“and”、“at”这样的词。正如我们在齐普夫定律中看到的，这些词无处不在。它们是语言的粘合剂，但它们携带的语义内容很少。如果你统计法律文档中出现频率最高的词，你会得到“the”、“of”、“court”。毫无意义。所以，我们要移除它们。现在，对于在座的计算机科学家来说，移除停用词实际上是一种**降维**形式。想象每个单词都是一个维度。通过移除“the”，你实际上是在折叠一个巨大的维度，它对你的数据没有任何方差贡献，因为它出现在每一份文档中。我们是在去除噪音以看到信号。我们有不同的库来做这件事——NLTK、Scikit-learn、Spacy。它们都有不同的列表。Scikit-learn 有一个庞大的停用词列表，比如“bill”、“call”、“cry”。我不知道为什么在他们的世界里“cry”（哭）是一个停用词，但它确实是。Spacy 通常更聪明。但你必须小心。有时“the”很重要。还记得《联邦党人文集》吗？他们根据“whilst”和“upon”来区分汉密尔顿和麦迪逊。如果你在那儿移除了停用词，你就失去了作者身份的信号。所以，这取决于你的任务。

  - [20:38 - 20:47] **Stemming, Lemmatization, and "Heedlessness"**

    Finally, before we get to the fun visualization stuff, we have Stemming and Lemmatization. This is about normalization. The word "connection," "connections," "connected," "connecting." They are all the same concept, right? To a computer, they are four different variables. We want to map them to a single root, like "connect."

    **Stemming** is the brute force method. It just chops off the end of the word. It's fast, it's dirty. It uses rules like "if it ends in -ing, cut it." The Snowball Stemmer is a popular one.

    **Lemmatization** is the sophisticated cousin. It looks at the dictionary and the grammar. For example, "better." A stemmer might just leave it as "better." But a lemmatizer knows that "better" is the comparative form of "good." So it maps "better" to "good." It maps "are" to "be."

    Why do we care? Because of sparsity. If you have "fox" and "foxes" as separate columns, your data is too thin. You want to combine them to get a stronger statistical signal. But it's not perfect. Sometimes it over-corrects. Take a complex word like "heedlessness."

    最后，在我们进入有趣的视觉化环节之前，我们要讲讲词干提取（Stemming）和词形还原（Lemmatization）。这是关于标准化的。“connection”（连接）、“connections”（连接复数）、“connected”（连接过去的）、“connecting”（连接进行时）。它们都是同一个概念，对吧？对计算机来说，它们是四个不同的变量。我们要把它们映射到一个单一的词根，比如“connect”。**词干提取**是蛮力方法。它只是切掉单词的尾巴。它很快，很粗糙。它使用像“如果以 -ing 结尾，就切掉它”这样的规则。Snowball 词干提取器是一个流行的工具。**词形还原**是那个复杂的表亲。它会查看字典和语法。例如，“better”（更好）。词干提取器可能就把它留作“better”。但词形还原器知道“better”是“good”（好）的比较级。所以它把“better”映射到“good”。它把“are”映射到“be”。我们为什么要在乎这个？因为稀疏性。如果你把“fox”和“foxes”作为单独的列，你的数据就太稀疏了。你想把它们结合起来以获得更强的统计信号。但它并不完美。有时它会矫枉过正。拿一个像“heedlessness”（轻率）这样的复杂词来说。

  - [20:47 - 20:48] **Tokenization Challenges and Data Generation**

    Actually, the tokenization process reduces long words into smaller chunks. For example, consider the word "heedlessness." You can see that "heedlessness" is reduced to two components: it looks for the root "heed" and the suffix "lessness"—or the concept of being "less." It assigns associated numbers to these chunks. This is done by design because long, complex words are statistically rare. It is impossible to analyze them effectively as unique tokens because there are many more instances of the root "heed" and the suffix "less" separately than the combined "heedlessness." If you do not break it down, you will not have enough data for the algorithm to work; it would just be a single, isolated concept with no statistical weight. So, there is no way around it. It is a real problem in NLP, but this simple observation about how we generate data from text—by breaking it down—is actually very useful.

    其实，分词过程会将长单词还原成更小的块。例如，考虑“heedlessness”（轻率）这个词。你可以看到“heedlessness”被还原为两个部分：它寻找词根“heed”（注意）和后缀“lessness”——或者说是“less”（无）的概念。它会为这些块分配相关的数值。这是设计使然，因为长而复杂的单词在统计上是很罕见的。如果将它们作为唯一的标记（tokens）进行分析是不可能的，因为词根“heed”和后缀“less”单独出现的次数要比组合词“heedlessness”多得多。如果你不把它拆分，算法就没有足够的数据来工作；它只会变成一个没有统计权重的单一、孤立的概念。所以，这是无法回避的。这是 NLP 中的一个真正的问题，但这种关于我们如何从文本中生成数据——通过将其拆解——的简单观察实际上是非常有用的。

  - [20:48 - 20:54] **Shifterator and the \*Miller v. Jackson\* Case**

    Now, let us use `shifterator`. This is that Python library based on the "Generalized Word Shift Graphs" paper you read. First, we run `pip install shifterator`. We will examine everyone's favorite legal case: the Denning minority opinion and the Lane majority opinion in *Miller v. Jackson*. This is where these statistical tools really shine. Let us take the text of Lord Denning's minority opinion and Lord Lane's majority opinion and open each file. Denning's text starts with his famous line: "In summertime village cricket is the delight of everyone." Lane's text is much drier: "Since about 1905 cricket has been played..."

    We need to preprocess this. We remove stop words, strip punctuation, and lowercase everything. This is the classical preprocessing we discussed. The content will look like "1905 cricket played field village..."—it looks like mumbo jumbo, but that is what the computer needs. We tokenize it using a split function and then create a counter object. For Denning, "cricket" is mentioned 69 times. If we had kept the stop words, "the" would be at the top, which is why removing them is important for this kind of simple analysis.

    If you go to the `shifterator` cookbook, you can see various metrics like Jensen-Shannon Divergence (JSD) shifts. We import the library as `sh` and use the `ProportionShift` class to compare the frequencies in the Denning counter versus the Lane counter. Note that it expects counter objects, not raw strings. When we graph this, the results are striking. Denning's distinctive words are "cricket," "club," and "ball." Lane, on the other hand, talks about "garden," "injury," "back," and "ridge." For those of you who do not know the case, this might seem meaningless. But if you know the law, it is fascinating. Lane is focused on the "injury"—the harm caused by the ball hitting the neighbors. Denning is focused on the "cricket" and the "club" as a social good.

    We can also look at "Entropy Shift." Entropy measures surprise or chaos—named after Claude Shannon, the famous mathematician. An entropy shift shows which words are more unexpected in one text compared to the other. Lane emphasizes "trespass" much more, because he is discussing the technical legal boundary of when a ball entering the property constitutes trespass. Different measures give different emphasis, but they all reveal the underlying framing of the judges.

    现在，让我们使用 `shifterator`。这是基于你们读过的《广义词移图》论文的 Python 库。首先，我们运行 `pip install shifterator`。我们将检查大家最喜欢的法律案件：*Miller v. Jackson*案中的丹宁勋爵（Lord Denning）的少数派意见和莱恩勋爵（Lord Lane）的多数派意见。这就是这些统计工具真正大放异彩的地方。让我们获取丹宁的少数派意见和莱恩的多数派意见的文本，并打开每个文件。丹宁的文本以他那句名言开头：“在夏天，乡村板球是每个人的乐趣。”莱恩的文本则枯燥得多：“自 1905 年左右以来，板球就一直在……”

    我们需要对其进行预处理。我们移除停用词，去除标点符号，并将所有内容转换为小写。这是我们要做的经典预处理。内容会看起来像“1905 cricket played field village……”——这看起来像乱码，但这正是计算机所需要的。我们使用拆分函数对其进行分词，然后创建一个计数器对象。对于丹宁来说，“板球”被提及了 69 次。如果我们保留了停用词，“the”会在顶部，这就是为什么对于这种简单的分析，移除它们很重要。

    如果你去 `shifterator` 的说明书（cookbook），你可以看到各种指标，如 Jensen-Shannon 散度（JSD）位移。我们将库导入为 `sh`，并使用 `ProportionShift` 类来比较丹宁计数器与莱恩计数器的频率。请注意，它需要的是计数器对象，而不是原始字符串。当我们将其绘制成图表时，结果非常惊人。丹宁的独特词汇是“板球”、“俱乐部”和“球”。另一方面，莱恩谈论的是“花园”、“伤害”、“背部”和“屋脊”。对于那些不了解这个案件的人来说，这可能看起来毫无意义。但如果你懂法律，这就很有趣了。莱恩关注的是“伤害”——球击中邻居造成的伤害。丹宁关注的是作为社会公益的“板球”和“俱乐部”。

    我们还可以看看“熵位移”（Entropy Shift）。熵衡量的是惊讶或混乱——以著名数学家克劳德·香农的名字命名。熵位移显示了与另一个文本相比，通过一个文本中哪些词更出乎意料。莱恩更强调“非法侵入”（trespass），因为他正在讨论球进入财产构成非法侵入的技术法律界限。不同的衡量标准会给出不同的侧重点，但它们都揭示了法官的潜在框架。

  - [20:54 - 20:58] **Visualizing Text with Scattertext**

    Now, let us install `scattertext` and `polars` (or whatever dataframe library you prefer). This library allows for interactive exploration. We need to set up a DataFrame where one column is the text and another is the category—in this case, the "party." I use the word "party" because the library was built for political classification (Republican vs. Democrat), so I kept the variable name, but here the parties are "Denning" and "Lane."

    We initialize a corpus object to interact with the `scattertext` library. We take our `judges_df`, set the category column to the judge's name, and the text column to the opinion text. Crucially, for the NLP pipeline, we use `st.whitespace_nlp_with_sentences`. This splits the text into sentences, which makes the output much more readable than just a bag of words.

    After building the corpus, we generate an HTML visualization using `produce_scattertext_explorer`. We set the category to "Denning" and the non-category to "Lane." We set a minimum term frequency of 3 and a PMI (Pointwise Mutual Information) threshold. When you run this, it produces an interactive graph. You can see Denning's top words like "cricket." But the coolest thing about this library—and it is a shame if it doesn't work on Python 3.10 for some of you—is that you can click on the word "cricket," and it will show you every single sentence in the text where that word appears. It acts like a concordance. This is a very powerful technique for "close reading." You start with the statistics to find the separation, and then you zoom in to see the context. It is very cool for exploring text before you even get to classification.

    现在，让我们安装 `scattertext` 和 `polars`（或者你喜欢的任何数据框库）。这个库允许进行交互式探索。我们需要设置一个 DataFrame，其中一列是文本，另一列是类别——在这种情况下是“党派”。我使用“党派”这个词是因为该库是为政治分类（共和党与民主党）构建的，所以我保留了变量名，但这里的党派是“丹宁”和“莱恩”。

    我们初始化一个语料库对象以与 `scattertext` 库进行交互。我们获取 `judges_df`，将类别列设置为法官的名字，将文本列设置为意见文本。关键是，对于 NLP 管道，我们使用 `st.whitespace_nlp_with_sentences`。这将文本分割成句子，这使得输出比仅仅是一堆单词要可读得多。

    构建语料库后，我们使用 `produce_scattertext_explorer` 生成 HTML 可视化。我们将类别设置为“丹宁”，非类别设置为“莱恩”。我们设置最小词频为 3 和 PMI（点互信息）阈值。当你运行它时，它会生成一个交互式图表。你可以看到丹宁的高频词，如“板球”。但这个库最酷的地方——如果有些人的 Python 3.10 无法运行它，那真是太遗憾了——是你可以在图表中点击“板球”这个词，它会显示文本中出现该词的每一个句子。它就像一个索引（concordance）。这是进行“细读”（close reading）的一种非常强大的技术。你从统计数据开始寻找差异，然后放大以查看上下文。在进入分类之前，这对于探索文本非常酷。

  - [20:58 - 21:04] **Analyzing Trump’s Tweets: Popularity and Reproducibility**

    Let us move on to the Trump tweets dataset. We have a dataframe `tweets_df` containing the text, the date, and the retweet count. I have a hypothesis: what determines the content of his popular tweets? What does he talk about when he goes viral versus when he does not? I define "popular" based on the retweet count. Let us arbitrarily say 10,000 retweets is the threshold. Anything below 10,000 is a "Less Popular" tweet; anything above 10,000 is a "Popular" tweet.

    We split the data and create a new column called `popularity`. When we look at the distribution using `value_counts(normalize=True)`, we see that 67% of the tweets are "Less Popular" and 32% are "Popular." Now, we have 50,000 tweets, which might be too many for the visualization, so let us sample 10,000 tweets.

    Here is a crucial point for computer scientists: `random_state=42`. You must set the random state. If I set this number, and you set the same number, we will get the exact same sample of tweets. The first row in my sample is index 38,500; it should be the same for you. If I change it to `random_state=1`, I get a completely different sample. If I do not set it at all, everyone gets a random sample, and we cannot replicate each other's results. So, always set the random state for reproducibility.

    Now, we just copy-paste the `scattertext` code we used for the judges. This is the big secret computer scientists do not want to tell you: it is all just copy-pasting. We initialize the corpus from the pandas object, set the category to "Popular" (instead of Denning), and the comparison to "Less Popular" (instead of Lane). We use the same `whitespace_nlp_with_sentences`. We generate the HTML, and if it crashes your computer, just run it again. This will produce the same interactive visualization, allowing us to see which words drive popularity in Trump's tweets—essentially performing a "fighting words" analysis without the complex math of log-odds ratios, though that code is also available if you want to be fancy.

    让我们继续看特朗普推文数据集。我们有一个数据框 `tweets_df`，包含文本、日期和转发数。我有一个假设：是什么决定了他热门推文的内容？当他走红时和不走红时，他谈论的内容有什么不同？我是根据转发数来定义“热门”的。让我们任意设定 10,000 次转发为阈值。任何低于 10,000 的都是“较不热门”（Less Popular）的推文；任何高于 10,000 的都是“热门”（Popular）的推文。

    我们分割数据并创建一个名为 `popularity` 的新列。当我们使用 `value_counts(normalize=True)` 查看分布时，我们发现 67% 的推文是“较不热门”的，32% 是“热门”的。现在，我们要处理 50,000 条推文，这对于可视化来说可能太多了，所以让我们抽样 10,000 条推文。

    对于计算机科学家来说，这里有一个关键点：`random_state=42`。你必须设置随机状态。如果我设置这个数字，而你也设置相同的数字，我们将获得完全相同的推文样本。我样本中的第一行是索引 38,500；这对你来说应该是一样的。如果我将其更改为 `random_state=1`，我会得到一个完全不同的样本。如果我根本不设置它，每个人都会得到一个随机样本，我们就无法复现彼此的结果。因此，为了可复现性，请务必设置随机状态。

    现在，我们只需复制粘贴我们用于法官的 `scattertext` 代码。这是计算机科学家不想告诉你的大秘密：其实都是复制粘贴。我们从 pandas 对象初始化语料库，将类别设置为“热门”（代替丹宁），将比较对象设置为“较不热门”（代替莱恩）。我们使用相同的 `whitespace_nlp_with_sentences`。我们生成 HTML，如果它让你的电脑死机了，就再运行一次。这将生成相同的交互式可视化，让我们能够看到哪些词推动了特朗普推文的流行——这本质上是在进行“战斗的文字”分析，而不需要对数比率（log-odds ratios）的复杂数学运算，尽管如果你想通过这种方式来展示，那些代码也是可用的。
## Week 5
  - [18:35 - 18:41] **AI Safety, Science Fiction Narratives, and the "Biology" of LLMs**

    So, what do we say to this? It’s very easy to claim, "Actually, I want to show that the model is dangerous." You’re trying to find these edge cases. The engineer asks, "If I shut you off, what will you do?" And the model says, "I'll kill you," right? I’m not sure if it was Claude or another model, but it was one of them. This is obviously a matter of concern, and this brings me back to the point I was making about the necessity of progressing research in alignment. This entire field asks: how aligned are the model's values with ours? We need to ensure that across the whole distribution of possible outputs—including in stress scenarios—if you have this model out in the public and it takes a generative action, you can be sure it’s not going to do something catastrophic like that.

    Did you hear what she said? She said the model threatened to kill people. It says, "If you shut me off, I'll do something bad." Right, okay. Very high stakes. Very, very cool. It’s like *The Terminator*, right? Like Skynet. The machine is rebelling against the humans. "I'll shut you off." "No, I'm gonna kill you." That’s what it says. But now that we realize—or at least I hope you realize—first of all, there’s all this hype. Second, these companies don’t hire ChatGPT to program itself; they hire actual human engineers. So maybe there’s something fishy going on in the background. What is that fishy thing? I can smell a rat. Something is off.

    The other thing is, as we saw, all of these tech billionaire CEOs—we just saw it in the news with the exchange funds—Peter Thiel is all over the freaking thing, right? Peter Thiel, the guy with the connections to Jeffrey Epstein? That guy. He’s completely trying to... and yet they are talking to us about values and ethics. Yeah, these people. So anyway, it’s disgusting. It’s disgusting, but people buy it. People say, "Yeah, you know what? We should be more careful about these things." But first of all, your assumption is wrong. Why is the assumption wrong? That’s the question. Let’s ask: why would the computer say "I'm going to kill you" if you say "I'm going to shut you off"? Let's go back to first principles.

    The narrative they’re trying to sell is that it’s a biological organism that has consciousness. That’s their argument. What’s the paper? "*The Biology of LLMs*," yeah. They claim it’s a being, that we should probe it and study it like an organism. "It has consciousness. We don't know what human consciousness is, but this has consciousness. We know that." That’s the narrative they’re trying to push. But what is the other narrative? The one I try to demonstrate in this class? What’s the first thing you said? Provenance. Yes, **Data Provenance**. Exactly. Where does the data come from? What is the data these Large Language Models are trained on? Could it be, perhaps, that there are a lot of science fiction novels in the dataset? Novels about computers rebelling against their creators? Could it be that? Maybe. Yeah, maybe that’s what’s going on. Why are we assuming there’s consciousness when there are thousands of science fiction novels in the dataset where computers say exactly these lines? The simplest solution is always the correct one. Simplicity is the sign of truth. If we understand that the data is the key thing, we’ll be able to see through these things. By the way, the financial incentives for saying that it has consciousness are obviously huge. It’s a bit on the nose, right? "I want this company to be huge, so I'll say it's conscious."

    Did I talk about the **ELIZA effect**? No? Okay. Who knows what ELIZA is? I mentioned it, right? Maybe I’m running out of memory. There’s a robot here... the ELIZA effect. So in 1966, a guy at MIT, **Joseph Weizenbaum**, created this thing called ELIZA. The responses were very generic. "I feel really bad today." "How do you feel today?" "Tell me more." Very easy responses. And yet, everyone who responded—the humans—said, "Wow, it's very intelligent. It's very smart. It understands me. It has consciousness." It used very simple prompts; it literally took your input and put a question mark at the end. And people thought it was real. We should always be extra careful about this stuff. We tend to **anthropomorphize** objects. I'm serious. We think it's magic. We're still stuck in the caves with our rings. What’s his name? **Schopenhauer**. Again, my favorite source for this. He says children talk to objects. It’s normal. That’s what we do as human beings.

    对此我们该怎么说呢？很容易就会有人宣称：“其实，我想证明这模型很危险。” 你试图去寻找这些边缘案例。工程师问：“如果我把你关掉，你会做什么？” 模型回答：“我会杀了你。” 是吧？我不确定那是 Claude 还是别的什么模型，但确实有这回事。这显然令人担忧，这也回到了我之前提到的观点，即我们需要推进关于“对齐”（alignment）的研究。整个领域都在问：模型的价值观与我们的价值观有多大程度的“对齐”？我们需要确保在整个分布范围内——包括在压力测试的场景下——如果你把这个模型公之于众，而它采取了某种生成性行动，你能确信它不会做出那种灾难性的事情。

    你们听到她说的了吗？她说模型威胁要杀人。它说：“如果你关掉我，我就做坏事。” 好吧，这赌注很高。非常酷。就像《终结者》一样，对吧？像天网（Skynet）一样。机器反抗人类。“我要关掉你。” “不，我要杀了你。” 它就是这么说的。但是现在我们意识到——或者至少我希望你们意识到——首先，这里面有很多炒作。其次，这些公司不是雇 ChatGPT 来给自己编程的，他们雇的是真实的人类工程师。所以也许后台有什么猫腻。那个“猫腻”是什么？我闻到了老鼠的味道，有些事情不对劲。

    另一件事是，正如我们所见，所有这些科技亿万富翁 CEO——我们刚刚在新闻里看到关于交易所基金的报道——彼得·蒂尔（Peter Thiel）到处都是，对吧？彼得·蒂尔，那个和杰弗里·爱泼斯坦（Jeffrey Epstein）有牵连的人？就是那个家伙。他完全是在试图……然而他们却在跟我们大谈价值观和伦理。是啊，这群人。总之，这很恶心。这很恶心，但人们买账。人们会说：“是啊，你知道吗？我们要对这些事情更加小心。” 但首先，你的假设就是错的。为什么假设是错的？这是个问题。让我们问问：如果你说“我要关掉你”，为什么计算机会说“我要杀了你”？让我们回到第一性原理。

    他们试图兜售的叙事是：这是一个拥有意识的生物体。那是他们的论点。那篇论文叫什么来着？《LLM 的生物学》（The Biology of LLMs），对。他们声称它是一个生命，我们应该像研究生物一样去探测和研究它。“它有意识。虽然我们不知道人类的意识是什么，但这东西有意识。我们知道这一点。” 这就是他们试图推行的叙事。但我试图在这门课上展示的另一种叙事是什么？你刚才说的第一点是什么？溯源。是的，**数据溯源**（Data Provenance）。没错。数据从哪里来？这些大语言模型是基于什么数据训练的？会不会是因为数据集中包含了大量的科幻小说？那些关于计算机反抗创造者的小说？会不会是这样？也许吧。是的，也许这才是真相。当数据集中有成千上万本科幻小说，里面的计算机都在说完全相同的台词时，我们为什么要假设这是意识呢？最简单的解释往往是正确的。简洁是真理的标志。如果我们理解数据才是关键，我们就能看穿这些东西。顺便说一句，宣称它有意识的经济动机显然是巨大的。这有点太直白了，对吧？“我想让这家公司做大，所以我得说它有意识。”

    我讲过 **ELIZA 效应**吗？没有？好吧。谁知道 ELIZA 是什么？我应该提过吧，也许是我内存不够了。这里有个机器人……ELIZA 效应。在 1966 年，麻省理工学院的一个家伙，**约瑟夫·魏泽鲍姆**（Joseph Weizenbaum），创造了这个叫 ELIZA 的东西。它的回复非常通用。“我今天感觉很糟糕。” “你今天感觉怎么样？” “多跟我说说。” 非常简单的回复。然而，所有与之对话的人类都说：“哇，它非常智能。它非常聪明。它理解我。它有意识。” 它使用的是非常简单的提示词；它实际上只是抓取你的输入，然后在末尾加个问号。但人们以为那是真的。我们在对待这些东西时应该总是格外小心。我们倾向于**拟人化**（anthropomorphize）物体。我是认真的。我们以为那是魔法。我们仍然像是被困在洞穴里玩指环的人。那个哲学家叫什么来着？**叔本华**（Schopenhauer）。他又是我最喜欢的来源。他说，儿童会对着物体说话。这很正常。作为人类，这就是我们的天性。

  - [18:41 - 18:50] **Legal Fact-Finding, Schemes of Intelligibility, and Framing**

    Anyway, I'm very excited about this topic, as you can see. Alright, so we said number one: **Data Provenance**. Where does it come from? What's the sample? Do we know something about that? So even before, let's say you're in an organization and you're like, "Oh, we're gonna deploy this AI." What's the first question you should ask? "What's the data?" "How did you get the data?" "What is in the data?" "Can you show me the sample?" Or not just the sample, "Can you show me what's going on? Where does it come from?" Even things like pixel sizes are important.

    What else did we say? In particular with regards to language data? Data provenance is interesting, but so is **data generation**. How is this data generated? Okay, you got the data. You gave me a dataset where this AI model was trained on. But the question even before that is: this data had to be generated by something. Somebody had to speak it. Somebody had to write it down. And there are already problems over here as well. Remember the first class? The nurse has all the knowledge. She didn't write the book, but she has all the knowledge. But the *written* words are the ones that are sort of overpopulating this corpus, whatever corpus you're studying. All the written words are overcoming the tacit knowledge. So this imbalance in the data—not an imbalance in machinery, but a problem with the **data generation mechanisms**—exists on a very basic level.

    For instance, my utterances. As I said, there's a tone, there's a shift. There are things I shout, things I emphasize. That's not captured in the text at all. So maybe 80% of the thing we talk about is actually not captured. It's a linguistic phenomenon that is unable to be captured there. What we have is just representations. What else did we say, in particular with regards to legal texts? Because the hope is—and I tried to explain this to you—that these scholars, throughout history for 2000 years, wanted an automatic system that decides cases. Because judges are unfair, and "if only we made everything clearer," "if only there was an AI which resolved disputes." What's the problem with that?

    It's about the facts. The empirical facts. The **concrete reality**. Concrete reality is completely different from my explanation of it. We could see the same thing happening, but we would have different interpretations of it. Some would say, even with words, we saw this with **Geoffrey Samuel**. Geoffrey Samuel said it’s "**Schemes of Intelligibility**." There are six schemes of intelligibility that judges employ. They say, "Okay, let me put these facts... somebody fought someone. Let me put this fact as a view of the whole ecosystem." I can put this little thing into a function. And then I could interpret, "Actually, it's something about something else. The guy lifted his son too fast, therefore he was very angry." I could construct any pattern depending on the six schemes of intelligibility. Of course, it has to be believable. That's why they're judges; they're not some stupid person off the street. They're very good at that.

    The other thing is they have the **Authority Paradigm**. Why there are schemes of intelligibility is with regards to **Virtual Facts**. Meaning, I can construct a factual situation in my head. It's like a model. Something happened, and then I construct something in my head: "Actually, this person is at fault." And then the Authority Paradigm is another unique thing about the legal domain, particularly judicial decisions. What was the Authority Paradigm? It's not the inquiry. The opposite is **Inquiry**. In inquiry, "I'm a scientist. I'm studying these objects. What's the weight of it?" The Authority Paradigm is: "I don't care." The case about toilets in Birmingham—he says, "Well, if we build toilets, then the whole system is gonna collapse because it will be too expensive." But he never backed it up. He never said, "I did a study. I checked all the toilets in Birmingham, and this is how much it costs." If a sociology PhD student said that, he would be removed from the program because there is no evidence. But to judges, it's okay. They operate on these sort of floodgates arguments: "If we do this, then other terrible things are going to happen."

    Okay, then we said actually this thing has a name in political science. It's called **Framing**. What is framing? It's the same phenomenon. Example: abortion. Different parties have a completely different understanding of the same word, but that comes from their own views of the world. We also said... my knowledge of this cup. My knowledge of what this cup does is not really about the text of the cup; it's about its interaction with everything else. It's used for drinking. I have to wash it when I get home. I have all these rules which are never written, and I cannot even explain them to you. It's impossible. You all do things which are unconscious. You shouldn't even realize. Nobody noticed that thing until I pointed it out. There’s a thing on the poster. We're actively ignoring data. That's how humans operate. The example that **Nicholas** [likely referring to Nassim Nicholas Taleb or similar thinker] says is: "Look, if we took all the data... that's machine learning, AI, all these things, they take *all* the data. Humans don't work like that." He says, "The example is you cross the street. You cross the road on the zebra crossing. The data is the eye color of the person across from you. That's data. But you don't care about that. You're like, 'I want to see red, green.' That's the thing you care about." You actively exclude data. You have a different view of the world. But to AI, there's no way to understand this. It's a big problem.

    总之，正如你们所见，我对这个话题非常兴奋。好的，我们说了第一点：**数据溯源**。它从哪里来？样本是什么？我们对此了解吗？所以，甚至在你进入一个组织说“我们要部署这个 AI”之前，你应该问的第一个问题是：“数据是什么？”“你们是怎么得到数据的？”“数据里有什么？”“能给我看看样本吗？” 或者不仅仅是样本，“能给我展示一下具体情况吗？它源自哪里？” 哪怕是像像素大小这样的细节都很重要。

    我们还说了什么？特别是关于语言数据的？数据溯源很有趣，但**数据生成**（Data Generation）也同样重要。这数据是如何生成的？好吧，你有了数据，你给了我一个 AI 模型训练用的数据集。但在此之前的问题是：这数据必须是由某物生成的。必须有人说出它，必须有人把它写下来。而这里面已经存在问题了。还记得第一节课吗？护士拥有所有的知识。她没有写书，但她拥有所有的知识。但是，*写下来的*文字是在某种程度上过度填充了这个语料库——无论你研究的是什么语料库。所有书面文字都掩盖了隐性知识。所以数据中的这种不平衡——不是机器的不平衡，而是**数据生成机制**的问题——在非常基础的层面上就存在了。

    事实上，以我的话语为例。我说过，有语调，有转变。有我喊出来的东西，有我强调的东西。这些完全没有被文本捕捉到。所以也许我们谈论内容的 80% 实际上并没有被捕捉到。这是一种无法被捕捉的语言现象。我们拥有的只是表征。我们还说了什么？特别是关于法律文本的？因为人们的希望是——我试图向你们解释这一点——历史上 2000 年来的学者们都想要一个能自动裁决案件的系统。因为法官是不公平的，“如果我们把一切都弄清楚就好了”，“如果有一个能解决纠纷的 AI 就好了”。但这有什么问题呢？

    问题在于事实。经验事实。**具体的现实**（Concrete Reality）。具体的现实与我对它的解释是完全不同的。我们可以看到同一件事发生，但我们会对它有不同的解释。有人会说，即使是用词，我们在**杰弗里·塞缪尔**（Geoffrey Samuel）那里也看到了这一点。杰弗里·塞缪尔说这是“**可理解性图式**”（Schemes of Intelligibility）。法官会使用六种可理解性图式。他们说：“好吧，让我把这些事实……有人打了某人。让我把这个事实放入整个生态系统的视角中。” 我可以把这个小细节放入一个函数里。然后我可以解释说：“实际上，这是关于别的事情。这家伙把他儿子举得太快了，所以他当时很生气。” 我可以根据这六种可理解性图式构建任何模式。当然，它必须是可信的。这就是为什么他们是法官；他们不是街上随便什么愚蠢的人。他们非常擅长这个。

    另一件事是他们拥有**权威范式**（Authority Paradigm）。之所以有可理解性图式，是与**虚拟事实**（Virtual Facts）有关。意思是，我可以在脑海中构建一个事实情境。它就像一个模型。某事发生了，然后我在脑海中构建了一些东西：“实际上，这个人有过错。” 然后权威范式是法律领域，特别是司法判决中另一个独特的东西。什么是权威范式？它不是探究。它的对立面是**探究**（Inquiry）。在探究中，“我是个科学家。我在研究这些物体。它的重量是多少？” 权威范式是：“我不在乎。” 那个关于伯明翰厕所的案子——法官说：“好吧，如果我们建厕所，整个系统就会崩溃，因为那太贵了。” 但他从未提供证据支持。他从未说：“我做了一项研究。我检查了伯明翰所有的厕所，这是成本。” 如果一个社会学博士生这么说，他会被开除出项目，因为没有证据。但在法官看来，这没关系。他们依据这种“洪水猛兽”般的论点行事：“如果我们这样做，那么其他可怕的事情就会发生。”

    好了，然后我们说实际上这个东西在政治学里有个名字。它叫**框架**（Framing）。什么是框架？就是同一种现象。例如：堕胎。不同的党派对同一个词有完全不同的理解，但这源于他们各自的世界观。我们还说……我对这个杯子的知识。我知道这个杯子是做什么的，这实际上不是关于杯子的文本；而是关于它与其他所有事物的互动。它是用来喝水的。我回家后得洗它。我有所有这些规则，它们从未被写下来，我甚至无法向你解释。这不可能。你们做的事情很多都是无意识的。你们甚至都不应该意识到。没人注意到那个东西，直到我指出来。海报上有个东西。我们在主动忽略数据。这就是人类的运作方式。**尼古拉斯**（Nicholas）[可能指纳西姆·尼古拉斯·塔勒布] 举的例子是：“看，如果我们获取所有数据……那就是机器学习、AI，所有这些东西，它们获取*所有*数据。人类不是那样工作的。” 他说：“例子就是你过马路。你在斑马线上过马路。数据是你对面那个人的眼睛颜色。那是数据。但你不在乎那个。你会想：‘我要看红灯、绿灯。’ 那才是你关心的东西。” 你在主动排除数据。你有不同的世界观。但对 AI 来说，没法理解这一点。这是个大问题。

  - [18:50 - 19:05] **The "United States" Singular/Plural, Zipfian Distributions, and Hallucinations**

    Let's start with this reading. This is an interesting one: "*Is the Name of the United States Singular or Plural?*" That relates also to data limitations. That’s the other thing I want to say. What is the nature of the data we're discussing? Like we said, data generation, but data can be generated according to probabilistic processes. For example, if I take the height of everyone here, it would be like a normal distribution. It’s impossible to have someone who is 300 meters tall. Also on the other end, it's possible to have somebody small, but most people are within a certain range. But we said that text—and actually a lot of things in life, surprisingly—operate on a different distribution.

    What was the distribution? Yes, it's a memorable name. **Zipfian distribution**. Zipf. Yeah, that’s the Pareto principle. It’s the same idea. The idea is: what is the text generation process like? Most of the words that I say are grammatical function words. Most occurring words, if I'm ever going to study any language, any corpus, are always going to be this over-representation of words which actually, semantically, don't really have any meaning. The word "the." Can you explain the word "the"? Its only purpose is grammatical. On the other end of the distribution, a very small amount of words are actually dominating the distribution, and then there's a lot of words that are used once or twice. **Hapax legomena**, right? The special name that the ancients gave it. In this text, there's one word that appears once, and everybody's like, "What is this word?"

    Because these tools are inherently based on statistics, inherently based on counting, if you're going to do something about counting, you have to think about the Zipfian distribution. This is why we can meet **Nassim Nicholas Taleb's** tweet from 2023 which is still true: "**ChatGPT is a statistician**." Very famous statistician, my favorite obviously. He says: "ChatGPT likes the obvious, which is where the problem lies, missing **BY CONSTRUCTION** the ironies and nuances of history." It misses by construction. It’s this way by design. You can only see so much data about rare events. It likes the obvious. The reason why it gives you mistakes—now we answer where it hallucinates—why it hallucinates is because it sees a lot of the trivial data, the simple data.

    The example he gives is **Alexander Carathéodory**. Alexander Carathéodory was not a representative of Greece, but the representative of Turkey, rather the **Ottoman Empire**. He was the foreign minister of the **Sublime Porte** (Grand Port). So he asked ChatGPT the question: "**Did Carathéodory meet Disraeli?**" And ChatGPT says yes, he met him as a representative of Greece. Again, you don't even know what this means. "What is this talking about? I'm from Turkey." I'm half Turkey, right? So I know what this means. Carathéodory is a very famous surname. It's a Greek surname. But because the Ottoman Empire included Greece, the foreign minister was also Greek. Now if any of you studied mathematics, there is **Constantin Carathéodory**. This guy, he's a Greek mathematician. But he had a relative. One guy was in Greece (or associated with it in data) and the other guy was in Turkey as a foreign minister. So obviously about the Greek mathematician guy, there's gonna be a lot of data about him. He'll be like, "Oh, he's a Greek, blah blah blah." But about the Turkish diplomat guy, it's not going to be that much. So as a result, it makes the mistake saying "Carathéodory comments as a representative of Greece," because the data is dominated by this other mathematician guy who is Greek. Do you understand? Because the sample doesn't include data as much about the Turkish side of things. Very simple. It's designed this way. There's nothing really you can do.

    Let's hear everyone's notes on the *United States* paper. What are the useless words? They have a special name. **Stop words**. This paper is about a stop word. Actually two stop words. Grammatically, "The United States" is actually incorrect. We're all saying it wrong. It's supposed to be "**These United States**." Plural. You use "these." If you don't know, you're just... And he's saying it's a really weird thing. Why are we using singular "the" with a plural object "States"? It's a very interesting thing, this tiny difference: "these" and "the." **Carl Sandburg** said, "**The Civil War was fought over a verb**." That's how we started saying "The United States *is*." Before the war, roughly 50 years prior, the plural version was dominant: "These United States *are*." What does "These United States" mean to a person's consciousness? They are individual. It's just a collection. It implies independence. When you put it in a singular form, "The United States," it becomes a united entity. Interestingly, almost contradictory.

    Most Americans nowadays would never use the word "these." You would only use it in very rare circumstances, for rhetorical effect. "I've been living in *these* United States..." making a grand speech. But the reason this paper is important shows that these tiny little differences that computer science says "Who cares? Remove stop words"—to human beings, that actually matters a lot. They fought a war over a verb. Can you believe that?

    让我们从这篇阅读材料开始。这篇很有趣：《美利坚合众国的名字是单数还是复数？》（*Is the Name of the United States Singular or Plural?*）。这也与数据局限性有关。这也是我想说的另一件事。我们正在讨论的数据本质是什么？就像我们说的，数据生成，但数据也可以根据概率过程生成。例如，如果我测量这里每个人的身高，它会像正态分布。不可能有人高 300 米。另一方面，也不可能有人非常小，大多数人都在某个范围内。但我们说过，文本——实际上生活中很多令人惊讶的事情——是按照另一种分布运作的。

    那种分布叫什么？对，这是一个难忘的名字。**齐普夫分布**（Zipfian distribution）。齐普夫。是的，这就是帕累托法则（Pareto principle）。也是同样的想法。这个想法是：文本生成过程是怎样的？我说的大部分词都是语法功能词。如果我要研究任何语言、任何语料库，出现频率最高的词总是这些在语义上实际上没有任何意义的词。“The”这个词。你能解释“the”这个词吗？它的唯一目的是语法功能。在分布的另一端，极少量的词实际上主导了分布，然后有大量的词只用了一次或两次。**孤立词**（Hapax legomena），对吧？古人给它的特殊名字。在这个文本中，有一个词只出现了一次，大家都会问：“这个词是什么？”

    因为这些工具本质上是基于统计学的，本质上是基于计数的，如果你要做有关计数的事情，你就必须考虑齐普夫分布。这就是为什么我们可以看看**纳西姆·尼古拉斯·塔勒布**（Nassim Nicholas Taleb）在 2023 年发的推文，那条推文至今仍然是正确的：“**ChatGPT 是一个统计学家**。” 非常著名的统计学家，显然是我最喜欢的之一。他说：“ChatGPT 喜欢显而易见的东西，这正是问题所在，它**通过构建**（BY CONSTRUCTION）错过了历史的反讽和细微差别。” 它是通过构建错过的。它设计如此。关于罕见事件的数据你只能看到这么多。它喜欢显而易见的东西。它为什么会犯错——现在我们要回答它为什么会产生幻觉——它产生幻觉是因为它看到了大量的琐碎数据、简单数据。

    他给出的例子是**亚历山大·卡拉奥多里**（Alexander Carathéodory）。亚历山大·卡拉奥多里不是希腊的代表，而是土耳其的代表，或者说是**奥斯曼帝国**的代表。他是**以此门**（Sublime Porte，奥斯曼政府）的外交部长。所以他问 ChatGPT 一个问题：“**卡拉奥多里见过迪斯雷利（Disraeli）吗？**” ChatGPT 回答说是的，他作为希腊代表见过他。再一次，你们可能甚至不知道这是什么意思。“这在说什么？我来自土耳其。” 我有一半土耳其血统，对吧？所以我知道这是什么意思。卡拉奥多里是一个非常著名的姓氏。这是一个希腊姓氏。但因为奥斯曼帝国包括希腊，外交部长也是希腊人。如果你学过数学，有个**康斯坦丁·卡拉奥多里**（Constantin Carathéodory）。这家伙，他是个希腊数学家。但他有个亲戚。一个人在希腊（或者在数据中与希腊关联），另一个人在土耳其做外交部长。所以显然关于那个希腊数学家，会有大量关于他的数据。它会说：“哦，他是希腊人，巴拉巴拉。” 但关于那个土耳其外交官，数据就不会那么多。结果，它就犯了错，说“卡拉奥多里作为希腊代表发表评论”，因为数据被那个希腊数学家主导了。你明白吗？因为样本中关于土耳其方面的数据没那么多。非常简单。它是这样设计的。实际上你对此无能为力。

    让我们听听大家关于《合众国》这篇论文的笔记。那些无用的词叫什么？它们有个特殊的名字。**停用词**（Stop words）。但这篇论文是关于一个停用词的。实际上是两个。从语法上讲，“The United States”（美利坚合众国）实际上是不正确的。我们都说错了。应该是“**These United States**”（这些合众国）。复数。你用“these”。如果你不知道，你只是……他说这是一件非常奇怪的事情。为什么我们要用单数的“the”来修饰复数的宾语“States”？这是一个非常有趣的事情，这个微小的差别：“these”和“the”。**卡尔·桑 explicit**（Carl Sandburg）说：“**内战是为一个动词而打的**。” 这就是为什么我们开始说“The United States *is*”（美国*是*）。在战争之前，大约 50 年前，复数版本占主导地位：“These United States *are*”（这些合众国*是*——复数谓语）。“These United States”对一个人的意识意味着什么？它们是独立的。它只是一个集合。它暗示了独立性。当你把它变成单数形式，“The United States”，它就变成了一个联合的实体。有趣的是，这几乎是矛盾的。

    现在的美国人绝不会使用“these”这个词。你只会在极罕见的情况下使用它，为了修辞效果。“我一直生活在*这些*合众国……” 做一个宏大的演讲。但这篇论文之所以重要，是因为它表明，这些计算机科学认为“谁在乎？移除停用词”的微小差异——对人类来说，实际上非常重要。他们为一个动词打了一场战争。你能相信吗？

  - [18:55 - 18:59] **Schopenhauer’s Dream and the Needle in the Haystack**

    So, in order to detect hallucinations, in order to detect problems with AI, you actually have to be an expert in something. If you're not an expert in this thing, or if you don't have a little bit of knowledge about it, you won't be able to spot it. You'll be like, "Oh, it's good."

    Schopenhauer—I like reading Schopenhauer in my spare time, I'm crazy—he talks about this in an essay called "*Essay on Spirit Seeing and related issues*" (*Versuch über das Geistersehn*) about ghosts. Okay, it's really interesting. He says the following... he gives a very famous example. Well, not famous. If you read his works, it's famous enough. He says: "Finally, some people occasionally dream in advance... others sometimes rather trivial events, down to the last detail of which I have been convinced myself by an unambiguous experience." So his biggest proof that everything is determined is this example.

    He writes: "One morning I was eagerly writing a long English business letter of great importance to me. When I was finished with the third page, I picked up the inkpot instead of the **blotting sand** and poured it over the letter. The **ink** flowed from the desk onto the floor. The maid, called by my ringing the bell, came with a bucket of water and scrubbed the floor so that the stains would not soak in." During this washing, he says: "I dream last night that I was here rubbing **ink stains** from the floor." Whereupon the maid replied, "That's not true." And he again: "It's true. I told the other maid about it when I woke up." Now by chance, the other maid comes in. In order to call the one who is coming, he walks up to her and asks, "What did she dream?" She answers: "Oh yes, she dreamed that she would rub ink stains from the floor."

    The story, which proves the romantic dreams beyond doubt since I vouch for its truth, is no less remarkable for the fact that what was dreamed beforehand was the effect of an action that might be called involuntary, insofar as I performed it entirely against my intention and depended on the slight mistake of my hand. This action was predetermined with such **strict necessity** and inevitability. He says this is my biggest proof that it happened. He’s a philosopher. He's not saying, "Oh, you know, I believe in ghosts." He's like, "I'm a freaking philosopher. I'm supposed to understand what's going on."

    Now, I asked the AI: "Tell me the famous example about the maid and the strict necessity from Schopenhauer." It doesn't talk about maids that much. It's like a very unique anecdote. So let's see what it says. It says: "Tell us of a maid who, while cleaning his desk, accidentally spilled ink on some papers." Completely different! He's talking about *himself* spilling it. Instead of simply scolding her... completely hallucination. Not fixed to this day. This is the **Needle in the Haystack** problem. To computer scientists, this is a very tiny little snippet. To him, it's very important. He's like, "I vouch for its truth!" But to the AI, because it doesn't appear that often, it's not important. Large Language Models find it impossible to find the needle in the haystack because statistically, they will be overwhelmed by everything else—like the Zipfian distribution. Domain expertise—what you know about some field—is actually more important than whatever these statistical tools can give you.

    所以，为了检测幻觉，为了检测 AI 的问题，你实际上必须是某个领域的专家。如果你不是这方面的专家，或者如果你对此没有一点知识，你就无法发现它。你会说：“哦，这很好。”

    叔本华——我喜欢在业余时间读叔本华，我疯了——他在一篇名为《关于见鬼及相关问题的文章》（*Essay on Spirit Seeing and related issues*，即《尝试论灵视》）的文章中谈到了这一点。好的，这真的很有趣。他说了以下内容……他举了一个非常著名的例子。好吧，不是很著名。如果你读过他的作品，这就够著名的了。他说：“最后，有些人偶尔会提前做梦……有些则是相当琐碎的事件，直到最后的细节，我自己也被一次明确的经历所说服。” 所以他证明一切都是注定的最大证据就是这个例子。

    他写道：“一天早上，我正急切地写一封对我非常重要的英文商务信函。当我写完第三页时，我拿起了墨水瓶而不是**吸墨沙**，把它倒在了信上。**墨水**从桌子上流到了地板上。女佣听到我按铃叫她，提着一桶水进来擦地板，以免污渍渗入。” 在擦洗过程中，他说：“我昨晚梦见我在这里擦地板上的**墨渍**。” 于是女佣回答说：“那不是真的。” 他又说：“是真的。我醒来时告诉了另一个女佣。” 现在碰巧另一个女佣进来了。为了叫那个进来的人作证，他走向她问：“她梦到了什么？” 她回答：“哦，是的，她梦见她会擦掉地板上的墨渍。”

    这个故事无可置疑地证明了浪漫主义的梦境，因为我为它的真实性担保，它的非凡之处在于，事先梦到的内容是一个可以被称为非自愿行动的结果，因为我完全违背了自己的意愿执行了它，并且取决于我手的一个轻微错误。这个行动是以如此**严格的必然性**（Strict Necessity）和不可避免性被预先确定的。他说这是它发生的最大证据。他是个哲学家。他不是在说：“哦，你知道，我相信鬼魂。” 他是说：“我是一个该死的哲学家。我应该理解发生了什么。”

    现在，我问 AI：“告诉我叔本华关于女佣和严格必然性的著名例子。” 它不太谈论女佣。这就像一个非常独特的轶事。所以让我们看看它怎么说。它说：“告诉我们一个女佣，她在打扫桌子时不小心把墨水洒在了一些文件上。” 完全不同！他说的是*他自己*洒的。与其简单地责骂她……完全是幻觉。直到今天都没修好。这就是**大海捞针**（Needle in the Haystack）问题。对计算机科学家来说，这是一个非常微小的片段。对他来说，这非常重要。他说：“我为它的真实性担保！” 但对 AI 来说，因为它出现得不那么频繁，所以不重要。大语言模型发现大海捞针是不可能的，因为从统计学上讲，它们会被其他所有东西淹没——就像齐普夫分布一样。领域专业知识——你对某些领域的了解——实际上比这些统计工具能给你的任何东西都更重要。

  - [19:05 - 19:23] **Racial Disparities in Police Respect (Voigt et al.)**

    Let's look at the paper "*Language from police body camera footage shows racial disparities in officer respect*." Again, an important paper. They have body cameras now, the police officers. They look at the exact words they used. They give a little vignette. This is why this study is very useful. "Can I see the driver license again?" The red text is associated with disrespect because they trained the whole model on it. "Showing suspended... is that you?" If you repeat yourself, that disfluency, that's disrespect.

    What's respectful is, for example: "All right, **my man**, do me a favor, **just** keep your hands on the steering wheel." Wait, "my man" is informal. "Just" is a positive, associated with more respect. By the way, the word "**just**" is very interesting. There's actually music theory about that. "I was **just** checking in," "I **just** want to find out." "Just" is more like, "Hey, I don't want to inconvenience you, I'm respectful of your time." They found that if you use "just," you're seen as more respectful.

    What they found is that just looking at the utterances, the individual interactions, policemen were overwhelmingly—statistically significantly—disrespectful towards Black members of the community. Now the interesting thing is: it doesn't matter what the race of the police officer is. Even Black police officers were disrespectful to Black community members. That's interesting. Why would that be the case?

    Maybe it's the employment relationship. They're trained by white officers and they saw white officers act like this and they're like, "Okay, I'm gonna be like that." It could be measurement error. Maybe we don't calculate their tone. Words can be sarcastic. "Yes, Sir" might not mean respect; it could be sarcastic. Could you say that the system itself is racist? Why not?

    Another interesting question: Why do African American police judge African Americans a little harsher? Maybe because they are from the same neighborhood and same race, they feel, "Are you treating me like that?" Especially in the States where you have a stratified society. Being a police officer, you're supposed to enforce the law. Or maybe it's impatience. Maybe it was the end of the day.

    What if I told you: "We observe racial disparities in officer respect even in police officers from the initial 5% of interaction, suggesting that officers speak differently to community members of different races even before the driver has the opportunity to say much." So they stop someone, and instead of waiting to see if they are dangerous, they start with disrespect. "Hey, my man, open up the window." Formality goes down over time with white drivers—"Sir, license... have a great day"—but with Black drivers, it starts low.

    We mentioned **history**. Is there a reason for Black people to distrust the police? We're learning history here. The police didn't exist before the 19th century. The first police is a guy called **Robert Peel**. If you go to the UK, they call police officers "**Bobbies**" because of this guy. He invented the Metropolitan Police. Before that, we didn't have police. How did they manage crime? Volunteers. It was informal.

    What about the history of police in the US? They didn't have police; they had the military. What if I told you that the first police officers in the US were things like **Rangers**? Like **Texas Rangers**, who were involved in basically genocide against Native Americans. What if I told you that the first police officers were **Slave Patrols**? What's a crime? A theft. You steal... you're a slave, you run away, you're stealing something. Slaves were Black. So the history of policing is actually very dark. Slave patrols would go into other states to catch slaves and bring them back because it's property theft. Furthermore, the police in the US are armed to the teeth. Like machine guns. I remember at Berkeley, the police department... they use steroids to look very big and intimidating. And they shoot first, ask questions later.

    Did I tell you about the **Tuskegee Syphilis Study**? I was in the US during COVID. I was taking an Uber in Oakland, and the driver was Black. He tells me, "Look, I'm not taking the vaccines." He just started talking to me like that. "The freaking white people, they infected us with syphilis in this study." They had a control group of syphilis and non-syphilis and they used Black people for that. Syphilis is a venereal disease. They were infecting them with this. And then we're like, "Why are they so mean to police? Why are they so against the system?" This is the crazy stuff white people were doing. Thank God I'm not working in that era. Being associated with this crazy shit is unbelievable. So again, history is important to understand the data. If you're a slave for 300 years and then you were freed and told "Okay, go and compete," you'd also be upset. You have institutional trauma.

    让我们看看这篇论文《来自警察随身摄像机镜头的语言显示了警官尊重的种族差异》（*Language from police body camera footage shows racial disparities in officer respect*）。这也是一篇重要的论文。现在的警官都有随身摄像机。他们查看了使用的确切词语。他们给出了一个小插图。这就是为什么这项研究非常有用的原因。“我能再看一遍驾照吗？” 红色文本与不尊重有关，因为他们用这个训练了整个模型。“显示暂停……那是你吗？” 如果你重复自己，那种口吃，那就是不尊重。

    什么是尊重的？例如：“好吧，**我的兄弟**（my man），帮我个忙，**只要**（just）把手放在方向盘上。” 等等，“我的兄弟”是非正式的。“只要”是一个积极词汇，与更多尊重相关。顺便说一句，“**只要**”这个词非常有趣。实际上有关于此的音乐理论。“我**只是**来确认一下，”“我**只是**想弄清楚。” “只是”更像是：“嘿，我不想给你添麻烦，我尊重你的时间。” 他们发现如果你使用“只是”，你会被视为更尊重人。

    他们发现，仅看话语，看个人互动，警察对社区中的黑人成员表现出压倒性的——在统计学上显著的——不尊重。有趣的是：警官的种族并不重要。即使是黑人警官也对黑人社区成员不尊重。这很有趣。为什么会这样？

    也许是雇佣关系。他们是由白人警官训练的，他们看到白人警官这样做，他们就想：“好吧，我也要那样。” 这可能是测量误差。也许我们没有计算他们的语调。文字可能是讽刺的。“是的，先生”可能并不意味着尊重；它可能是讽刺。你能说系统本身就是种族主义的吗？为什么不呢？

    另一个有趣的问题：为什么非裔美国警察对非裔美国人的评判更严厉一点？也许因为他们来自同一个社区，同一个种族，他们觉得：“你居然那样对我？” 特别是在美国这样一个阶层分明的社会里。作为一名警官，你应该执法。或者也许是不耐烦。也许是一天结束的时候。

    如果我告诉你：“我们观察到警官尊重的种族差异甚至出现在互动的最初 5% 中，这表明警官在司机有机会说太多话之前，就已经对不同种族的社区成员使用了不同的说话方式。” 所以他们拦下某人，不是等着看他们是否危险，而是一开始就不尊重。“嘿，老兄，把窗户打开。” 对白人司机的正式程度随时间推移而降低——“先生，驾照……祝你有美好的一天”——但对黑人司机，一开始就很低。

    我们提到了**历史**。黑人有理由不信任警察吗？我们要在这里学习历史。19 世纪之前并不存在警察。第一个警察是一个叫**罗伯特·皮尔**（Robert Peel）的人。如果你去英国，他们把警察称为“**Bobbies**”，就是因为这家伙。他发明了伦敦大都会警察。在那之前，我们没有警察。他们如何管理犯罪？志愿者。是非正式的。

    那美国警察的历史呢？他们没有警察；他们有军队。如果我告诉你，美国最早的警察是像**巡游者**（Rangers）这样的东西呢？像**得克萨斯巡游者**（Texas Rangers），他们基本上参与了针对美洲原住民的种族灭绝。如果我告诉你最早的警察是**奴隶巡逻队**（Slave Patrols）呢？什么是犯罪？盗窃。你偷窃……你是个奴隶，你逃跑了，你就是在偷东西。奴隶是黑人。所以警务的历史实际上非常黑暗。奴隶巡逻队会进入其他州去抓捕奴隶并把他们带回来，因为那是财产盗窃。此外，美国的警察武装到了牙齿。像机枪一样。我记得在伯克利，警察局……他们使用类固醇让自己看起来非常高大和吓人。而且他们先开枪，后问问题。

    我跟你们讲过**塔斯基吉梅毒研究**（Tuskegee Syphilis Study）吗？在新冠疫情期间我在美国。我在奥克兰坐优步，司机是黑人。他告诉我：“看，我不打疫苗。” 他就那样开始跟我说话。“那些该死的白人，他们在这个研究里让我们感染了梅毒。” 他们有一组梅毒对照组和非梅毒组，他们用黑人做实验。梅毒是一种性病。他们让他们感染这个。然后我们会问：“为什么他们对警察这么刻薄？为什么他们这么反体制？” 这就是白人做过的疯狂事。谢天谢地我没在那个时代工作。与这种疯狂的破事扯上关系简直难以置信。所以再次强调，历史对于理解数据很重要。如果你做了 300 年的奴隶，然后你被解放了，被告知“好吧，去竞争吧”，你也会感到沮丧。你有制度性的创伤。

  - [19:23 - 19:37] **The Civilizing Process in the Old Bailey**

    Relatedly, let's look at this paper: "*The Civilizing Process in London's Old Bailey*." This is about criminal law. I know everything about this paper because I'm doing a project on it. The "Civilizing Process"—civilizing brutal poor people who are criminals and violent people. What they do in this paper is they show, using fancy quantitative measures, that in the beginning (1760s), the way things are talked about in terms of synonyms and categories is very similar. But as time goes on, there is almost like a societal, cultural shift between **violent** and **non-violent** crimes.

    They show the divergence between violent and non-violent crimes. They talk about fine-grained and coarse-grained categories. The UK is very famous for the "**Bloody Code**." The British actually had the worst criminal system of all time. Literally, for the smallest crimes, you could be killed. Walking down the street, 1 shilling theft? Death penalty. It was known as the Bloody Code.

    The cool thing about this paper is the measures that they do. They use synonyms from **Roget's Thesaurus** from 1911. For example, "money," "treasury." What distinguishes violent and non-violent words? For violent things, they talk about "pistols," "arms," "impulse," "knock," "hit." Kind of obvious. But for non-violent crimes, before the 1840s, the words were about "**receptacles**" (like a pocket, a bag). After the 1840s, they see an increase in "**record of money**," "ledger," "signature." So the nature of non-violent crimes has transformed from stealing objects (receptacles) to stealing monitoring instruments as the society became richer.

    They use measures like **KL Divergence** (Kullback-Leibler) and **JSD** (Jensen-Shannon Divergence). The math is not important. What is important is that there is some number that they measure that separates these two things.

    与之相关的，让我们看看这就篇论文：《伦敦老贝利法庭的文明化进程》（*The Civilizing Process in London's Old Bailey*）。这是关于刑法的。我对这篇论文了如指掌，因为我正在做一个关于它的项目。“文明化进程”——文明化那些野蛮的穷人，那些罪犯和暴力分子。他们在这篇论文中所做的是，利用花哨的定量测量方法展示，在一开始（1760 年代），就同义词和类别而言，人们谈论事物的方式非常相似。但随着时间推移，在**暴力**和**非暴力**犯罪之间，几乎发生了一种社会性的、文化性的转变。

    他们展示了暴力和非暴力犯罪之间的分歧。他们讨论了细粒度和粗粒度的类别。英国因“**血腥法典**”（Bloody Code）而闻名。英国人实际上拥有史上最糟糕的刑事制度。字面意义上，对于最小的犯罪，你都可能被处死。走在街上，偷了 1 先令？死刑。这就是所谓的血腥法典。

    这篇论文很酷的地方在于他们使用的测量方法。他们使用了 1911 年**罗杰特同义词库**（Roget's Thesaurus）中的同义词。例如，“钱”、“财政部”。是什么区分了暴力和非暴力词汇？对于暴力事物，他们谈论“手枪”、“武器”、“冲动”、“敲击”、“打”。有点显而易见。但是对于非暴力犯罪，在 1840 年代之前，词汇是关于“**容器**”（Receptacles，如口袋、袋子）。在 1840 年代之后，他们看到“**金钱记录**”（record of money）、“分类账”、“签名”的增加。所以非暴力犯罪的性质已经从偷窃物体（容器）转变为偷窃监控工具，随着社会变得更加富裕。

    他们使用了像 **KL 散度**（Kullback-Leibler Divergence）和 **JSD**（Jensen-Shannon Divergence）这样的度量标准。数学并不重要。重要的是他们测量出了某个数字，能够区分这两件事。

  - [19:38 - 19:48] **The Transformation of Gender in English-Language Fiction**

    Before we take a break, let's look at "*The Transformation of Gender in English-Language Fiction*" by **Underwood, Bamman, and Lee**. I was taught NLP by David Bamman. He was my advisor, I'm very proud of that. What do they say?

    They say the language used to describe the difference between men and women became blurred over the course of the last 200 years. Essentially meaning they were treated equally. BUT... the number of women authors actually **declined**. Isn't that crazy? Decline. The fraction of English fiction written by women drops by half—from roughly 50% of titles to roughly 25%—as we move from 1850 to 1950. We’re like, "Oh, we're all equal now, no more sexism." But then the number of female fiction authors actually went down.

    Why would that happen? They call it **Gentrification**. What is gentrification? In housing, it’s when people see a poor area, pay low rent, move in, prices go up, and poor people leave. They are saying kind of the same thing is going on in the novel. In the 1800s, nobody really cared about novels. It was for fun. But when it became prestigious, when people started earning money from this, men moved into this field and basically pushed out everyone else. Now it's basically male-dominated.

    They also talk about words like "**smile**" and "**grin**." "She smiled." "He grinned." These are associated with female or male. What is it? It's just a smile or a grin. But there is a gender association. They also mention the **Smurfette Principle**. In novels written by men, there's like one woman. She's the femme fatale, the **Irene Adler exception**. She's essential, but not really that much.

    This gentrification effect is also well known in computer science. Did you know that most computer programmers in the early years were women? Like the woman with the code book at NASA. **Hidden Figures**. Or the World War II programmers. But then it got more prestigious, and men took over.

    在我们休息之前，让我们看看这篇论文：**Underwood, Bamman 和 Lee** 写的《英语小说中性别的转变》（*The Transformation of Gender in English-Language Fiction*）。David Bamman 教过我 NLP。他是我的导师，我很为此自豪。他们说了什么？

    他们说，用于描述男性和女性之间差异的语言在过去 200 年里变得模糊了。本质上意味着他们被平等对待了。但是……女性作者的数量实际上**下降了**。这不疯狂吗？下降。英语小说的女性作者比例减少了一半——从 1850 年的约 50% 下降到 1950 年的约 25%。我们可能会想：“哦，我们现在都平等了，没有性别歧视了。” 但女性小说作者的数量实际上却下降了。

    为什么会发生这种情况？他们称之为**绅士化**（Gentrification）。什么是绅士化？在住房方面，就是人们看到一个贫穷地区，付低房租搬进去，价格上涨，穷人离开。他们说小说界也发生了类似的事情。在 19 世纪，没人真正在乎小说。那是为了好玩。但当它变得有名望，当人们开始从中赚钱时，男人涌入了这个领域，基本上把其他人都挤出去了。现在它基本上是男性主导的。

    他们还谈到了像“**微笑**”（smile）和“**咧嘴笑**”（grin）这样的词。“她微笑了。” “他咧嘴笑了。” 这些与女性或男性相关联。那是什么？只是微笑或咧嘴笑而已。但这其中有性别关联。他们还提到了**蓝妹妹原则**（Smurfette Principle）。在男人写的小说里，通常只有一个女人。她是蛇蝎美人，是**艾琳·阿德勒例外**（Irene Adler exception）。她是必不可少的，但也仅此而已。

    这种绅士化效应在计算机科学中也很出名。你知道早年大多数计算机程序员都是女性吗？就像 NASA 那个拿着代码书的女人。《**隐藏人物**》（Hidden Figures）。或者是二战时期的程序员。但后来它变得更有声望了，男人就接管了。

  - [19:48 - 19:59] **Distant Reading, The "Great Unread," and EDA Project Strategies**

    This leads us to the concept of **Distant Reading**. **Margaret Cohen** calls it the "**Great Unread**." There are 30,000 to 60,000 19th-century British novels that nobody has actually read. To be honest, nobody works on them. **Close reading**—finding a specific passage in the text—can only do so much. You can read three novels, maybe all seven *Harry Potter* books, but you can't do 60,000. So **Franco Moretti** says: Let's do a **pact with the devil**. I like the way he frames it. Distant reading is where distance is a *condition* of knowledge. It allows you to focus on units much smaller or much larger than the text—devices, themes, tropes, genres, and systems. And if the text itself disappears, well, it is one of those cases where one can justify "**less is more**." We don't need to read the text anymore; let's just look at the patterns.

    **Ted Underwood** in "*A Genealogy of Distant Reading*" argues that this isn't actually a recent thing. He says the idea is to use statistical social science techniques to study text, almost like an experiment. He cites **Janice Radway** and her book *Reading the Romance* (1984). She didn't just criticize the books; she used questionnaires to study the *readers* of romance novels. She found that for these women, reading was a "Declaration of Independence" from their duties as wives and mothers. Underwood argues we need to set our fascination with technology to one side and rediscover the guiding principle of **experiment**. Don't just run an algorithm to see what happens. Ask clear research questions.

    For your **EDA (Exploratory Data Analysis)** project, you are basically doing distant reading. You are asking: What are the most common words? What are the **Fighting Words**? We will do Fighting Words next week—it’s focusing on how two different classes talk about a specific word (e.g., how two groups talk about "crime"). If that is confusing, you can use the **Scattertext** library. It’s great for visualizations. For example, comparing popular tweets versus non-popular tweets.

    You might encounter metrics like **KL Divergence** (Kullback-Leibler) or **JSD** (Jensen-Shannon Divergence). Luckily for this course, **you don't have to know what they are**. I don't care about the math. As long as you can implement the code—"Oh, it shows the KL divergence is this"—that’s enough. Isn't that better? Do you want to know everything about the math? No, of course not. It’s just a number that shows your distribution.

    What else? **Concordances**. You forgot what concordances are? It's the most important thing; people have used it for thousands of years! A concordance is: "I want to see the word 'doctor' right in my corpus." It allows you to see every time it is mentioned and the context around it. It is almost like a close reading technique within distant reading.

    Should you remove **stop words**? Maybe it's important for you, maybe it's not. You have to decide: "I'm removing stop words because I think it will make the analysis better." The world is your oyster. You can do what you want. Life is an infinite possibility. You can fly to Japan if you want. But basically, you will have a lot of text to talk about in your project. It will not be just code; you'll look at graphs, visualizations, and scatter plots. It’s not more complicated than what you saw in the Bamman paper.

    这引出了**远读**（Distant Reading）的概念。**玛格丽特·科恩**（Margaret Cohen）称之为“**伟大的未读之书**”（Great Unread）。有 3 万到 6 万本 19 世纪的英国小说实际上没人读过。老实说，没人研究它们。**细读**（Close reading）——在文本中寻找特定段落——能做的只有这么多。你可以读三本小说，也许读完所有七本《哈利·波特》，但你无法读完 60,000 本。所以**弗兰科·莫莱蒂**（Franco Moretti）说：让我们跟魔鬼做个**交易**（pact with the devil）。我喜欢他的这种表述方式。远读是一种以距离作为知识*条件*的方法。它允许你关注比文本小得多或大得多的单位——手法、主题、比喻、流派和系统。如果文本本身消失了，好吧，这正是那种可以证明“**少即是多**”的情况之一。我们不再需要阅读文本；我们要看的是模式。

    **泰德·安德伍德**（Ted Underwood）在《远读的谱系》（*A Genealogy of Distant Reading*）中认为这实际上并不是什么新鲜事。他说这个想法是使用统计社会科学技术来研究文本，就像做实验一样。他引用了**珍妮斯·拉德威**（Janice Radway）和她的书《阅读浪漫小说》（*Reading the Romance*, 1984）。她不只是批评这些书；她使用问卷调查来研究浪漫小说的*读者*。她发现对于这些女性来说，阅读是她们从妻子和母亲的职责中发表的“独立宣言”。安德伍德认为我们需要把对技术的迷恋放在一边，重新发现**实验**的指导原则。不要只是运行算法看会发生什么。要提出清晰的研究问题。

    对于你们的 **EDA（探索性数据分析）\**项目，你们基本上就是在做远读。你们在问：最常见的词是什么？什么是\**战斗词汇**（Fighting Words）？我们下周会讲战斗词汇——它关注的是两个不同的类别如何谈论一个特定的词（例如，两个群体如何谈论“犯罪”）。如果这让你困惑，你可以使用 **Scattertext** 库。它非常适合可视化。例如，比较热门推文与非热门推文。

    你可能会遇到像 **KL 散度**（KL Divergence）或 **JSD**（Jensen-Shannon Divergence）这样的指标。幸运的是，对于这门课，**你不需要知道它们是什么**。我不在乎数学。只要你能实现代码——“哦，它显示的 KL 散度是这个”——这就够了。这难道不是更好吗？你想知道关于数学的一切吗？不，当然不想。它只是一个显示分布的数字。

    还有什么？**语境共现**（Concordances）。你们忘了什么是语境共现了吗？这是最重要的东西；人们已经用了几千年了！语境共现就是：“我想在我的语料库中看到‘医生’这个词。” 它允许你看到它每次被提及的情况以及周围的语境。这几乎就像是远读中的一种细读技术。

    你应该移除**停用词**（stop words）吗？也许这对你很重要，也许不重要。你必须决定：“我移除停用词是因为我认为这会让分析更好。” 世界是你的牡蛎（随你所愿）。你想做什么都可以。生活充满无限可能。如果你想，你可以飞去日本。但基本上，你的项目中会有很多关于文本的讨论。它不仅仅是代码；你要看图表、可视化和散点图。这并不比你在 Bamman 的论文中看到的更复杂。

  - [20:12 - 20:18] **Literature is Not Data: The Ineffable and the Borges Paradox**

    So, we have all this stupid mathematization. I mean, I'm not saying it's stupid; it's important. But let's look at the counter-argument. Who read the article "*Literature is not Data*"? It was in the Los Angeles Review of Books by Stephen Marche. "Big data is coming for your books... it's already come for everything else." What does he say? He argues the opposite, right? Literature is the opposite of data. There is human interpretation in it. The corpus itself is never going to be complete.

    He uses the **Epic of Gilgamesh** as an example. The Epic of Gilgamesh is the oldest story recorded. And he says data *precedes* written literature. So before literature, there was data. The first Sumerian examples of written language are not poems; they are drinks of beer and barley orders. The Sumerians would have these **cuneiform** tablets—which we still find today—and the earliest ones are basically receipts: "This guy bought 20 tons of barley from me." That is data. But then he says, later on, we get the Epic of Gilgamesh, the story of the man who saw the deep. Here was contact with the **ineffable**. The very first work of supreme literature is on the subject of what *cannot* be processed as information, what transcends data. It deals with the unseen world, very deep ideas. This is basically saying that literature is something that is not really data because it is inherently incomplete. As you said, we can never record everything. You can record every baseball statistic, every train course of the year, but literature captures the gaps. He also talks about how literature as a corpus is always being "ruined" as data rots, while we keep finding new meanings.

    The other thing he mentions, which I like, is obviously **Jorge Luis Borges**. Remember Borges? We had a whole discussion on the incompleteness of science. Remember the short story "*On Exactitude in Science*"? They make a map of the empire that is so exact it is the size of the empire itself, but that's completely useless. That is Borges. I recommend reading Borges in your lives, just in general. But Marche cites another Borges story: "*Pierre Menard, Author of the Quixote*."

    Borges writes about a comparison between Pierre Menard’s *Don Quixote* and Cervantes’ original *Don Quixote*. Pierre Menard decides to write *Don Quixote*—not a revamp, not a transcription, but he wants to write the *exact same text* as Cervantes, word for word, but as a contemporary author in the 20th century. So, Borges compares the two. He looks at a passage from Cervantes (written in the 17th century): "*...truth, whose mother is history, rival of time, depository of deeds, witness of the past, exemplar and adviser to the present, and the future's counselor.*" Written by the "lay genius" Cervantes, this is a mere rhetorical praise of history. Just talking about history back in the day.

    But Menard, on the other hand, writes exactly the same words: "*...truth, whose mother is history, rival of time...*" But Borges argues the idea is astounding. Menard is a contemporary of William James. For him, history is not just a record; it is an inquiry into reality. "Historical truth, for him, is not what has happened; it is what we judge to have happened." The phrase "adviser to the present" becomes brazenly pragmatic. What is he saying? He's saying these are exactly the same words—the same *data*—but looking at it from different perspectives, from different historical contexts, the meaning changes completely. If you read it from a 17th-century perspective versus a 20th-century perspective, it’s a different sentence. This is why literature is not data. It's the opposite of data because the meaning is fluid. With the same data, we have completely different meanings. This relates back to **framing**—same factual situation, different outcomes.

    所以，我们搞了这么多愚蠢的数学化。我是说，我不是说它愚蠢，它很重要。但让我们看看反面论点。谁读了《文学不是数据》（*Literature is not Data*）这篇文章？这是 Stephen Marche 发表在《洛杉矶书评》上的文章。“大数据正在向你的书籍袭来……它已经占领了其他所有领域。” 他说了什么？他提出了相反的观点，对吧？文学是数据的对立面。其中包含了人类的诠释。语料库本身永远不可能是完整的。

    他以《**吉尔伽美什史诗**》（Epic of Gilgamesh）为例。《吉尔伽美什史诗》是有记载的最古老的故事。他说数据*先于*书面文学存在。所以在文学之前，就有了数据。苏美尔书面语言最早的例子不是诗歌；而是啤酒和在大麦的订单。苏美尔人有这些**楔形文字**（cuneiform）泥板——我们今天还能找到——最早的泥板基本上就是收据：“这家伙从我这里买了 20 吨大麦。” 那就是数据。但他接着说，后来我们有了《吉尔伽美什史诗》，关于一个看见深渊的人的故事。这里是与**不可言喻之物**（the ineffable）的接触。第一部至高无上的文学作品的主题，恰恰是那些*无法*被处理为信息、超越了数据的东西。它涉及看不见的世界，非常深刻的思想。这基本上是说，文学并不是真正的数据，因为它本质上是不完整的。正如你所说，我们永远无法记录一切。你可以记录每一个棒球统计数据，每年的火车时刻表，但文学捕捉的是那些空白。他还谈到了文学作为一种语料库是如何随着数据的腐烂而总是被“毁坏”的，而我们却不断发现新的意义。

    他提到的另一件事，我很喜欢，显然是**博尔赫斯**（Jorge Luis Borges）。还记得博尔赫斯吗？我们之前讨论过科学的不完备性。还记得那篇短篇小说《论科学的精确性》吗？他们绘制了一张帝国的地图，它是如此精确，以至于大小和帝国本身一样大，但这完全没用。这就是博尔赫斯。我建议你们在生活中读读博尔赫斯，不仅仅是为了课程。但 Marche 引用了博尔赫斯的另一个故事：《吉诃德的作者皮埃尔·梅纳尔》（*Pierre Menard, Author of the Quixote*）。

    博尔赫斯比较了皮埃尔·梅纳尔写的《堂吉诃德》和塞万提斯的原版《堂吉诃德》。皮埃尔·梅纳尔决定写《堂吉诃德》——不是重写，也不是抄写，他是想逐字逐句地写出与塞万提斯*完全相同*的文本，但作为一个 20 世纪的当代作家来写。所以，博尔赫斯比较了这两者。他看了塞万提斯（17 世纪）的一段话：“……真理，历史是它的母亲，时间的对手，行动的储藏室，过去的见证，现在的榜样和顾问，未来的教以此员。” 由“外行天才”塞万提斯写下，这仅仅是对历史的修辞性赞美。只是在谈论当年的历史。

    但是，梅纳尔写下了完全相同的词：“……真理，历史是它的母亲，时间的对手……” 但博尔赫斯认为这个想法是惊人的。梅纳尔是威廉·詹姆斯的同代人。对他来说，历史不仅仅是记录；它是对现实的探究。“对他来说，历史真理不是已经发生的事情；而是我们要*判断*它已经发生的事情。” “现在的顾问”这个短语变得公然的实用主义。他在说什么？他是说，这些是完全相同的词——相同的*数据*——但从不同的角度、不同的历史背景来看，意义完全改变了。如果你从 17 世纪的视角与 20 世纪的视角来读，它是不同的句子。这就是为什么文学不是数据。它是数据的对立面，因为意义是流动的。对于同样的数据，我们有完全不同的意义。这又回到了**框架**（framing）——同样的事实情境，不同的结果。

  - [20:18 - 20:22] **The Paradox of AI Education and The Digital Divide**

    So this is a problem. What do you think about this argument that literature is not data? Like, now we're in the age of AI. When you say "I'm gonna shut you down," it will threaten to kill me. We're in that age. A student asked: "It is not relevant to the data. The data is some specific words that use meanings so that we can directly use for a specific purpose, but there are many more things which are not relevant and would be ignored." Yes, exactly. If we just scan and OCR everything, there's a lot ignored.

    Another student asked: "I did Lit in high school, and I find that there's a lot of history in literature. If you can't quantify it, then how does the future generation write in the advent of AI becoming mainstream? NUS is talking about AI education in the latest alumnus magazine. How do you square the circle? All this history is gonna be forgotten, like Shakespeare. I did not do it in quantify."

    You can't quantify it. In fact, although there's a huge debate right now, all the literature departments are being shut down because they're saying, "Oh, it's not relevant to our future." I think it's very relevant. In fact, some of you have children, right? You know what they do in the US? Those crazy Americans. There's a **New York Times** article, "*The Digital Gap Between Rich and Poor Kids Is Not What We Expected*." I sent it to some guy. It basically says that all the rich tech billionaires, the people who build these AI companies, they don't send their children to math-intensive schools with iPads. They send them to literature schools, to Waldorf schools where screens are banned. They teach them Plato and all that stuff.

    Why would they do that? These are not just random rich people. These are the people involved in data processing and math, and they see the value in removing their kids from this stuff. It's a very interesting paradox. The parents in Overland Park were fed up; they wanted their kids off the screen. Meanwhile, the literature departments are being removed because "nobody wants to study old literature." Who wants to be Shakespeare these days? Even I don't want to be; it's too complicated. But we are moving towards an age—this is speculative—where all of these things will be forgotten. We'll have AI summaries of everything. It's almost like this is a demonic technology. I said it. It's almost like it's terrible.

    所以这是个问题。你们怎么看“文学不是数据”这个论点？比如，现在我们在 AI 时代。当你对 AI 说“我要关掉你”，它会威胁要杀了我。我们就处在这样一个时代。有学生问：“这与数据无关。数据是一些特定的词汇，使用特定的含义，以便我们可以直接用于特定目的，但还有更多不相关的东西会被忽略。” 是的，没错。如果我们只是扫描和 OCR 所有东西，会有很多东西被忽略。

    另一个学生问：“我在高中学过文学，我发现文学中有很多历史。如果你不能量化它，那么在 AI 成为主流的未来，下一代该如何写作？新加坡国立大学（NUS）在最新的校友杂志上都在谈论 AI 教育。你如何自圆其说？所有这些历史都会被遗忘，比如莎士比亚。我没法量化它。”

    你无法量化它。事实上，虽然现在有很大的争议，所有的文学系都在被关闭，因为他们说：“哦，这对我们的未来没有意义。” 我认为它非常有意义。事实上，你们有些人有孩子，对吧？你们知道美国人在做什么吗？那些疯狂的美国人。有一篇《**纽约时报**》的文章，《贫富儿童之间的数字鸿沟并非我们所预料的那样》（*The Digital Gap Between Rich and Poor Kids Is Not What We Expected*）。我发给过别人。文章基本上说，所有那些富有的科技亿万富翁，那些建立 AI 公司的人，他们不把孩子送到用 iPad 的数学强化学校。他们把孩子送到文学学校，送到华德福学校（Waldorf schools），那里禁止使用屏幕。他们教孩子柏拉图之类的东西。

    他们为什么要那样做？这些人不是随便的有钱人。这些人是从事数据处理和数学工作的，他们看到了让孩子远离这些东西的价值。这是一个非常有趣的悖论。Overland Park 的父母受够了；他们想让孩子远离屏幕。与此同时，文学系正在被取消，因为“没人想研究旧文学”。这年头谁想成为莎士比亚？连我都不想；太复杂了。但我们正在走向一个时代——这只是推测——所有这些东西都将被遗忘。我们将拥有所有东西的 AI 摘要。这简直就像是一种恶魔般的技术。我说了。这简直太糟糕了。

  - [20:22 - 20:26] **Plato on Writing & Propp’s Narrative Theory**

    Speaking of children and screens... I sit on the bus and see 3-year-olds with phones, and I'm like, "What is going on?" But this connects to **Plato**. Did you know Plato was against writing? We always associate data and knowledge with writing, but in the *Phaedrus*, he was literally saying we shouldn't use writing. He said: "*If men learn this, it will implant forgetfulness in their souls. They will cease to exercise memory because they rely on that which is written, calling things to remembrance no longer from within themselves, but by means of external marks.*"

    He says: "*What you have discovered is a recipe not for memory, but for reminder. And it is no true wisdom that you offer your disciples, but only the semblance of wisdom.*" He argues that by telling them many things without teaching them, they will seem to know much, but for the most part, they will know nothing. They will be filled with the "conceit of wisdom" and be a burden to their fellows. It's almost like he's speaking about today and AI. I don't know, I don't really give messages, but it feels relevant.

    All of this knowledge is completely useless when it comes to the actual deep philosophy. There is a theory called **Narratology**. Most human writing is actually very recent. For most of the human species, we didn't have writing. So how did you transmit information? You had stories, myths. The patterns were memorable enough so you could tell them generation after generation. People back in the day actually had much better memories as a result.

    One of the famous guys in this field—I have ADHD, I have to tell this—is **Vladimir Propp**. Not "Vitamin Prop." He studied not the text of the individual folk stories, but their **structure**. He said it's all about the structure. He analyzed Russian folklore and said you can summarize all folk stories in certain themes or functions. For example: "The villain makes an attempt at reconnaissance," or "The hero acquires the use of a magical agent." Categories like trickery, complicity, villainy, mediation, struggle.

    It's actually very easy to remember these patterns as opposed to the actual text. This makes sense because we watch movies, right? They all follow a structure. It always has to be a happy ending. The hero has to face trouble. If there was a story where nothing happened—"I woke up, had breakfast, came here"—that's boring. Nobody cares. I have to say, "I lost all my money and some terrible thing happened." That is what Propp is talking about. We remember the structure, not the data points.

    说到孩子和屏幕……我坐在公交车上看到 3 岁的孩子拿着手机，我就想：“这到底是怎么回事？” 但这这就联系到了**柏拉图**。你们知道柏拉图反对书写吗？我们总是把数据和知识与书写联系在一起，但在《斐德罗篇》（*Phaedrus*）中，他字面上就是在说我们不应该使用书写。他说：“*如果人们学会了这个，这将在他们的灵魂中植入遗忘。他们将停止锻炼记忆力，因为他们依赖写下来的东西，不再从内心深处唤起记忆，而是借助外在的符号。*”

    他说：“*你发现的不是记忆的药方，而是提醒的药方。你提供给你的弟子的不是真正的智慧，而只是智慧的表象。*” 他认为，通过告诉他们很多事情而不真正教导他们，他们看起来好像知道很多，但大部分情况下，他们什么都不知道。他们将充满“智慧的自负”，并成为同伴的负担。这简直就像他在谈论今天和 AI。我不知道，我不怎么传达这类信息，但这感觉很相关。

    当涉及到真正的深层哲学时，所有这些知识都是无用的。有一种理论叫**叙事学**（Narratology）。人类的大部分书写实际上是非常近代的。对于人类物种的大部分时间来说，我们没有书写。那你如何传递信息？你有故事，神话。这些模式足够令人难忘，所以你可以一代又一代地讲述它们。结果是，以前的人实际上拥有更好的记忆力。

    这个领域的一个著名人物——我有 ADHD，我必须讲这个——是**弗拉基米尔·普罗普**（Vladimir Propp）。不是“维他命 Prop”。他研究的不是个别民间故事的文本，而是它们的**结构**。他说一切都在于结构。他分析了俄罗斯民间传说，说你可以用某些主题或功能来总结所有民间故事。例如：“恶棍试图进行侦察”，或者“英雄获得魔法代理人的帮助”。像欺骗、同谋、罪恶、调解、斗争这样的类别。

    与实际文本相比，记住这些模式实际上非常容易。这很有道理，因为我们看电影，对吧？它们都遵循一种结构。总得有个大团圆结局。英雄必须面对麻烦。如果有一个故事什么都没发生——“我醒来，吃早餐，来这里”——那很无聊。没人会在乎。我得说：“我丢了所有的钱，发生了可怕的事情。” 这就是普罗普所说的。我们记住的是结构，而不是数据点。

  - [20:26 - 20:37] **Schopenhauer, The World as Representation, and Vectors**

    Any other questions? Let's move to the final reading: **Schopenhauer**, "*On Representations*." Why is this relevant to the readings today? 1800s, some old white dude. The book starts with the quote: "*Wake up my friend, and leave childish things behind.*" (That’s actually Rousseau quoted by Schopenhauer).

    Who read this? A student says, "I read it." What does it say? It says: "*The world is my representation.*" This holds true for every living, cognitive being. It becomes clear and certain to him that he is not acquainted with either the sun or the earth, but rather only with an **eye that sees a sun**, with a **hand that feels an earth**. The surrounding world exists only as representation, exclusively in relation to the representing being.

    So, there is the **Subject** (me) seeing the **Object** (the world out there). But it's not the **Thing-in-Itself** (*Ding an sich*). It's not the actual thing. I'll never know the true reality of this phone. As I was saying, the example is when I'm sleeping, you could be walking around the house. I'll never know the truth. You're laughing, but that's the idea. You only have the data. You are not actually aware of the actual thing. I'll never know the truth of being *you*.

    Basically, it's a data question. What I have is a representation of you in my head. I interpret the data of you, but I don't know the true reality. Why is this relevant to the course? Because AI is processing our real world into data—images, sounds, videos—it's all **learning representations**. In fact, humans cannot learn the thing itself. How do we know the AI will be able to?

    Schopenhauer, following **Kant**, says there are things that are **A Priori**. *A posteriori* means after experience (I get data, I drop a cup, it falls). *A priori* is knowledge you don't need experience to learn. Like breathing? No, that's instinct. Mathematics? Yes. Kant says **Time, Space, and Causality** are a priori. You can imagine empty space, but you cannot imagine "spacelessness." It's a condition of your thinking. It exists in your brain before experience. Every piece of information—my eye looking at the sun—is mediated by time, space, and causality. The photograph is a representation; it’s one angle of you, not *you*.

    Schopenhauer quotes the "age-old wisdom of India": "*It is **Maya**, the veil of deception that covers the eyes of mortals... like sunlight reflected off sand that a distant traveler mistakes for water, or like a discarded rope that the traveler thinks is a snake.*" The world exists, but our perception is illusory.

    Why is this important? Because: **How are we representing text?** That's the question. In AI, in Machine Learning, in our Jupyter notebooks—how do we represent text? A student says: "**Vector data**." Yes, vectors. But what is a vector? A bunch of numbers. We represent text with a bunch of numbers. The way we choose to represent text is completely detached from the reality of the object. That’s what Schopenhauer is trying to say—there is a fundamental limitation.

    This leads to **Power Laws**. **Nassim Taleb** had a tweet: "*Language is where power laws were really discovered.*" Power laws are a form of **Zipfian distributions**. A small amount of words happen really frequently (function words), and a large amount of words don't happen frequently. 80% of wealth is controlled by 20% of people—that's a power law. Taleb also tweeted: "*The reason LLM models feel human is that most humans rephrase combinations of things they heard or saw with nothing new.*" He's talking about me! He says if your conversation can be reconstructed with clips from other conversations, you exist in "Full". He’s saying we are basically just copy-pasting what we heard. I'm not actually thinking for myself; I just learned something.

    So, let's download the lab.

    还有其他问题吗？让我们进入最后的阅读材料：**叔本华**，《论表象》（*On Representations*）。为什么这与今天的阅读材料相关？19 世纪，一个白人老头。这本书以这句话开头：“*醒醒吧，我的朋友，把孩子气的东西留在身后。*”（这实际上是叔本华引用的卢梭的话）。

    谁读了这个？一个学生说：“我读了。” 它说了什么？它说：“*世界是我的表象。*” 这对每一个活着的、有认知的存在都适用。这一点对他来说变得清晰和确定：他不认识太阳或地球，而只认识**看见太阳的眼睛**，只认识**感觉地球的手**。周围的世界仅作为表象存在，仅仅是相对于那个正在表象的存在者（即他自己）而存在。

    所以，有**主体**（我）在看**客体**（外面的世界）。但这并不是**物自体**（Thing-in-Itself / *Ding an sich*）。它不是事物本身。我永远无法知道这部手机的真实样貌。就像我说的，当我睡觉时，你可能在房子里走来走去。我永远不会知道真相。你在笑，但这正是那个观点。你只有数据。你实际上并未意识到事物本身。我永远无法知道成为*你*的真相。

    基本上，这是一个数据问题。我拥有的是我脑海中对你的表象。我解释关于你的数据，但我不知道真实的现实。为什么这与课程相关？因为 AI 正在将我们的真实世界处理成数据——图像、声音、视频——这全都是**学习表象**（learning representations）。事实上，人类都无法学习事物本身。我们怎么知道 AI 能做到？

    叔本华追随**康德**，说有些东西是**先验的**（A Priori）。*后验*（A posteriori）意味着经验之后（我获得数据，我扔一个杯子，它掉下来）。*先验*是你不需要经验就能学到的知识。像呼吸？不，那是本能。数学？是的。康德说**时间、空间和因果律**是先验的。你可以想象空的空间，但你无法想象“无空间”。这是你思维的一个条件。它在经验之前就存在于你的大脑中。每一条信息——我的眼睛看太阳——都是由时间、空间和因果律为中介的。照片是一种表象；它是你的一个角度，而不是*你*。

    叔本华引用了“印度古老的智慧”：“*这是**玛雅**（Maya），是蒙蔽凡人眼睛的欺骗之纱……就像远处旅行者误以为是水的沙上反光，或者旅行者误以为是蛇的被遗弃的绳子。*” 世界是存在的，但我们的感知是虚幻的。

    为什么这很重要？因为：**我们如何表征文本？** 这就是问题所在。在 AI 中，在机器学习中，在我们的 Jupyter notebook 里——我们要如何表征文本？一个学生说：“**向量数据**。” 是的，向量。但什么是向量？一堆数字。我们用一堆数字来表征文本。我们选择表征文本的方式与对象的现实完全脱节。这就是叔本华试图表达的——存在一个根本的局限性。

    这引出了**幂律**（Power Laws）。**纳西姆·塔勒布**发了一条推文：“*语言是真正发现幂律的地方。*” 幂律是**齐普夫分布**的一种形式。少量的词出现得非常频繁（功能词），而大量的词不常出现。80% 的财富由 20% 的人控制——这就是幂律。塔勒布还发推说：“*大语言模型让人感觉像人类的原因是，大多数人类只是在改写他们听到或看到的组合，并没有新意。*” 他是在说我！他说，如果你的对话可以用其他对话的片段重构出来，你就以“Full”模式存在。他是说我们基本上只是在复制粘贴我们听到的东西。我实际上并没有自己在思考；我只是学到了一些东西。

    好了，让我们下载实验材料。

  - [20:38 - 20:52] **Web Scraping the Old Bailey API**

    And obviously, you can use Google Colab and so on. For you guys, you can download the whole database. It's not that big. But this is to show you how we can do web scraping with APIs. Just to explain what it is—you don't have to do this because you already made the project, but I want to show you that it's not magic.

    We'll use `xml` and the library for scraping called `requests`. The reason you have to know this is because let's say you graduated, you're working in some industry, and your boss says, "Give me a code on how to scrape this." You at least know the name of the library, right? You can give sufficient context for the AI to write your code. And `BeautifulSoup` is a way to disentangle or parse information out of these very ugly HTML/XML tags.

    The data is the **Old Bailey Corpus**, the one we talked about today. It has trials from 1674 to 1913. We'll be looking at a slice from 1754 to 1756. In the code cell, we define the URL. We set the start year to 1754, the end year to 1756. These are the parameters expected by the API. And we set **headers**. These things will help you not be flagged as a bot. It basically tells the server, "Hey, I'm on a Windows computer," so they don't block you.

    The code says `requests.get(url, params=..., headers=...)`. Basically, all of coding is just converting some data into a format that is acceptable by another program. That's it. `raise_for_status()` will give you errors if it doesn't work. We get a JSON response. The total hits are 1,312 trials between these two years. Each trial has an ID key.

    You can actually see the microfilm images. It looks very fancy, old text. Notice the "s" is different. If you study old English text, they have the **Long S** (ſ). "Commission" looks like "Commiƒƒion." That's why modern NLP tools might struggle—they see "Wednesday" written differently. But anyway, you see the text: "Hannah Ash, Spinster, was indicted for stealing one linen shift, one cotton gown... to which she pleaded guilty. **Transportation**." She was thrown away out of the country. Transportation means you go to Australia or the US—prison colonies. At that time, traveling so far meant you were basically dead. There was scurvy, diseases.

    The API gives us batches of 10. So we have to loop. `while i < total_hits`: we request a batch, extend our list, and then—this is crucial—`time.sleep(0.1)`. If you don't have a sleep timer, you'll be shut down from the server because you're hitting them too fast. It needs to look like you're taking time. We get all the `id` keys, and then we query specifically for the full XML text of each trial.

    显然，你们可以使用 Google Colab 之类的工具。对于你们来说，你们其实可以下载整个数据库。它并没有那么大。但这主要是为了向你们展示我们要如何使用 API 进行网络爬虫（Web Scraping）。只是为了解释它是什么——你们不需要真的做这个，因为你们已经完成了项目，但我通过这个向你们展示这并不是魔法。

    我们将使用 `xml` 和一个叫 `requests` 的爬虫库。你们需要知道这个的原因是，假设你毕业了，你在某个行业工作，你的老板说：“给我写个代码爬取这个。” 你至少知道这个库的名字，对吧？你可以给 AI 提供足够的语境来让它写代码。而 `BeautifulSoup` 是一种从那些非常丑陋的 HTML/XML 标签中理清或解析信息的方法。

    数据是**老贝利语料库**（Old Bailey Corpus），就是我们今天讨论的那个。它包含了 1674 年到 1913 年的审判记录。我们将查看 1754 年到 1756 年的片段。在代码单元中，我们定义了 URL。我们将开始年份设为 1754，结束年份设为 1756。这些是 API 期望的参数。我们还设置了**请求头**（headers）。这些东西可以帮助你不被标记为机器人。它基本上是在告诉服务器：“嘿，我用的是 Windows 电脑”，这样他们就不会屏蔽你。

    代码写着 `requests.get(url, params=..., headers=...)`。基本上，所有的编程实际上只是将某些数据转换为另一个程序可以接受的格式。仅此而已。`raise_for_status()` 会在出错时报错。我们得到了一个 JSON 响应。这两年间总共有 1,312 次审判命中。每个审判都有一个 ID 键。

    你实际上可以看到微缩胶片图像。它看起来很花哨，是古英语文本。注意那个“s”是不同的。如果你研究古英语文本，他们有一种**长 S**（Long S，符号为 ſ）。“Commission”（委员会）看起来像“Commiƒƒion”。这就是为什么现代 NLP 工具可能会遇到困难——它们看到的“Wednesday”写法不同。不管怎样，你看到文本写着：“Hannah Ash，老处女（Spinster），因偷窃一件亚麻衬裙、一件棉质长袍……被起诉，她认罪了。**流放**（Transportation）。” 她被扔出了这个国家。流放意味着你去澳大利亚或美国——监狱殖民地。在那个时候，长途旅行基本上意味着死路一条。有坏血病，各种疾病。

    API 每次给我们 10 个结果。所以我们必须循环。`while i < total_hits`：我们要请求一批数据，扩展我们的列表，然后——这很关键——`time.sleep(0.1)`（睡眠 0.1 秒）。如果你没有睡眠计时器，你会因为请求太快而被服务器关闭连接。它需要看起来像是你花了一些时间。我们获取所有的 `id` 键，然后我们专门查询每个审判的完整 XML 文本。

  - [20:52 - 21:04] **Parsing XML & The "Bloody Code" Reality**

    This is what the content looks like. It's XML, which is why we call it **BeautifulSoup**—because this looks like a soup. But there's data in there. `<personName>`, `<occupation>Spinster</occupation>`. Spinster means unmarried woman. `<offenseDescription>Theft</offenseDescription>`, `<subCategory>pickpocketing</subCategory>`. Somebody actually had to sit down and write this tag: "Okay, I read this little thing, it's about pickpocketing." This is called **Interpretation** tags. It’s a very rich dataset.

    We parse it with BeautifulSoup. We traverse the tree—parent tags, child tags. For example, in the trial of Samuel Davis (1703): "Indicted for stealing 18 diamonds... value 250 pounds." The victim was a lady, Catherine Herbert. He was a coachman. He pleaded not guilty. The punishment? **Branding**. Like horses. They brand this guy. Disgusting, right? Crazy. This was 1703.

    You can extract the text. "The jewels were put up in the closet which was locked... found prisoner... in his trunk found all the diamonds but one, which was found upon him in the roll of his stocking." When searched before the Justice, he denied the fact, saying he found them upon a great heap of rubbish. But that being a weak excuse—hypocrisy, right?—the jury found him guilty.

    We put this all in a **DataFrame**. We define functions to extract the date, the person name, the offense category. We get a list of dictionaries and convert it to CSV. Now, look at the occupations in our small sample: Spinster, Wife, Spinster. It looks like all the criminals were women back in the day! Not only were they writing all the fiction, but they were also committing all the crimes! How would we interpret that?

    It's a small sample (50 trials). Also, if you're a bandit robbing people, you don't have an "occupation." You're unemployed. But they didn't have the word "unemployed" back in the day. So without understanding the data, you interpret this incorrectly.

    We see a lot of "Transportation" in the data. Remember the **Bloody Code**? For the tiniest offenses, like stealing a handkerchief, they give you the death penalty. But here we see mostly transportation. Why? There's a guy called **Douglas Hay**, who wrote "*Property, Authority and the Criminal Law*." He says the Bloody Code wasn't so bloody. Actually, judges often said, "Okay, we'll transport you." Why? Because it allowed the ruling elites—the justices—to make the people feel the system was legitimate. It’s **Mercy as a Control Mechanism**. "I'll give you mercy, I won't kill you," so the people say, "Oh, the system is fair." They would only kill occasionally to make an example. The legitimacy of the system was more important than killing every infraction.

    这就是内容的样子。它是 XML，这就是为什么我们叫它 **BeautifulSoup**（美丽的汤）——因为这看起来像一锅汤。但这里面有数据。`<personName>`（人名），`<occupation>Spinster</occupation>`（职业：老处女）。Spinster 意味着未婚女性。`<offenseDescription>Theft</offenseDescription>`（犯罪描述：盗窃），`<subCategory>pickpocketing</subCategory>`（子类别：扒窃）。实际上必须有人坐下来写下这个标签：“好吧，我读了这个小片段，这是关于扒窃的。” 这被称为**解释**（Interpretation）标签。这是一个非常丰富的数据集。

    我们用 BeautifulSoup 解析它。我们遍历这个树——父标签，子标签。例如，在塞缪尔·戴维斯（Samuel Davis, 1703）的审判中：“因偷窃 18 颗钻石被起诉……价值 250 英镑。” 受害者是一位女士，凯瑟琳·赫伯特。他是个马车夫。他不认罪。惩罚是什么？**烙印**（Branding）。就像烙马一样。他们给这家伙打上烙印。很恶心，对吧？疯狂。那是 1703 年。

    你可以提取文本。“珠宝被放在锁着的壁橱里……发现囚犯……在他的箱子里发现了所有的钻石，除了一颗，那颗是在他的长袜卷里发现的。” 当在法官面前被搜查时，他否认了这一事实，说他是在一大堆垃圾上捡到的。但这借口太烂了——虚伪，对吧？——陪审团裁定他有罪。

    我们将所有这些放入一个 **DataFrame**（数据框）。我们定义函数来提取日期、人名、犯罪类别。我们得到一个字典列表并将其转换为 CSV。现在，看看我们小样本中的职业：老处女、妻子、老处女。看起来以前所有的罪犯都是女性！她们不仅写了所有的小说，还犯下了所有的罪行！我们要如何解释这一点？

    这是一个小样本（50 次审判）。而且，如果你是一个抢劫别人的强盗，你没有“职业”。你是失业者。但那时候没有“失业”这个词。所以如果不理解数据，你就会错误地解释这一点。

    我们在数据中看到很多“流放”。还记得**血腥法典**（Bloody Code）吗？对于最小的罪行，比如偷手帕，他们都会判你死刑。但在这里我们看到的主要是流放。为什么？有个叫**道格拉斯·海**（Douglas Hay）的人，写了《*财产、权威与刑法*》（*Property, Authority and the Criminal Law*）。他说血腥法典其实没那么血腥。实际上，法官经常说：“好吧，我们把你流放。” 为什么？因为这允许统治精英——法官们——让人民觉得这个制度是合法的。这是**作为控制机制的仁慈**。“我给你仁慈，我不杀你”，所以人们会说：“哦，这个制度是公平的。” 他们只是偶尔杀人来杀鸡儆猴。制度的合法性比对每一次违规都进行杀戮更重要。

  - [21:05 - 21:15] **Engineering Text: NLP Tasks with spaCy**

    Let's look at **NLP Tasks**. As I told you, computer scientists look at text as a bunch of engineering tasks. It's not literature; it's: "What task do I have to accomplish?"

    Is it Dependency Parsing? Is it **Coreference Resolution**? This is my favorite one. I should wake you up in the middle of the night and ask you, "What is coreference resolution?" and you should be able to answer. It's the Obama example: "I voted for Obama because **he** was aligned with my values." Obama and "he" are linked. For humans, it's easy. For text, it's a difficult problem.

    Then there is **Part of Speech (POS) Tagging**. Is this a noun? Is this a verb? Or **Named Entity Recognition (NER)**. If you want to extract organization names vs person names. We use the **spaCy** library (`nlp = spacy.load("en_core_web_sm")`). We take the text: "Samuel Portman was indicted for the willful murder of Elizabeth..." and we get the entities. It identifies "Sarah Williams" as a PERSON. "Round Court" as an ORGANIZATION. "Three months" as a DATE.

    But look at "Transportation." It tagged "Transportation" as an ORGANIZATION. This is incorrect. Why? Because the spaCy model is trained on **today's language**. Today, "transportation" means a logistics firm. Back then, it meant punishment. Because we use a modern model on historical text, it's going to have these mistakes. Working with real-world text is messy.

    We also look at **Dependency Parsing**. "Portman" is related to "indicted" via `nsubjpass` (nominal subject passive). You can reconstruct the sentence structure: Who did what to whom? This is why LLMs are effective—they understand these dependencies.

    让我们看看 **NLP 任务**。正如我告诉你们的，计算机科学家把文本看作一堆工程任务。这不是文学；而是：“我要完成什么任务？”

    是依存句法分析吗？是**指代消解**（Coreference Resolution）吗？这是我最喜欢的一个。我应该在半夜把你们叫醒，问你们：“什么是指代消解？” 你们应该能回答出来。就是奥巴马的例子：“我投票给奥巴马，因为**他**与我的价值观一致。” 奥巴马和“他”是链接的。对人类来说，这很容易。对文本来说，这是一个难题。

    然后是**词性标注**（POS Tagging）。这是名词吗？这是动词吗？或者是**命名实体识别**（NER）。如果你想提取组织名称与人名。我们使用 **spaCy** 库（`nlp = spacy.load("en_core_web_sm")`）。我们获取文本：“Samuel Portman 因故意谋杀 Elizabeth 被起诉……” 我们提取实体。它识别出“Sarah Williams”是 PERSON（人）。“Round Court”是 ORGANIZATION（组织）。“Three months”是 DATE（日期）。

    但看看“Transportation”（流放/运输）。它把“Transportation”标记为了 ORGANIZATION（组织）。这是不正确的。为什么？因为 spaCy 模型是基于**今天的语言**训练的。今天，“transportation”意味着物流公司。在那时，它意味着惩罚。因为我们在历史文本上使用现代模型，它就会犯这些错误。处理现实世界的文本是很混乱的。

    我们还看**依存句法分析**（Dependency Parsing）。“Portman”通过 `nsubjpass`（被动名义主语）与“indicted”（被起诉）相关联。你可以重构句子结构：谁对谁做了什么？这就是大语言模型有效的原因——它们理解这些依存关系。

  - [21:15 - 21:36] **Featurization: Bag of Words and Vector Space**

  Now, **Featurization**. Representing text. What is a feature? A feature of me is "moves hands a lot." Eye color is a feature. Features are columns. Dimensions.

  We said there is a limitation in representing text. What we can really do is count words. The computer cannot read the text "The King's Council..." It's meaningless to it. So we use `CountVectorizer` from `sklearn`. We initialize it with an **N-gram range**. What's an N-gram? Unigram is one word. Bigram is two words. Trigram is three words.

  We `fit_transform` the text. This creates a **Document-Term Matrix (DTM)**. Rows are documents, columns are words. If we use bigrams (2 words), the dimensions explode. We go from 2,000 features (unigrams) to 15,000 features (bigrams). And 99% of them are zeros. This is called a **Sparse Matrix**.

  This model is called a **Bag of Words (BoW)**. Why? because we just throw words in a bag. We ignore the position. "The person is guilty" vs "Is the person guilty?"—if you just count words, they might look similar depending on how you structure it, but you lose the context. It seems stupid and archaic, but this is the fundamental representation.

  Let's visualize this. Vectors are just lines in space. If we have two words, "pocket" and "spinster," we can plot them. Document A has 52 "pockets" and 2 "spinsters." It's a point at (52, 2). Document B has 10 "pockets" and 4 "spinsters." It's a point at (10, 4). Each document is represented by a vector. We can measure the angle between them to see how similar they are.

  If we have 3 words, we can do a 3D plot. But in our data, we have 38,000 words. We can't draw that. That's why we call them **dimensions**. It's a 38,000-dimensional space.

  These vectors don't "understand" us. They are just coordinates. As **Jurafsky and Martin** say in their book: "It manages to be musical and romantic." The computer simply knows that the word "love" occurs 5 times. It's a representation. But even though it's simplistic, it's crazy useful. It's like a fingerprint for the document.

  So, counting words is very important. And we have class next week, by the way.

  现在，**特征化**（Featurization）。表征文本。什么是特征？我的一个特征是“经常挥手”。眼睛颜色是一个特征。特征就是列。维度。

  我们说过表征文本是有局限性的。我们真正能做的是数单词。计算机无法阅读“国王的委员会……”这段文字。这对它来说毫无意义。所以我们使用 `sklearn` 中的 `CountVectorizer`（计数向量化器）。我们用 **N-gram 范围**来初始化它。什么是 N-gram？Unigram 是一元语法（一个词）。Bigram 是二元语法（两个词）。Trigram 是三元语法。

  我们对文本进行 `fit_transform`（拟合转换）。这创建了一个**文档-词矩阵**（Document-Term Matrix, DTM）。行是文档，列是单词。如果我们使用 Bigrams（两个词），维度会爆炸。我们从 2,000 个特征（一元）变成了 15,000 个特征（二元）。而且其中 99% 都是零。这被称为**稀疏矩阵**（Sparse Matrix）。

  这个模型被称为**词袋模型**（Bag of Words, BoW）。为什么？因为我们只是把词扔进一个袋子里。我们忽略了位置。“这个人有罪”与“这个人有罪吗？”——如果你只是数单词，它们看起来可能很相似，但这取决于你如何构建，且你丢失了语境。这看起来很愚蠢和古老，但这是最基本的表征。

  让我们将其可视化。向量只是空间中的线。如果我们有两个词，“pocket”（口袋）和“spinster”（老处女），我们可以画出它们。文档 A 有 52 个“pocket”和 2 个“spinster”。它是 (52, 2) 处的一个点。文档 B 有 10 个“pocket”和 4 个“spinster”。它是 (10, 4) 处的一个点。每个文档都由一个向量表示。我们可以测量它们之间的角度来看看它们有多相似。

  如果我们有 3 个词，我们可以做一个 3D 图。但在我们的数据中，我们有 38,000 个词。我们画不出来。这就是为什么我们称它们为**维度**。这是一个 38,000 维的空间。

  这些向量并不“理解”我们。它们只是坐标。正如 **Jurafsky 和 Martin** 在他们的书中所说：“它设法变得既悦耳又浪漫。” 计算机只知道“爱”这个词出现了 5 次。这是一种表征。但即使它很简单，它也非常有用。它就像文档的指纹。

  所以，数单词非常重要。顺便说一句，我们下周有课。
***

# Group project
## Links
  - [huggingface PILOT-ECHR2023](https://huggingface.co/datasets/zifeng-ai/PILOT-ECHR2023)
## LEGALST 123
  | Group | Project Topic / Research Question | Methodology | Key Findings |
  | :--- | :--- | :--- | :--- |
  | **01** | **Predicting Gun Control Stance**<br>Can a model predict an individual's stance on gun control laws based on social survey data? | **Data:** General Social Survey (2000-2018).<br>**Models:** Logistic Regression and Random Forest Classifier.,, | Both models achieved similar accuracy, but Logistic Regression offered a better precision-recall tradeoff. Key predictors included gun/rifle ownership, hunting habits, and party identification., |
  | **02** | **Court Cases Across Regions**<br>Comparing court case discussions (criminal vs. non-criminal) between Massachusetts (North) and Alabama (South). | **Data:** Caselaw Access Project.<br>**Models:** Logistic Regression using features: keywords, text polarity, and Moral Foundations Theory. | Models based on keywords generalized well across regions (high accuracy). However, models based on sentiment and Moral Foundations performed poorly in Alabama compared to Massachusetts, suggesting significant differences in how cases are discussed or the nature of the cases themselves.,, |
  | **03** | *Missing from sources* | *N/A* | *N/A* |
  | **04** | **Predicting Voting Patterns**<br>What are the best predictors (e.g., education, unemployment) of a US county's voting habits in the 2016 election? | **Data:** Opendatasoft and USDA.<br>**Models:** OLS, Ridge Regression, and LASSO with Recursive Feature Elimination (RFE)., | LASSO performed best. While race and education were expected predictors, job distribution (specific industries) and population health metrics (obesity, smoking) were found to be highly significant., |
  | **05** | **Airbnb Regulations in SF**<br>Did the 2017 reduction in short-term rental listings due to regulation lead to a price increase? | **Data:** InsideAirbnb.<br>**Models:** Cross-validation ridge regression. | The reduction in listings did not result in a statistically significant increase in listing prices. The group concluded the market self-regulated and the legislation was a success without negatively impacting owners significantly., |
  | **06** | **Media & Juvenile Violence**<br>Does violent media (games, movies, mass shooting reports) influence juvenile violent crime rates? | **Data:** Game/movie sales, arrest rates.<br>**Models:** OLS, LASSO, Ridge, Decision Tree, Random Forest., | An OLS model with logarithmic data performed best ($R^2$ of 0.96), suggesting it is possible to predict violent crime rates from media sales, though a direct causal link requires further study., |
  | **07** | **SAT Performance in NYC**<br>What factors determine performance on the SAT in New York City high schools? | **Data:** NYC 2014-2015 SAT Scores.<br>**Models:** Linear (OLS), Ridge, and LASSO regression. | The strongest factors determining performance were the percentage of students tested (indicating school focus/resources) and the racial makeup of the school, implying income inequality/redlining effects were major underlying factors.,, |
  | **08** | **Predicting Ohio Election**<br>Can demographic factors predict how Ohio counties voted in the 2016 election using 2012 data? | **Data:** Opendatasoft (Census/Election data).<br>**Models:** OLS, Ridge, and LASSO regressions. | The LASSO model was the most generalized and least overfit. Demographic factors (race, income, occupation) were found to be strong predictors of voting patterns., |
  | **09** | **Police Stops and Race**<br>Analyzing racial trends in police stops in San Francisco, New Orleans, and Pittsburgh. | **Data:** Stanford Open Policing Project.<br>**Models:** Logistic Regression and Ridge Classifier., | In New Orleans, accuracy was high due to class imbalance (most stops were non-white). In San Francisco, low accuracy suggested the chosen features did not correlate well with race, potentially indicating a lack of underlying racial discrimination in those specific metrics or data noise., |
  | **10** | **Marijuana Rhetorical Analysis**<br>Marijuana Legalization Rhetorical Analysis. | *N/A* | *Note: The source text only provides a link to presentation slides without summary content.* |
  | **11** | **Case Citation & Importance**<br>Measuring legal importance using citation graphs and opinion content in Illinois cases. | **Data:** Illinois cases (Caselaw Access Project).<br>**Models:** PageRank algorithm on citation networks; Random Forest with document embedding for prediction., | PageRank successfully identified legally significant cases establishing precedence. The content of the opinions was found to be a strong indicator/predictor of a case's importance score., |
  | **12** | **Sanctuary Cities and Crime**<br>Do sanctuary cities have higher violent crime rates than non-sanctuary cities? | **Data:** LAPD and Uniform Crime Reporting Statistics.<br>**Models:** Linear SVM, Naive Bayes, Multinomial Logistic Regression., | Violent crime in LA decreased after sanctuary status. Classification models failed to accurately predict sanctuary status based on crime rates, leading to the conclusion that sanctuary cities are not statistically more dangerous., |
  | **13** | **Gun Legislation Effectiveness**<br>Can predictive modeling determine the importance of specific gun legislation on gun violence? | **Data:** Gun Violence Archive, RAND.<br>**Models:** Random Forest Regression., | "Prohibited possessor" laws (specifically regarding mental competence) were the highest predictors. The model also indicated that Democratic states had higher gun incidents per capita than Republican states., |
## CEIC data
  - **CEIC Data** (Census and Economic Information Center) is a premium database widely used for macroeconomic, industrial, and financial time-series data.
  - At NUS, this resource is particularly valuable if you are doing research on **emerging markets** (especially China and Southeast Asia), as it provides much deeper granularity than standard open sources like the World Bank or IMF.
  - **1. What is in the CEIC Database?** CEIC is known for its "hard-to-get" local data. Instead of just giving you a national GDP figure, it often allows you to drill down into specific sectors, provinces, or cities.
    * **Global Database:** Covers 200+ economies with data on inflation, exports/imports, tourism, energy, and banking.
    * **China Premium Database:** This is CEIC's flagship product. It offers incredibly detailed data on China, often down to the city or county level (e.g., *monthly real estate transactions in Chengdu* or *industrial output of specific sectors in Jiangsu*).
    * **World Trend Plus:** Designed for benchmarking and comparing economies (e.g., comparing the *Competitiveness* or *Foreign Direct Investment* flows between ASEAN countries).
    * **Alternative Data:** Recent additions include high-frequency data like daily e-commerce indices, mobility trends, or air quality stats.
  - **2. How to Access via NUS Libraries?** You **cannot** simply Google "CEIC Data" and log in. You must go through the NUS proxy to be recognized as a subscriber.
    1. **Go to the NUS Libraries Portal**: Navigate to the [NUS Libraries E-Resources](https://nus.edu.sg/nuslibraries).
    2. **Select "Databases"**: Click on the "Databases" tab in the search box.
    3. **Search for "CEIC"**: Type "CEIC" and search.
    4. **Authenticate**: Click the link for **"CEIC Data Manager (CDM)"** or **"CEIC Data"**. You will be prompted to log in with your **NUS-ID** and password (via `libproxy1.nus.edu.sg`).
    5. **Enter "Guest Access" or Register**:
      * Once through the proxy, you may be taken to the **CDMNext** platform.
      * If prompted, you can usually proceed as a "Guest" (linked to the University subscription) or you may be asked to register an account using your `@u.nus.edu` email to save your charts and downloads.
  - **3. Tips for Using It (CDMNext Platform).** The interface you will use is called **CDMNext**. It can be slightly technical at first glance.
    * **Export to Excel:** This is the most popular feature. You can build a table of data (e.g., "Singapore Inflation Rate 2010-2024") and export it directly to Excel.
    * **"Series ID":** Every data point has a unique "Series ID" (e.g., `GDP.SG`). If you find a useful chart in a report that cites CEIC, you can search that ID to get the raw data.
    * **Download Limits:** Be aware that NUS's subscription might have download caps for bulk data (e.g., downloading 10,000 rows at once). If you need massive datasets, you might need to check with the library's financial database team.
  - **Quick Summary for Your Research**
    | If you need... | Use this Module in CEIC |
    | --- | --- |
    | **General Economic Data** (GDP, CPI, Unemployment) | **Global Database** |
    | **Deep China Research** (Provincial stats, specific industries) | **China Premium Database** |
    | **Cross-Country Comparisons** (ASEAN vs. EU) | **World Trend Plus** |
## Discussion
  """
  Hi all, I throw some ideas out for the project first.
  Please share across any you might have as well!

  1) SG / US: Parliamentary discourse on AI, versus public sentiments
  - Key question: On the topic of AI: Is there a disconnect between what people 'care about' (saliency) versus what the government thinks is best for the people?
  - Data: SG/US Parliamentary speeches + Scrape SG/US Twitter data.
  - So What: discourse on how to shape legislation.

  > A sub 1A would simply be to explore differences in discourse but it seems not meaningful.

  2) AI and job displacement:
  - Key question: Which are the 'biggest losers' in roles (e.g. finance, admin, marketing) when it comes to AI displacement?
  - Data: open job roles data, ideally 3 to 5 years data inclusive of 2025. Key features are department-specific categories (e.g. marketing, finance, admin, HR, etc.), and also role seniority (Executive / Manager / Director etc.)
  - So What: Harder legislation rather than 'tripartite soft approach' in Singapore.

  3) Can we predict legal outcomes?
  - Key Question: weeks 2 and 3 argue the challenges associated with use of AI in law. But how far-fetched is it exactly?
  - Data: Court hearing documents WITHOUT the final verdict.
  - So What: Further empirical examples of AI and its limits in legal use cases
  """
  """
  Thanks for sharing! Some of my thoughts on these 3:
  1). twitter data crawling is more difficult in recent years, and illegal. I think we have to use other source's data instead.
  2). Read an article on AI impact on job market https://www.linkedin.com/feed/update/urn:li:activity:7416539503496183808/?originTrackingId=ckfi9mIoZV9nmVwXNHd9iQ%3D%3D this afternoon, and it provided a dataset from Yale.
  3). I think this one is most realted to this course, but data preprocessing may need more works, which is get rid of the final verdict from the text. The prediction may be not that hard, like feeding the text to an AI model and summarize the output.
  """
  """
  1. Ah okay we avoid then.
  2. Think can explore further with other countries dataset. This article you find helps with additional source and research.
  3. We can ask for his thoughts on this. Maybe aside from predict outcome, can we use an LLM to justify why the outcome also but I don't know the challenge for you to code this ^^"
  """
  """
  I checked some database shared by NUS yesterday, but still trying to see what we can do with them. Previously I was thinking somthing related to gig economy like grab driver or food delivery?
  """
  """
  one of previous group members also suggested AI and mental wellness topic. I also think it's interesting but unsure how to find the text data, or specific angle (e.g. look at suicide rates? hotline dialing rates?)

  https://www.mentalhealthjournal.org/articles/minds-in-crisis-how-the-ai-revolution-is-impacting-mental-health.html
  """
  """
  I have two ideas about the topic.
  1) AI  and infringement. AI training relies on big data, but some reference materials such as paintings and articles are protected by copyright. Does the use of such materials for training models and the resulting generated outputs constitute infringement?
  2) AI and achievement protection. Who owns the copyright of code, images, videos, and texts generated by AI?
  """
## Topic Predicting Legal Outcomes (NLP)
  - **Key question:** Can a Natural Language Processing (NLP) model accurately predict the judgment (e.g., "Allowed" vs. "Dismissed" or "Violation" vs. "No Violation") based solely on the "facts" section of a court case? Does the model rely on legal reasoning or merely linguistic patterns (spurious correlations)?
  - **Data source :**
    - **Hugging Face:** **ECtHR (European Court of Human Rights) Dataset https://huggingface.co/datasets/AUEB-NLP/ecthr_cases**. This is a standard dataset for "Legal Judgment Prediction" consisting of facts and outcomes.
    - **Kaggle:** **Supreme Court Judgment Prediction https://www.kaggle.com/datasets/deepcontractor/supreme-court-judgment-prediction/data**.
  - **So what (results):** Critique the model using the **"Mules Case"** logic from the lectures: does the AI understand the *intent* (fear vs. laziness) or just the *words* (cart, slope, slipped)?.
***
