## Yolov7 torch model test
  ```py
  sys.path.append('../yolov7')
  import torch
  from models.experimental import attempt_load
  from utils.general import non_max_suppression

  model = attempt_load('yolov7.pt', map_location='cpu')
  _ = model.eval()

  from skimage.data import chelsea
  from skimage.transform import resize
  imm = resize(chelsea(), [640, 640])  # 测试图片,图片值范围 [0, 1]

  pred = model(torch.from_numpy(imm.astype('float32'))[None].permute([0, 3, 1, 2]))  # 前向
  # print(non_max_suppression(pred))  # 输出
  print(non_max_suppression(pred[0]))  # 输出
  ```
  ```py
  sys.path.append('../yolov7')
  import torch
  from models.experimental import Ensemble

  model = Ensemble()
  weight = 'yolov7.pt'
  ckpt = torch.load(weight, map_location="cpu")  # load
  model.append(ckpt['ema' if ckpt.get('ema') else 'model'].float().eval())  # FP32 model

  # Compatibility updates
  for m in model.modules():
      if type(m) is torch.nn.Upsample:
          m.recompute_scale_factor = None  # torch 1.11.0 compatibility

  from keras_cv_attention_models import download_and_load
  download_and_load.try_save_pth_and_onnx(model[-1], input_shape=(1, 3, 640, 640), save_pth=False, save_name='yolov7')
  ```
## Convert weights
  ```py
  sys.path.append('../yolov7')
  import torch
  ss = torch.load('yolov7.pt', map_location="cpu")['model'].state_dict()
  # ss = {kk: vv for kk, vv in ss.items() if not(kk.endswith('anchors') or kk.endswith('anchors_grid'))}

  from keras_cv_attention_models import download_and_load
  from keras_cv_attention_models.yolov7 import yolov7
  mm = yolov7.YOLOV7_CSP()

  tail_align_dict = {"downsample_pool_conv": -3, "downsample_pool_bn": -4}

  full_name_align_dict = {
    "stack1_1_conv": "stack1_2_conv", "stack1_1_bn": "stack1_2_bn", "stack2_1_conv": "stack2_2_conv", "stack2_1_bn": "stack2_2_bn",
    "stack3_1_conv": "stack3_2_conv", "stack3_1_bn": "stack3_2_bn", "stack4_1_conv": "stack4_2_conv", "stack4_1_bn": "stack4_2_bn",
    "stack4_spp_short_conv": "stack4_spp_pre_1_conv", "stack4_spp_short_bn": "stack4_spp_pre_1_bn", "stack4_spp_output_bn": -1,
    "stack5_spp_output_bn": -1, # YOLOV7_W6
    "pafpn_p4p5_up_conv": -2, "pafpn_p4p5_up_bn": -2, "pafpn_p4p5_1_conv": "pafpn_p4p5_2_conv", "pafpn_p4p5_1_bn": "pafpn_p4p5_2_bn", "pafpn_p4p5_out_bn": -1,
    "pafpn_p3p4p5_up_conv": -2, "pafpn_p3p4p5_up_bn": -2, "pafpn_p3p4p5_1_conv": "pafpn_p3p4p5_2_conv", "pafpn_p3p4p5_1_bn": "pafpn_p3p4p5_2_bn",
    "pafpn_c3n3_pool_conv": -3, "pafpn_c3n3_pool_bn": -4, "pafpn_c3n3_1_conv": "pafpn_c3n3_2_conv", "pafpn_c3n3_1_bn": "pafpn_c3n3_2_bn",
    "pafpn_c3n4_pool_conv": -3, "pafpn_c3n4_pool_bn": -4, "pafpn_c3n4_1_conv": "pafpn_c3n4_2_conv", "pafpn_c3n4_1_bn": "pafpn_c3n4_2_bn",
    "head_1_3x3_bn": -5, "head_1_1x1_bn": -4, "head_2_3x3_bn": -3, "head_2_1x1_bn": -2, "head_3_3x3_bn": -1,  # YOLOV7_CSP
    "head_1_1_bn": -2, "head_2_1_bn": -1,  # YOLOV7_X
  }

  skip_weights = ["num_batches_tracked", "anchor_grid", "anchors"]

  download_and_load.keras_reload_from_torch_model(
      ss,
      mm,
      skip_weights=skip_weights,
      tail_align_dict=tail_align_dict,
      tail_split_position=1,
      full_name_align_dict=full_name_align_dict,
      save_name=mm.name + "_coco.h5",
      do_convert=True,
  )
  ```
  ```py
  sys.path.append('../yolov7')
  import torch
  ss = torch.load('yolov7.pt', map_location="cpu")['model'].state_dict()
  # ss = {kk: vv for kk, vv in ss.items() if not(kk.endswith('anchors') or kk.endswith('anchors_grid'))}

  from keras_cv_attention_models import download_and_load
  from keras_cv_attention_models.yolov7 import yolov7
  mm = yolov7.YOLOV7_CSP()

  tail_align_dict = {"pafpn": {"up_conv": -2, "up_bn": -2, "1_conv": "2_conv", "1_bn": "2_bn", "pool_conv": -3, "pool_bn": -4}}

  full_name_align_dict = {
    "stack1_1_conv": "stack1_2_conv", "stack1_1_bn": "stack1_2_bn", "stack2_1_conv": "stack2_2_conv", "stack2_1_bn": "stack2_2_bn",
    "stack3_1_conv": "stack3_2_conv", "stack3_1_bn": "stack3_2_bn", "stack4_1_conv": "stack4_2_conv", "stack4_1_bn": "stack4_2_bn",
    "stack5_1_conv": "stack5_2_conv", "stack5_1_bn": "stack5_2_bn",  # YOLOV7_W6
    "stack2_downsample_pool_conv": -3, "stack2_downsample_pool_bn": -4,
    "stack3_downsample_pool_conv": -3, "stack3_downsample_pool_bn": -4,
    "stack4_downsample_pool_conv": -3, "stack4_downsample_pool_bn": -4,
    "stack4_spp_short_conv": -7, "stack4_spp_short_bn": -8, "stack4_spp_output_bn": -1,
    "stack5_spp_short_conv": -7, "stack5_spp_short_bn": -8, "stack5_spp_output_bn": -1,  # YOLOV7_W6
    "stack5_spp_output_bn": -1,  # YOLOV7_W6
    # "pafpn_p4p5_up_conv": -2, "pafpn_p4p5_up_bn": -2, "pafpn_p4p5_1_conv": "pafpn_p4p5_2_conv", "pafpn_p4p5_1_bn": "pafpn_p4p5_2_bn",
    # "pafpn_p3p4p5_up_conv": -2, "pafpn_p3p4p5_up_bn": -2, "pafpn_p3p4p5_1_conv": "pafpn_p3p4p5_2_conv", "pafpn_p3p4p5_1_bn": "pafpn_p3p4p5_2_bn",
    # "pafpn_c3n3_pool_conv": -3, "pafpn_c3n3_pool_bn": -4, "pafpn_c3n3_1_conv": "pafpn_c3n3_2_conv", "pafpn_c3n3_1_bn": "pafpn_c3n3_2_bn",
    # "pafpn_c3n4_pool_conv": -3, "pafpn_c3n4_pool_bn": -4, "pafpn_c3n4_1_conv": "pafpn_c3n4_2_conv", "pafpn_c3n4_1_bn": "pafpn_c3n4_2_bn",
    "pafpn_p4p5_out_bn": -1, "pafpn_p5p6_out_bn": -1, "pafpn_p4p5p6_out_bn": -1,
    "head_1_3x3_bn": -5, "head_1_1x1_bn": -4, "head_2_3x3_bn": -3, "head_2_1x1_bn": -2, "head_3_3x3_bn": -1,  # YOLOV7_CSP
    # "head_1_1_bn": -2, "head_2_1_bn": -1,  # YOLOV7_X [comment off for YOLO_W6]
    "head_1_1_bn": -3, "head_2_1_bn": -2, "head_3_1_bn": -1,  # YOLO_W6 [comment off for YOLOV7_X]

  }

  skip_weights = ["num_batches_tracked", "anchor_grid", "anchors"]

  download_and_load.keras_reload_from_torch_model(
      ss,
      mm,
      skip_weights=skip_weights,
      tail_align_dict=tail_align_dict,
      tail_split_position=2,
      full_name_align_dict=full_name_align_dict,
      save_name=mm.name + "_coco.h5",
      do_convert=True,
  )
  ```
  ```py
  sys.path.append('../yolov7')
  import torch
  ss = torch.load('yolov7-e6.pt', map_location="cpu")['model'].state_dict()
  # ss = {kk: vv for kk, vv in ss.items() if not(kk.endswith('anchors') or kk.endswith('anchors_grid'))}

  from keras_cv_attention_models import download_and_load
  from keras_cv_attention_models.yolov7 import yolov7
  mm = yolov7.YOLOV7_E6()

  tail_align_dict = {"pafpn": {"up_conv": -2, "up_bn": -2, "1_conv": "2_conv", "1_bn": "2_bn", "conv_2_bn": -1}}

  full_name_align_dict = {
    "stack1_1_conv": "stack1_2_conv", "stack1_1_bn": "stack1_2_bn", "stack2_1_conv": "stack2_2_conv", "stack2_1_bn": "stack2_2_bn",
    "stack3_1_conv": "stack3_2_conv", "stack3_1_bn": "stack3_2_bn", "stack4_1_conv": "stack4_2_conv", "stack4_1_bn": "stack4_2_bn",
    "stack5_1_conv": "stack5_2_conv", "stack5_1_bn": "stack5_2_bn",  # YOLOV7_W6
    "stack1_downsample_conv_2_bn": -1, "stack2_downsample_conv_2_bn": -1, "stack3_downsample_conv_2_bn": -1, "stack4_downsample_conv_2_bn": -1,  # YOLOV7_E6
    "stack5_downsample_conv_2_bn": -1,  # YOLOV7_E6
    "stack4_spp_short_conv": -7, "stack4_spp_short_bn": -8, "stack4_spp_output_bn": -1,
    "stack5_spp_short_conv": -7, "stack5_spp_short_bn": -8, "stack5_spp_output_bn": -1,  # YOLOV7_W6
    "stack5_spp_output_bn": -1,  # YOLOV7_W6
    # "pafpn_p4p5_up_conv": -2, "pafpn_p4p5_up_bn": -2, "pafpn_p4p5_1_conv": "pafpn_p4p5_2_conv", "pafpn_p4p5_1_bn": "pafpn_p4p5_2_bn",
    # "pafpn_p3p4p5_up_conv": -2, "pafpn_p3p4p5_up_bn": -2, "pafpn_p3p4p5_1_conv": "pafpn_p3p4p5_2_conv", "pafpn_p3p4p5_1_bn": "pafpn_p3p4p5_2_bn",
    # "pafpn_c3n3_pool_conv": -3, "pafpn_c3n3_pool_bn": -4, "pafpn_c3n3_1_conv": "pafpn_c3n3_2_conv", "pafpn_c3n3_1_bn": "pafpn_c3n3_2_bn",
    # "pafpn_c3n4_pool_conv": -3, "pafpn_c3n4_pool_bn": -4, "pafpn_c3n4_1_conv": "pafpn_c3n4_2_conv", "pafpn_c3n4_1_bn": "pafpn_c3n4_2_bn",
    "pafpn_p4p5_out_bn": -1, "pafpn_p5p6_out_bn": -1, "pafpn_p4p5p6_out_bn": -1,
    "head_1_3x3_bn": -5, "head_1_1x1_bn": -4, "head_2_3x3_bn": -3, "head_2_1x1_bn": -2, "head_3_3x3_bn": -1,  # YOLOV7_CSP
    # "head_1_1_bn": -2, "head_2_1_bn": -1,  # YOLOV7_X [comment off for YOLO_W6]
    "head_1_1_bn": -3, "head_2_1_bn": -2, "head_3_1_bn": -1,  # YOLO_W6 [comment off for YOLOV7_X]

  }

  skip_weights = ["num_batches_tracked", "anchor_grid", "anchors"]

  download_and_load.keras_reload_from_torch_model(
      ss,
      mm,
      skip_weights=skip_weights,
      tail_align_dict=tail_align_dict,
      tail_split_position=2,
      full_name_align_dict=full_name_align_dict,
      save_name=mm.name + "_coco.h5",
      do_convert=True,
  )
  ```
  **Convert bboxes output `[left, top, right, bottom]` -> `top, left, bottom, right`**
  ```py
  from keras_cv_attention_models.yolov7 import yolov7
  mm = yolov7.YOLOV7_CSP(pretrained="yolov7_csp_coco.h5")
  heads = [ii.name for ii in mm.layers if ii.name.startswith('head')]
  for ii in range(1, 100):
      layer_name = 'head_{}_2_conv'.format(ii)
      print(f">>>> {layer_name = }")
      if layer_name not in heads:
          break
      conv_layer = mm.get_layer(layer_name)
      new_ww = []
      for ww in conv_layer.get_weights():
          ww = np.reshape(ww, [*ww.shape[:-1], 3, 85])[..., [1, 0, 3, 2, *np.arange(5, 85), 4]]
          ww = np.reshape(ww, [*ww.shape[:-2], -1])
          new_ww.append(ww)
      conv_layer.set_weights(new_ww)

  mm.save(mm.name + "_coco.h5")


  from keras_cv_attention_models import test_images, coco
  imm = test_images.dog_cat()
  preds = mm(mm.preprocess_input(imm))
  bboxs, lables, confidences = mm.decode_predictions(preds)[0]
  coco.show_image_with_bboxes(imm, bboxs, lables, confidences, num_classes=80)
  ```
  **Convert SSP block `[::-1]` concat -> concat weitghs for YOLOV7_Tiny**
  ```py
  aa = mm.get_layer('stack4_spp_post_1_conv')
  ww = aa.get_weights()[0]
  aa.set_weights([np.concatenate([ww[:, :, 768:], ww[:, :, 512:768], ww[:, :, 256:512], ww[:, :, :256]], axis=2)])
  ```
  ```py
  foo = [
      'stem_conv',
      'stem_bn',
      'stack1_downsample_conv_1_conv',
      'stack1_downsample_conv_1_bn',
      'stack1_downsample_conv_2_conv',
      'stack1_downsample_conv_2_bn',
      'stack1_downsample_pool_conv',
      'stack1_downsample_pool_bn',
      'stack1_1_conv',
      'stack1_1_bn',
      'stack1_2_conv',
      'stack1_2_bn',
      'stack1_3_conv',
      'stack1_3_bn',
      'stack1_4_conv',
      'stack1_4_bn',
      'stack1_5_conv',
      'stack1_5_bn',
      'stack1_6_conv',
      'stack1_6_bn',
      'stack1_7_conv',
      'stack1_7_bn',
      'stack1_8_conv',
      'stack1_8_bn',
      'stack1_out_conv',
      'stack1_out_bn',
      'stack1_another_1_conv',
      'stack1_another_1_bn',
      'stack1_another_2_conv',
      'stack1_another_2_bn',
      'stack1_another_3_conv',
      'stack1_another_3_bn',
      'stack1_another_4_conv',
      'stack1_another_4_bn',
      'stack1_another_5_conv',
      'stack1_another_5_bn',
      'stack1_another_6_conv',
      'stack1_another_6_bn',
      'stack1_another_7_conv',
      'stack1_another_7_bn',
      'stack1_another_8_conv',
      'stack1_another_8_bn',
      'stack1_another_out_conv',
      'stack1_another_out_bn',
      'stack2_downsample_conv_1_conv',
      'stack2_downsample_conv_1_bn',
      'stack2_downsample_conv_2_conv',
      'stack2_downsample_conv_2_bn',
      'stack2_downsample_pool_conv',
      'stack2_downsample_pool_bn',
      'stack2_1_conv',
      'stack2_1_bn',
      'stack2_2_conv',
      'stack2_2_bn',
      'stack2_3_conv',
      'stack2_3_bn',
      'stack2_4_conv',
      'stack2_4_bn',
      'stack2_5_conv',
      'stack2_5_bn',
      'stack2_6_conv',
      'stack2_6_bn',
      'stack2_7_conv',
      'stack2_7_bn',
      'stack2_8_conv',
      'stack2_8_bn',
      'stack2_out_conv',
      'stack2_out_bn',
      'stack2_another_1_conv',
      'stack2_another_1_bn',
      'stack2_another_2_conv',
      'stack2_another_2_bn',
      'stack2_another_3_conv',
      'stack2_another_3_bn',
      'stack2_another_4_conv',
      'stack2_another_4_bn',
      'stack2_another_5_conv',
      'stack2_another_5_bn',
      'stack2_another_6_conv',
      'stack2_another_6_bn',
      'stack2_another_7_conv',
      'stack2_another_7_bn',
      'stack2_another_8_conv',
      'stack2_another_8_bn',
      'stack2_another_out_conv',
      'stack2_another_out_bn',
      'stack3_downsample_conv_1_conv',
      'stack3_downsample_conv_1_bn',
      'stack3_downsample_conv_2_conv',
      'stack3_downsample_conv_2_bn',
      'stack3_downsample_pool_conv',
      'stack3_downsample_pool_bn',
      'stack3_1_conv',
      'stack3_1_bn',
      'stack3_2_conv',
      'stack3_2_bn',
      'stack3_3_conv',
      'stack3_3_bn',
      'stack3_4_conv',
      'stack3_4_bn',
      'stack3_5_conv',
      'stack3_5_bn',
      'stack3_6_conv',
      'stack3_6_bn',
      'stack3_7_conv',
      'stack3_7_bn',
      'stack3_8_conv',
      'stack3_8_bn',
      'stack3_out_conv',
      'stack3_out_bn',
      'stack3_another_1_conv',
      'stack3_another_1_bn',
      'stack3_another_2_conv',
      'stack3_another_2_bn',
      'stack3_another_3_conv',
      'stack3_another_3_bn',
      'stack3_another_4_conv',
      'stack3_another_4_bn',
      'stack3_another_5_conv',
      'stack3_another_5_bn',
      'stack3_another_6_conv',
      'stack3_another_6_bn',
      'stack3_another_7_conv',
      'stack3_another_7_bn',
      'stack3_another_8_conv',
      'stack3_another_8_bn',
      'stack3_another_out_conv',
      'stack3_another_out_bn',
      'stack4_downsample_conv_1_conv',
      'stack4_downsample_conv_1_bn',
      'stack4_downsample_conv_2_conv',
      'stack4_downsample_conv_2_bn',
      'stack4_downsample_pool_conv',
      'stack4_downsample_pool_bn',
      'stack4_1_conv',
      'stack4_1_bn',
      'stack4_2_conv',
      'stack4_2_bn',
      'stack4_3_conv',
      'stack4_3_bn',
      'stack4_4_conv',
      'stack4_4_bn',
      'stack4_5_conv',
      'stack4_5_bn',
      'stack4_6_conv',
      'stack4_6_bn',
      'stack4_7_conv',
      'stack4_7_bn',
      'stack4_8_conv',
      'stack4_8_bn',
      'stack4_out_conv',
      'stack4_out_bn',
      'stack4_another_1_conv',
      'stack4_another_1_bn',
      'stack4_another_2_conv',
      'stack4_another_2_bn',
      'stack4_another_3_conv',
      'stack4_another_3_bn',
      'stack4_another_4_conv',
      'stack4_another_4_bn',
      'stack4_another_5_conv',
      'stack4_another_5_bn',
      'stack4_another_6_conv',
      'stack4_another_6_bn',
      'stack4_another_7_conv',
      'stack4_another_7_bn',
      'stack4_another_8_conv',
      'stack4_another_8_bn',
      'stack4_another_out_conv',
      'stack4_another_out_bn',
      'stack5_downsample_conv_1_conv',
      'stack5_downsample_conv_1_bn',
      'stack5_downsample_conv_2_conv',
      'stack5_downsample_conv_2_bn',
      'stack5_downsample_pool_conv',
      'stack5_downsample_pool_bn',
      'stack5_1_conv',
      'stack5_1_bn',
      'stack5_2_conv',
      'stack5_2_bn',
      'stack5_3_conv',
      'stack5_3_bn',
      'stack5_4_conv',
      'stack5_4_bn',
      'stack5_5_conv',
      'stack5_5_bn',
      'stack5_6_conv',
      'stack5_6_bn',
      'stack5_7_conv',
      'stack5_7_bn',
      'stack5_8_conv',
      'stack5_8_bn',
      'stack5_out_conv',
      'stack5_out_bn',
      'stack5_another_1_conv',
      'stack5_another_1_bn',
      'stack5_another_2_conv',
      'stack5_another_2_bn',
      'stack5_another_3_conv',
      'stack5_another_3_bn',
      'stack5_another_4_conv',
      'stack5_another_4_bn',
      'stack5_another_5_conv',
      'stack5_another_5_bn',
      'stack5_another_6_conv',
      'stack5_another_6_bn',
      'stack5_another_7_conv',
      'stack5_another_7_bn',
      'stack5_another_8_conv',
      'stack5_another_8_bn',
      'stack5_another_out_conv',
      'stack5_another_out_bn',
      'stack5_spp_pre_1_conv',
      'stack5_spp_pre_1_bn',
      'stack5_spp_short_conv',
      'stack5_spp_short_bn',
      'stack5_spp_pre_2_conv',
      'stack5_spp_pre_2_bn',
      'stack5_spp_pre_3_conv',
      'stack5_spp_pre_3_bn',
      'stack5_spp_post_1_conv',
      'stack5_spp_post_1_bn',
      'stack5_spp_post_2_conv',
      'stack5_spp_post_2_bn',
      'stack5_spp_output_conv',
      'stack5_spp_output_bn',
      'pafpn_p5p6_up_conv',
      'pafpn_p5p6_up_bn',
      'pafpn_p5_down_conv',
      'pafpn_p5_down_bn',
      'pafpn_p5p6_1_conv',
      'pafpn_p5p6_1_bn',
      'pafpn_p5p6_2_conv',
      'pafpn_p5p6_2_bn',
      'pafpn_p5p6_3_conv',
      'pafpn_p5p6_3_bn',
      'pafpn_p5p6_4_conv',
      'pafpn_p5p6_4_bn',
      'pafpn_p5p6_5_conv',
      'pafpn_p5p6_5_bn',
      'pafpn_p5p6_6_conv',
      'pafpn_p5p6_6_bn',
      'pafpn_p5p6_7_conv',
      'pafpn_p5p6_7_bn',
      'pafpn_p5p6_8_conv',
      'pafpn_p5p6_8_bn',
      'pafpn_p5p6_out_conv',
      'pafpn_p5p6_out_bn',
      'pafpn_p5p6_another_1_conv',
      'pafpn_p5p6_another_1_bn',
      'pafpn_p5p6_another_2_conv',
      'pafpn_p5p6_another_2_bn',
      'pafpn_p5p6_another_3_conv',
      'pafpn_p5p6_another_3_bn',
      'pafpn_p5p6_another_4_conv',
      'pafpn_p5p6_another_4_bn',
      'pafpn_p5p6_another_5_conv',
      'pafpn_p5p6_another_5_bn',
      'pafpn_p5p6_another_6_conv',
      'pafpn_p5p6_another_6_bn',
      'pafpn_p5p6_another_7_conv',
      'pafpn_p5p6_another_7_bn',
      'pafpn_p5p6_another_8_conv',
      'pafpn_p5p6_another_8_bn',
      'pafpn_p5p6_another_out_conv',
      'pafpn_p5p6_another_out_bn',
      'pafpn_p4p5p6_up_conv',
      'pafpn_p4p5p6_up_bn',
      'pafpn_p4_down_conv',
      'pafpn_p4_down_bn',
      'pafpn_p4p5p6_1_conv',
      'pafpn_p4p5p6_1_bn',
      'pafpn_p4p5p6_2_conv',
      'pafpn_p4p5p6_2_bn',
      'pafpn_p4p5p6_3_conv',
      'pafpn_p4p5p6_3_bn',
      'pafpn_p4p5p6_4_conv',
      'pafpn_p4p5p6_4_bn',
      'pafpn_p4p5p6_5_conv',
      'pafpn_p4p5p6_5_bn',
      'pafpn_p4p5p6_6_conv',
      'pafpn_p4p5p6_6_bn',
      'pafpn_p4p5p6_7_conv',
      'pafpn_p4p5p6_7_bn',
      'pafpn_p4p5p6_8_conv',
      'pafpn_p4p5p6_8_bn',
      'pafpn_p4p5p6_out_conv',
      'pafpn_p4p5p6_out_bn',
      'pafpn_p4p5p6_another_1_conv',
      'pafpn_p4p5p6_another_1_bn',
      'pafpn_p4p5p6_another_2_conv',
      'pafpn_p4p5p6_another_2_bn',
      'pafpn_p4p5p6_another_3_conv',
      'pafpn_p4p5p6_another_3_bn',
      'pafpn_p4p5p6_another_4_conv',
      'pafpn_p4p5p6_another_4_bn',
      'pafpn_p4p5p6_another_5_conv',
      'pafpn_p4p5p6_another_5_bn',
      'pafpn_p4p5p6_another_6_conv',
      'pafpn_p4p5p6_another_6_bn',
      'pafpn_p4p5p6_another_7_conv',
      'pafpn_p4p5p6_another_7_bn',
      'pafpn_p4p5p6_another_8_conv',
      'pafpn_p4p5p6_another_8_bn',
      'pafpn_p4p5p6_another_out_conv',
      'pafpn_p4p5p6_another_out_bn',
      'pafpn_p3p4p5p6_up_conv',
      'pafpn_p3p4p5p6_up_bn',
      'pafpn_p3_down_conv',
      'pafpn_p3_down_bn',
      'pafpn_p3p4p5p6_1_conv',
      'pafpn_p3p4p5p6_1_bn',
      'pafpn_p3p4p5p6_2_conv',
      'pafpn_p3p4p5p6_2_bn',
      'pafpn_p3p4p5p6_3_conv',
      'pafpn_p3p4p5p6_3_bn',
      'pafpn_p3p4p5p6_4_conv',
      'pafpn_p3p4p5p6_4_bn',
      'pafpn_p3p4p5p6_5_conv',
      'pafpn_p3p4p5p6_5_bn',
      'pafpn_p3p4p5p6_6_conv',
      'pafpn_p3p4p5p6_6_bn',
      'pafpn_p3p4p5p6_7_conv',
      'pafpn_p3p4p5p6_7_bn',
      'pafpn_p3p4p5p6_8_conv',
      'pafpn_p3p4p5p6_8_bn',
      'pafpn_p3p4p5p6_out_conv',
      'pafpn_p3p4p5p6_out_bn',
      'pafpn_p3p4p5p6_another_1_conv',
      'pafpn_p3p4p5p6_another_1_bn',
      'pafpn_p3p4p5p6_another_2_conv',
      'pafpn_p3p4p5p6_another_2_bn',
      'pafpn_p3p4p5p6_another_3_conv',
      'pafpn_p3p4p5p6_another_3_bn',
      'pafpn_p3p4p5p6_another_4_conv',
      'pafpn_p3p4p5p6_another_4_bn',
      'pafpn_p3p4p5p6_another_5_conv',
      'pafpn_p3p4p5p6_another_5_bn',
      'pafpn_p3p4p5p6_another_6_conv',
      'pafpn_p3p4p5p6_another_6_bn',
      'pafpn_p3p4p5p6_another_7_conv',
      'pafpn_p3p4p5p6_another_7_bn',
      'pafpn_p3p4p5p6_another_8_conv',
      'pafpn_p3p4p5p6_another_8_bn',
      'pafpn_p3p4p5p6_another_out_conv',
      'pafpn_p3p4p5p6_another_out_bn',
      'pafpn_c3n3_conv_1_conv',
      'pafpn_c3n3_conv_1_bn',
      'pafpn_c3n3_conv_2_conv',
      'pafpn_c3n3_conv_2_bn',
      'pafpn_c3n3_pool_conv',
      'pafpn_c3n3_pool_bn',
      'pafpn_c3n3_1_conv',
      'pafpn_c3n3_1_bn',
      'pafpn_c3n3_2_conv',
      'pafpn_c3n3_2_bn',
      'pafpn_c3n3_3_conv',
      'pafpn_c3n3_3_bn',
      'pafpn_c3n3_4_conv',
      'pafpn_c3n3_4_bn',
      'pafpn_c3n3_5_conv',
      'pafpn_c3n3_5_bn',
      'pafpn_c3n3_6_conv',
      'pafpn_c3n3_6_bn',
      'pafpn_c3n3_7_conv',
      'pafpn_c3n3_7_bn',
      'pafpn_c3n3_8_conv',
      'pafpn_c3n3_8_bn',
      'pafpn_c3n3_out_conv',
      'pafpn_c3n3_out_bn',
      'pafpn_c3n3_another_1_conv',
      'pafpn_c3n3_another_1_bn',
      'pafpn_c3n3_another_2_conv',
      'pafpn_c3n3_another_2_bn',
      'pafpn_c3n3_another_3_conv',
      'pafpn_c3n3_another_3_bn',
      'pafpn_c3n3_another_4_conv',
      'pafpn_c3n3_another_4_bn',
      'pafpn_c3n3_another_5_conv',
      'pafpn_c3n3_another_5_bn',
      'pafpn_c3n3_another_6_conv',
      'pafpn_c3n3_another_6_bn',
      'pafpn_c3n3_another_7_conv',
      'pafpn_c3n3_another_7_bn',
      'pafpn_c3n3_another_8_conv',
      'pafpn_c3n3_another_8_bn',
      'pafpn_c3n3_another_out_conv',
      'pafpn_c3n3_another_out_bn',
      'pafpn_c3n4_conv_1_conv',
      'pafpn_c3n4_conv_1_bn',
      'pafpn_c3n4_conv_2_conv',
      'pafpn_c3n4_conv_2_bn',
      'pafpn_c3n4_pool_conv',
      'pafpn_c3n4_pool_bn',
      'pafpn_c3n4_1_conv',
      'pafpn_c3n4_1_bn',
      'pafpn_c3n4_2_conv',
      'pafpn_c3n4_2_bn',
      'pafpn_c3n4_3_conv',
      'pafpn_c3n4_3_bn',
      'pafpn_c3n4_4_conv',
      'pafpn_c3n4_4_bn',
      'pafpn_c3n4_5_conv',
      'pafpn_c3n4_5_bn',
      'pafpn_c3n4_6_conv',
      'pafpn_c3n4_6_bn',
      'pafpn_c3n4_7_conv',
      'pafpn_c3n4_7_bn',
      'pafpn_c3n4_8_conv',
      'pafpn_c3n4_8_bn',
      'pafpn_c3n4_out_conv',
      'pafpn_c3n4_out_bn',
      'pafpn_c3n4_another_1_conv',
      'pafpn_c3n4_another_1_bn',
      'pafpn_c3n4_another_2_conv',
      'pafpn_c3n4_another_2_bn',
      'pafpn_c3n4_another_3_conv',
      'pafpn_c3n4_another_3_bn',
      'pafpn_c3n4_another_4_conv',
      'pafpn_c3n4_another_4_bn',
      'pafpn_c3n4_another_5_conv',
      'pafpn_c3n4_another_5_bn',
      'pafpn_c3n4_another_6_conv',
      'pafpn_c3n4_another_6_bn',
      'pafpn_c3n4_another_7_conv',
      'pafpn_c3n4_another_7_bn',
      'pafpn_c3n4_another_8_conv',
      'pafpn_c3n4_another_8_bn',
      'pafpn_c3n4_another_out_conv',
      'pafpn_c3n4_another_out_bn',
      'pafpn_c3n5_conv_1_conv',
      'pafpn_c3n5_conv_1_bn',
      'pafpn_c3n5_conv_2_conv',
      'pafpn_c3n5_conv_2_bn',
      'pafpn_c3n5_pool_conv',
      'pafpn_c3n5_pool_bn',
      'pafpn_c3n5_1_conv',
      'pafpn_c3n5_1_bn',
      'pafpn_c3n5_2_conv',
      'pafpn_c3n5_2_bn',
      'pafpn_c3n5_3_conv',
      'pafpn_c3n5_3_bn',
      'pafpn_c3n5_4_conv',
      'pafpn_c3n5_4_bn',
      'pafpn_c3n5_5_conv',
      'pafpn_c3n5_5_bn',
      'pafpn_c3n5_6_conv',
      'pafpn_c3n5_6_bn',
      'pafpn_c3n5_7_conv',
      'pafpn_c3n5_7_bn',
      'pafpn_c3n5_8_conv',
      'pafpn_c3n5_8_bn',
      'pafpn_c3n5_out_conv',
      'pafpn_c3n5_out_bn',
      'pafpn_c3n5_another_1_conv',
      'pafpn_c3n5_another_1_bn',
      'pafpn_c3n5_another_2_conv',
      'pafpn_c3n5_another_2_bn',
      'pafpn_c3n5_another_3_conv',
      'pafpn_c3n5_another_3_bn',
      'pafpn_c3n5_another_4_conv',
      'pafpn_c3n5_another_4_bn',
      'pafpn_c3n5_another_5_conv',
      'pafpn_c3n5_another_5_bn',
      'pafpn_c3n5_another_6_conv',
      'pafpn_c3n5_another_6_bn',
      'pafpn_c3n5_another_7_conv',
      'pafpn_c3n5_another_7_bn',
      'pafpn_c3n5_another_8_conv',
      'pafpn_c3n5_another_8_bn',
      'pafpn_c3n5_another_out_conv',
      'pafpn_c3n5_another_out_bn',
      'head_1_1_conv',
      'head_1_1_bn',
      'head_2_1_conv',
      'head_2_1_bn',
      'head_3_1_conv',
      'head_3_1_bn',
      'head_4_1_conv',
      'head_4_1_bn',
      'head_1_2_conv',
      'head_2_2_conv',
      'head_3_2_conv',
      'head_4_2_conv',
  ]

  sys.path.append('../yolov7')
  import torch
  ss = torch.load('yolov7-e6e.pt', map_location="cpu")['model'].state_dict()
  # ss = {kk: vv for kk, vv in ss.items() if not(kk.endswith('anchors') or kk.endswith('anchors_grid'))}

  from keras_cv_attention_models import download_and_load
  from keras_cv_attention_models.yolov7 import yolov7
  mm = yolov7.YOLOV7_E6E()

  skip_weights = ["num_batches_tracked", "anchor_grid", "anchors"]
  download_and_load.keras_reload_from_torch_model(ss, mm, skip_weights=skip_weights, specific_match_func=lambda xx: foo, save_name=mm.name + "_coco.h5")
  ```
## DCNv2 Deformable Convolution Network
  - [Github miemie2013/Keras-YOLOv4](https://github.com/miemie2013/Keras-YOLOv4)
  ```py
  class DCNv2(Layer):
      '''
      咩酱自实现的DCNv2，咩酱的得意之作，tensorflow的纯python接口实现，效率极高。
      '''
      def __init__(self, input_dim, filters, filter_size, stride=1, padding=0, bias_attr=False, distribution='normal', gain=1, name=''):
          super(DCNv2, self).__init__()
          assert distribution in ['uniform', 'normal']
          self.input_dim = input_dim
          self.filters = filters
          self.filter_size = filter_size
          self.stride = stride
          self.padding = padding
          self.bias_attr = bias_attr

          self.conv_offset_padding = keras.layers.ZeroPadding2D(padding=((1, 0), (1, 0)))
          self.zero_padding = keras.layers.ZeroPadding2D(padding=((padding, padding+1), (padding, padding+1)))

      def build(self, input_shape):
          input_dim = self.input_dim
          filters = self.filters
          filter_size = self.filter_size
          bias_attr = self.bias_attr
          self.offset_w = self.add_weight('offset_w', shape=[filter_size, filter_size, input_dim, filter_size * filter_size * 3], initializer='zeros')
          self.offset_b = self.add_weight('offset_b', shape=[1, 1, 1, filter_size * filter_size * 3], initializer='zeros')
          self.dcn_weight = self.add_weight('dcn_weight', shape=[filters, input_dim, filter_size, filter_size], initializer='uniform')
          self.dcn_bias = None
          if bias_attr:
              self.dcn_bias = self.add_weight('dcn_bias', shape=[filters, ], initializer='zeros')

      def compute_output_shape(self, input_shape):
          filters = self.filters
          return (None, None, None, filters)

      def call(self, x):
          filter_size = self.filter_size
          stride = self.stride
          padding = self.padding
          dcn_weight = self.dcn_weight
          dcn_bias = self.dcn_bias


          # 当filter_size = 3, stride = 2, padding = 1时， 设置padding2 = 'valid'，K.conv2d层前加一个self.conv_offset_padding
          # 当filter_size = 3, stride = 1, padding = 1时， 设置padding2 = 'same'，K.conv2d层前不用加一个self.conv_offset_padding
          # 无论什么条件，self.zero_padding层都是必须要加的。
          if stride == 2:
              temp = self.conv_offset_padding(x)
          else:
              temp = x
          padding2 = None
          if stride == 2:
              padding2 = 'valid'
          else:
              padding2 = 'same'
          offset_mask = K.conv2d(temp, self.offset_w, strides=(stride, stride), padding=padding2)
          offset_mask += self.offset_b

          offset_mask = tf.transpose(offset_mask, [0, 3, 1, 2])
          offset = offset_mask[:, :filter_size ** 2 * 2, :, :]
          mask = offset_mask[:, filter_size ** 2 * 2:, :, :]
          mask = tf.nn.sigmoid(mask)


          # ===================================
          N = tf.shape(x)[0]
          H = tf.shape(x)[1]
          W = tf.shape(x)[2]
          out_C = tf.shape(dcn_weight)[0]
          in_C = tf.shape(dcn_weight)[1]
          kH = tf.shape(dcn_weight)[2]
          kW = tf.shape(dcn_weight)[3]
          W_f = tf.cast(W, tf.float32)
          H_f = tf.cast(H, tf.float32)
          kW_f = tf.cast(kW, tf.float32)
          kH_f = tf.cast(kH, tf.float32)

          out_W = (W_f + 2 * padding - (kW_f - 1)) // stride
          out_H = (H_f + 2 * padding - (kH_f - 1)) // stride
          out_W = tf.cast(out_W, tf.int32)
          out_H = tf.cast(out_H, tf.int32)
          out_W_f = tf.cast(out_W, tf.float32)
          out_H_f = tf.cast(out_H, tf.float32)

          # 1.先对图片x填充得到填充后的图片pad_x
          pad_x = self.zero_padding(x)
          pad_x = tf.transpose(pad_x, [0, 3, 1, 2])

          # 卷积核中心点在pad_x中的位置
          rows = tf.range(out_W_f, dtype=tf.float32) * stride + padding
          cols = tf.range(out_H_f, dtype=tf.float32) * stride + padding
          rows = tf.tile(rows[tf.newaxis, tf.newaxis, :, tf.newaxis, tf.newaxis], [1, out_H, 1, 1, 1])
          cols = tf.tile(cols[tf.newaxis, :, tf.newaxis, tf.newaxis, tf.newaxis], [1, 1, out_W, 1, 1])
          start_pos_yx = tf.concat([cols, rows], axis=-1)  # [1, out_H, out_W, 1, 2]   仅仅是卷积核中心点在pad_x中的位置
          start_pos_yx = tf.tile(start_pos_yx, [N, 1, 1, kH * kW, 1])  # [N, out_H, out_W, kH*kW, 2]   仅仅是卷积核中心点在pad_x中的位置
          start_pos_y = start_pos_yx[:, :, :, :, :1]  # [N, out_H, out_W, kH*kW, 1]   仅仅是卷积核中心点在pad_x中的位置
          start_pos_x = start_pos_yx[:, :, :, :, 1:]  # [N, out_H, out_W, kH*kW, 1]   仅仅是卷积核中心点在pad_x中的位置

          # 卷积核内部的偏移
          half_W = (kW_f - 1) / 2
          half_H = (kH_f - 1) / 2
          rows2 = tf.range(kW_f, dtype=tf.float32) - half_W
          cols2 = tf.range(kH_f, dtype=tf.float32) - half_H
          rows2 = tf.tile(rows2[tf.newaxis, :, tf.newaxis], [kH, 1, 1])
          cols2 = tf.tile(cols2[:, tf.newaxis, tf.newaxis], [1, kW, 1])
          filter_inner_offset_yx = tf.concat([cols2, rows2], axis=-1)  # [kH, kW, 2]   卷积核内部的偏移
          filter_inner_offset_yx = tf.reshape(filter_inner_offset_yx, (1, 1, 1, kH * kW, 2))  # [1, 1, 1, kH*kW, 2]   卷积核内部的偏移
          filter_inner_offset_yx = tf.tile(filter_inner_offset_yx, [N, out_H, out_W, 1, 1])  # [N, out_H, out_W, kH*kW, 2]   卷积核内部的偏移
          filter_inner_offset_y = filter_inner_offset_yx[:, :, :, :, :1]  # [N, out_H, out_W, kH*kW, 1]   卷积核内部的偏移
          filter_inner_offset_x = filter_inner_offset_yx[:, :, :, :, 1:]  # [N, out_H, out_W, kH*kW, 1]   卷积核内部的偏移

          mask = tf.transpose(mask, [0, 2, 3, 1])       # [N, out_H, out_W, kH*kW*1]
          offset = tf.transpose(offset, [0, 2, 3, 1])   # [N, out_H, out_W, kH*kW*2]
          offset_yx = tf.reshape(offset, (N, out_H, out_W, kH * kW, 2))  # [N, out_H, out_W, kH*kW, 2]
          offset_y = offset_yx[:, :, :, :, :1]  # [N, out_H, out_W, kH*kW, 1]
          offset_x = offset_yx[:, :, :, :, 1:]  # [N, out_H, out_W, kH*kW, 1]

          # 最终位置
          pos_y = start_pos_y + filter_inner_offset_y + offset_y  # [N, out_H, out_W, kH*kW, 1]
          pos_x = start_pos_x + filter_inner_offset_x + offset_x  # [N, out_H, out_W, kH*kW, 1]
          pos_y = tf.maximum(pos_y, 0.0)
          pos_y = tf.minimum(pos_y, H_f + padding * 2 - 1.0)
          pos_x = tf.maximum(pos_x, 0.0)
          pos_x = tf.minimum(pos_x, W_f + padding * 2 - 1.0)
          ytxt = tf.concat([pos_y, pos_x], -1)  # [N, out_H, out_W, kH*kW, 2]

          pad_x = tf.transpose(pad_x, [0, 2, 3, 1])  # [N, pad_x_H, pad_x_W, C]

          mask = tf.reshape(mask, (N, out_H, out_W, kH, kW))  # [N, out_H, out_W, kH, kW]

          def _process_sample(args):
              _pad_x, _mask, _ytxt = args
              # _pad_x:    [pad_x_H, pad_x_W, in_C]
              # _mask:     [out_H, out_W, kH, kW]
              # _ytxt:     [out_H, out_W, kH*kW, 2]

              _ytxt = tf.reshape(_ytxt, (out_H * out_W * kH * kW, 2))  # [out_H*out_W*kH*kW, 2]
              _yt = _ytxt[:, :1]
              _xt = _ytxt[:, 1:]
              _y1 = tf.floor(_yt)
              _x1 = tf.floor(_xt)
              _y2 = _y1 + 1.0
              _x2 = _x1 + 1.0
              _y1x1 = tf.concat([_y1, _x1], -1)
              _y1x2 = tf.concat([_y1, _x2], -1)
              _y2x1 = tf.concat([_y2, _x1], -1)
              _y2x2 = tf.concat([_y2, _x2], -1)

              _y1x1_int = tf.cast(_y1x1, tf.int32)  # [out_H*out_W*kH*kW, 2]
              v1 = tf.gather_nd(_pad_x, _y1x1_int)  # [out_H*out_W*kH*kW, in_C]
              _y1x2_int = tf.cast(_y1x2, tf.int32)  # [out_H*out_W*kH*kW, 2]
              v2 = tf.gather_nd(_pad_x, _y1x2_int)  # [out_H*out_W*kH*kW, in_C]
              _y2x1_int = tf.cast(_y2x1, tf.int32)  # [out_H*out_W*kH*kW, 2]
              v3 = tf.gather_nd(_pad_x, _y2x1_int)  # [out_H*out_W*kH*kW, in_C]
              _y2x2_int = tf.cast(_y2x2, tf.int32)  # [out_H*out_W*kH*kW, 2]
              v4 = tf.gather_nd(_pad_x, _y2x2_int)  # [out_H*out_W*kH*kW, in_C]

              lh = _yt - _y1  # [out_H*out_W*kH*kW, 1]
              lw = _xt - _x1
              hh = 1 - lh
              hw = 1 - lw
              w1 = hh * hw
              w2 = hh * lw
              w3 = lh * hw
              w4 = lh * lw
              value = w1 * v1 + w2 * v2 + w3 * v3 + w4 * v4  # [out_H*out_W*kH*kW, in_C]
              _mask = tf.reshape(_mask, (out_H * out_W * kH * kW, 1))
              value = value * _mask
              value = tf.reshape(value, (out_H, out_W, kH, kW, in_C))
              value = tf.transpose(value, [0, 1, 4, 2, 3])   # [out_H, out_W, in_C, kH, kW]
              return value

          # 旧的方案，使用逐元素相乘，慢！
          # new_x = tf.map_fn(_process_sample, [pad_x, mask, ytxt], dtype=tf.float32)   # [N, out_H, out_W, in_C, kH, kW]
          # new_x = tf.reshape(new_x, (N, out_H, out_W, in_C * kH * kW))   # [N, out_H, out_W, in_C * kH * kW]
          # new_x = tf.transpose(new_x, [0, 3, 1, 2])  # [N, in_C*kH*kW, out_H, out_W]
          # exp_new_x = tf.reshape(new_x, (N, 1, in_C*kH*kW, out_H, out_W))  # 增加1维，[N,      1, in_C*kH*kW, out_H, out_W]
          # reshape_w = tf.reshape(dcn_weight, (1, out_C, in_C * kH * kW, 1, 1))      # [1, out_C,  in_C*kH*kW,     1,     1]
          # out = exp_new_x * reshape_w                                   # 逐元素相乘，[N, out_C,  in_C*kH*kW, out_H, out_W]
          # out = tf.reduce_sum(out, axis=[2, ])                           # 第2维求和，[N, out_C, out_H, out_W]
          # out = tf.transpose(out, [0, 2, 3, 1])

          # 新的方案，用等价的1x1卷积代替逐元素相乘，快！
          new_x = tf.map_fn(_process_sample, [pad_x, mask, ytxt], dtype=tf.float32)   # [N, out_H, out_W, in_C, kH, kW]
          new_x = tf.reshape(new_x, (N, out_H, out_W, in_C * kH * kW))                # [N, out_H, out_W, in_C * kH * kW]
          tw = tf.transpose(dcn_weight, [1, 2, 3, 0])      # [out_C, in_C, kH, kW] -> [in_C, kH, kW, out_C]
          tw = tf.reshape(tw, (1, 1, in_C*kH*kW, out_C))   # [1, 1, in_C*kH*kW, out_C]  变成1x1卷积核
          out = K.conv2d(new_x, tw, strides=(1, 1), padding='valid')     # [N, out_H, out_W, out_C]
          return out
  ```
***

# Custom yolov7 practice
