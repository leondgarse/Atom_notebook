```py
import torch
from models.experimental import attempt_load

model = attempt_load('yolov7.pt', map_location='cpu')
_ = model.eval()
_ = model(torch.zeros([1, 3, 224, 224]))

sys.path.append('../keras_cv_attention_models/')
from keras_cv_attention_models import download_and_load
download_and_load.try_save_pth_and_onnx(model)
```
```py
import torch
from models.experimental import Ensemble

model = Ensemble()
weight = 'yolov7.pt'
ckpt = torch.load(weight, map_location="cpu")  # load
model.append(ckpt['ema' if ckpt.get('ema') else 'model'].float().eval())  # FP32 model

# Compatibility updates
for m in model.modules():
    if type(m) is torch.nn.Upsample:
        m.recompute_scale_factor = None  # torch 1.11.0 compatibility

sys.path.append('../keras_cv_attention_models/')
from keras_cv_attention_models import download_and_load
download_and_load.try_save_pth_and_onnx(model[-1])
```
```py
import tensorflow as tf
from tensorflow import keras
from keras_cv_attention_models.attention_layers import (
    BiasLayer,
    ChannelAffine,
    activation_by_name,
    batchnorm_with_activation,
    conv2d_no_bias,
    depthwise_conv2d_no_bias,
    add_pre_post_process,
)
from keras_cv_attention_models import model_surgery
from keras_cv_attention_models.download_and_load import reload_model_weights
from keras_cv_attention_models.coco import eval_func, anchors_func

# yolov7 backbone
backbone:
  # [from, number, module, args]
  [[-1, 1, Conv, [32, 3, 1]],  # 0

   [-1, 1, Conv, [64, 3, 2]],  # 1-P1/2
   [-1, 1, Conv, [64, 3, 1]],

   [-1, 1, Conv, [128, 3, 2]],  # 3-P2/4
   [-1, 1, Conv, [64, 1, 1]],
   [-2, 1, Conv, [64, 1, 1]],
   [-1, 1, Conv, [64, 3, 1]],
   [-1, 1, Conv, [64, 3, 1]],
   [-1, 1, Conv, [64, 3, 1]],
   [-1, 1, Conv, [64, 3, 1]],
   [[-1, -3, -5, -6], 1, Concat, [1]],
   [-1, 1, Conv, [256, 1, 1]],  # 11

   [-1, 1, MP, []],
   [-1, 1, Conv, [128, 1, 1]],
   [-3, 1, Conv, [128, 1, 1]],
   [-1, 1, Conv, [128, 3, 2]],
   [[-1, -3], 1, Concat, [1]],  # 16-P3/8
   [-1, 1, Conv, [128, 1, 1]],
   [-2, 1, Conv, [128, 1, 1]],
   [-1, 1, Conv, [128, 3, 1]],
   [-1, 1, Conv, [128, 3, 1]],
   [-1, 1, Conv, [128, 3, 1]],
   [-1, 1, Conv, [128, 3, 1]],
   [[-1, -3, -5, -6], 1, Concat, [1]],
   [-1, 1, Conv, [512, 1, 1]],  # 24

   [-1, 1, MP, []],
   [-1, 1, Conv, [256, 1, 1]],
   [-3, 1, Conv, [256, 1, 1]],
   [-1, 1, Conv, [256, 3, 2]],
   [[-1, -3], 1, Concat, [1]],  # 29-P4/16
   [-1, 1, Conv, [256, 1, 1]],
   [-2, 1, Conv, [256, 1, 1]],
   [-1, 1, Conv, [256, 3, 1]],
   [-1, 1, Conv, [256, 3, 1]],
   [-1, 1, Conv, [256, 3, 1]],
   [-1, 1, Conv, [256, 3, 1]],
   [[-1, -3, -5, -6], 1, Concat, [1]],
   [-1, 1, Conv, [1024, 1, 1]],  # 37

   [-1, 1, MP, []],
   [-1, 1, Conv, [512, 1, 1]],
   [-3, 1, Conv, [512, 1, 1]],
   [-1, 1, Conv, [512, 3, 2]],
   [[-1, -3], 1, Concat, [1]],  # 42-P5/32
   [-1, 1, Conv, [256, 1, 1]],
   [-2, 1, Conv, [256, 1, 1]],
   [-1, 1, Conv, [256, 3, 1]],
   [-1, 1, Conv, [256, 3, 1]],
   [-1, 1, Conv, [256, 3, 1]],
   [-1, 1, Conv, [256, 3, 1]],
   [[-1, -3, -5, -6], 1, Concat, [1]],
   [-1, 1, Conv, [1024, 1, 1]],  # 50
  ]

# yolov7 head
def Yolov7Backbone(
    depthes=[2, 8, 8, 4],
    channels=[128, 256, 512, 1024],
    stem_width=-1,  # -1 means using channels[0] // 2
    use_focus_stem=False,
    ssp_depth=2,
    out_features=[-3, -2, -1],
    use_csp_downsample=False,
    use_shortcut_bn=True,
    use_pre=False,
    use_post=True,
    input_shape=(512, 512, 3),
    activation="swish",
    model_name="",
):
    # base_channels = int(width_mul * 64)
    inputs = keras.layers.Input(input_shape)

    """ Stem """
    stem_width = stem_width if stem_width > 0 else channels[0] // 2
    nn = conv2d_no_bias(inputs, 32, kernel_size=3, strides=1, padding="SAME", name="stem_1_")
    nn = batchnorm_with_activation(nn, activation=activation, name="stem_1_")
    nn = conv2d_no_bias(nn, stem_width, kernel_size=3, strides=2, padding="SAME", name="stem_2_")
    nn = batchnorm_with_activation(nn, activation=activation, name="stem_2_")
    nn = conv2d_no_bias(nn, stem_width, kernel_size=3, strides=1, padding="SAME", name="stem_3_")
    nn = batchnorm_with_activation(nn, activation=activation, name="stem_3_")

    features = []

    """ dark blocks """
    for id, (channel, depth) in enumerate(zip(channels, depthes)):
        stack_name = "stack{}_".format(id + 1)
        if use_csp_downsample:
            nn = csp_conv_downsample(nn, channel, activation=activation, name=stack_name)
        else:
            nn = conv_dw_pw_block(nn, channel, 3, strides=2, activation=activation, name=stack_name + "downsample_")
        nn = csp_stack(nn, depth, use_pre=use_pre, use_post=use_post, use_shortcut_bn=use_shortcut_bn, activation=activation, name=stack_name)
        if id == len(depthes) - 1:
            # ssp_depth = max(round(depth_mul * 2), 1)
            nn = res_spatial_pyramid_pooling(nn, ssp_depth, use_shortcut_bn=use_shortcut_bn, activation=activation, name=stack_name + "spp_")
        features.append(nn)

    nn = [features[ii] for ii in out_features]
    model = keras.models.Model(inputs, nn, name=model_name)
    return model

class Conv(nn.Module):
    # Standard convolution
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups
        super(Conv, self).__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())

    def forward(self, x):
        return self.act(self.bn(self.conv(x)))

    def fuseforward(self, x):
        return self.act(self.conv(x))

```
